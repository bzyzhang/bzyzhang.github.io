<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>练习项目(一)：顶点动画</title>
    <url>/2020/11/28/2020-11-28-%EF%BC%88%E4%B8%80%EF%BC%89%E9%A1%B6%E7%82%B9%E5%8A%A8%E7%94%BB/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>之前是使用OpenGL练习图形学项目的，现在要转向在Unity
3d中练习图像学项目。由此，才有了这一系列的项目。本篇将从比较简单的顶点动画说起，开启图形学的篇章。<span id="more"></span></p>
<h1 id="原理">原理</h1>
<p>主要的原理，就是在顶点着色器中，对顶点进行各种偏移。这种偏移，可以根据自己的需要，在模型空间、世界空间、裁剪空间等空间中进行。</p>
<h1 id="压扁效果">1、压扁效果</h1>
<p>开放两个属性，TopY和BottomY，代表物体的上部和底部（世界空间中的数值）。再开放一个滑动属性用来控制顶点运动的幅度。</p>
<p>以TopY为基准，先计算出每个顶点的世界坐标，然后对顶点的Y坐标进行归一化处理。</p>
<figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="keyword">float</span> GetNormalizeDist(<span class="keyword">float</span> worldY)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">float</span> range = _TopY - _BottomY;</span><br><span class="line">    <span class="keyword">float</span> distance = _TopY - worldY;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">return</span> <span class="title">saturate</span><span class="params">(distance / range)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后使用Control滑动属性控制相应的顶点进行位移。（在模型空间移动，之后再转到裁剪空间。）</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>3 positionWS = TransformObjectToWorld(input.positionOS.xyz);</span><br><span class="line"><span class="built_in">float</span> normalizeDist = GetNormalizeDist(positionWS.y);</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span>3 localNegativeY = TransformWorldToObjectDir(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>));</span><br><span class="line"><span class="built_in">float</span> value = saturate(_Control - normalizeDist);</span><br><span class="line">input.positionOS.xyz += localNegativeY * value;</span><br><span class="line"></span><br><span class="line">output.vertex = TransformObjectToHClip(input.positionOS.xyz);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128114002.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.0-VertexAnimation/Shader/1.0.1-Squash.shader">代码</a></p>
<h1 id="被门吸收">2、被门吸收</h1>
<p>与上面的压扁效果的原理类似，只是移动的方向变了，同时还要将顶点的世界坐标传递给片元着色器。</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>3 positionWS = TransformObjectToWorld(input.positionOS.xyz);</span><br><span class="line"><span class="built_in">float</span> normalizeDist = GetNormalizeDist(positionWS.y);</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span>3 localNegativeY = TransformWorldToObjectDir(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line"><span class="built_in">float</span> value = saturate(_Control - normalizeDist);</span><br><span class="line">input.positionOS.xyz += localNegativeY * value;</span><br><span class="line"></span><br><span class="line">output.positionWS = TransformObjectToWorld(input.positionOS.xyz);</span><br></pre></td></tr></table></figure>
<p>还要做一些特殊处理，对超过“门”的部分进行<span
class="math inline">\(Clip\)</span>操作，这是通过比较顶点的世界坐标的<span
class="math inline">\(Y\)</span>值和<span
class="math inline">\(TopY\)</span>来判断的。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">clip</span>(_TopY - <span class="selector-tag">input</span><span class="selector-class">.positionWS</span><span class="selector-class">.y</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128152524.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.0-VertexAnimation/Shader/1.0.2-HideInDoor.shader">代码</a></p>
<h1 id="黑洞吸收">3、黑洞吸收</h1>
<p>与上面的原理类似，只是顶点的移动方向不再是上面的<span
class="math inline">\(Y\)</span>轴，而是朝向某个“黑洞”点。这里需要开放“黑洞”位置的属性接口。同时，也需要传递顶点的世界坐标给片元着色器。</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">float3 positionWS = TransformObjectToWorld(<span class="meta">input</span>.positionOS.xyz);</span><br><span class="line">float normalizeDist = GetNormalizeDist(positionWS.<span class="meta">x</span>);</span><br><span class="line"></span><br><span class="line">float3 toBlackHole = TransformWorldToObjectDir(_BlackHolePos.xyz - positionWS.xyz);</span><br><span class="line">float value = saturate(_Control - normalizeDist);</span><br><span class="line"><span class="meta">input</span>.positionOS.xyz += toBlackHole <span class="comment">* value;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">output</span>.positionWS = TransformObjectToWorld(<span class="meta">input</span>.positionOS.xyz);</span><br></pre></td></tr></table></figure>
<p>在片元着色器中，比较顶点的<span
class="math inline">\(X\)</span>坐标和“黑洞”的<span
class="math inline">\(X\)</span>坐标，进行<span
class="math inline">\(Clip\)</span>操作。</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">clip(_BlackHolePos.<span class="meta">x</span> - <span class="meta">input</span>.positionWS.<span class="meta">x</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128152852.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.0-VertexAnimation/Shader/1.0.3-BlackHole.shader">代码</a></p>
<h1 id="残影">4、残影</h1>
<p>这里的实现原理是，一个<span
class="math inline">\(Pass\)</span>用来渲染本体，另一个<span
class="math inline">\(Pass\)</span>用来渲染残影。这里有一点需要注意，渲染本体的<span
class="math inline">\(Pass\)</span>的<span
class="math inline">\(LightMode\)</span>是<span
class="math inline">\(UniversalForward\)</span>，要想让渲染残影的<span
class="math inline">\(Pass\)</span>也能正常渲染，需要设置该<span
class="math inline">\(Pass\)</span>的<span
class="math inline">\(LightMode\)</span>为<span
class="math inline">\(SRPDefaultUnlit\)</span>。</p>
<p>残影主要有两个实现点，一个是偏离本位，一个是残影自身的抖动。</p>
<p>首先是残影偏离本位，向特定方向整体偏移残影即可。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">input.positionOS += <span class="variable">_Offset</span> * <span class="built_in">cos</span>(<span class="variable">_Time</span>.y * <span class="variable">_ShakeSpeed</span>) * <span class="variable">_ShakeDir</span> * <span class="variable">_Control</span>;</span><br></pre></td></tr></table></figure>
<p>接着是残影的抖动。这里的做法是先把顶点坐标的<span
class="math inline">\(X\)</span>放大<span
class="math inline">\(10\)</span>倍，再向下取整，然后求取对于<span
class="math inline">\(2\)</span>的余数，对奇数部分的顶点进行偏移。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">float yOffset = <span class="number">0.5</span> * (<span class="built_in">floor</span>(input.positionOS.x * <span class="number">10</span>) % <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">input.positionOS += <span class="variable">_ShakeLevel</span> * yOffset * <span class="built_in">sin</span>(<span class="variable">_Time</span>.y * <span class="variable">_ShakeSpeed</span>) * <span class="variable">_ShakeDir</span> * <span class="variable">_Control</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128153024.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.0-VertexAnimation/Shader/1.0.4-Ghost.shader">代码</a></p>
<h1 id="折纸">5、折纸</h1>
<p>这里的原理是，对顶点以折叠处为中心进行旋转。同时要注意的是，为了同时渲染纸张的正面和背面，需要两个<span
class="math inline">\(Pass\)</span>，每个<span
class="math inline">\(Pass\)</span>都要设置正确的<span
class="math inline">\(Cull\)</span>模式。</p>
<p>这里是主要的重新计算折叠后的顶点位置的过程。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">float angle = <span class="variable">_FoldAngle</span>;</span><br><span class="line">float r = <span class="variable">_FoldPos</span> - input.positionOS.x;</span><br><span class="line"></span><br><span class="line"><span class="meta">#if ENABLE_DOUBLE</span></span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        angle = <span class="number">360</span> - <span class="variable">_FoldAngle</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="keyword">if</span> (r &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        angle = <span class="number">180</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">input.positionOS.x = <span class="variable">_FoldPos</span> + r * <span class="built_in">cos</span>(angle * <span class="literal">PI</span> / <span class="number">180</span>);</span><br><span class="line">input.positionOS.y  = r * <span class="built_in">sin</span>(angle * <span class="literal">PI</span> / <span class="number">180</span>);</span><br><span class="line"></span><br><span class="line">output.vertex = TransformObjectToHClip(input.positionOS.xyz);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128153213.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.0-VertexAnimation/Shader/1.0.5-PaperFold.shader">代码</a></p>
<h1 id="注意事项">注意事项</h1>
<p>上面的这几个小项目，只是练习用的，在真正用到项目中的时候，可能会有一些问题。在《<span
class="math inline">\(Unity Shader入门精要\)</span>》一书的<span
class="math inline">\(11.3
顶点动画\)</span>一节中，提到了一些注意事项。一个问题是批处理对顶点动画的影响；一个是对有顶点动画的物体添加阴影的问题。这里不再展开，有需要的可以在书中找到答案。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://www.jianshu.com/p/7cbae91e88d1">Unity Shader -
一些玩具Shader</a></li>
<li>[2] 《<span class="math inline">\(Unity
Shader入门精要\)</span>》</li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Vertex Animation</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(二)：消融效果</title>
    <url>/2020/11/28/2020-11-28-%EF%BC%88%E4%BA%8C%EF%BC%89%E6%B6%88%E8%9E%8D%E6%95%88%E6%9E%9C/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本篇是“练习项目”系列的第二篇，主要介绍一下利用消融实现的效果。在游戏开发的过程中，有很多看起来很神奇的效果，都是使用消融的原理实现的。<span id="more"></span></p>
<h1 id="原理">原理</h1>
<p>主要的原理，就是使用噪声图和透明度测试，根据噪声图中采样的值，对某些像素进行剔除。</p>
<h1 id="基本原理实现">1、基本原理实现</h1>
<p>这里会实现一个最基础的项目，来简单了解消融的基本原理。主要的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br></pre></td></tr></table></figure>
<p><strong>注意，这里要使用AlphaDiscard方法的话，必须设置正确的KeyWord。</strong></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128184418.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.1-Basic.shader">代码</a></p>
<h1 id="边缘颜色">2、边缘颜色</h1>
<p>在上面的动图中可以看到，只是简单实现了消融，但看起来效果不太好，比较单调。下面将使用几种方式来丰富效果。</p>
<h2 id="纯颜色">2.1 纯颜色</h2>
<p>第一种实现方式比较简单，只是在未消融的边界留下一段缓冲，显示边界的颜色。这里需要开放两个属性接口：_EdgeLength、_EdgeColor。即边缘长度和边缘颜色。先根据噪声图进行透明度剔除，然后根据透明度确定一段范围内显示边界的颜色。代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br><span class="line">                </span><br><span class="line"><span class="keyword">if</span> (cutout - _Threshold &lt; _EdgeLength)</span><br><span class="line">	return _EdgeColor;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128190633.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.2-EdgeColor.shader">代码</a></p>
<h2 id="两种颜色混合">2.2 两种颜色混合</h2>
<p>一种颜色的效果看起来还是有点单调，使用两种颜色混合的效果可能会更好。根据_EdgeLength可以确定一个“边界”范围。“边界”与剔除区域的交界可以使用第一种颜色，“边界”与正常区域的交界可以使用第二种颜色，而在“边界”内部，则可以在第一种颜色和第二种颜色之间进行插值。代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br><span class="line">                </span><br><span class="line"><span class="keyword">if</span> (cutout - _Threshold &lt; _EdgeLength)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">float</span> degree = (cutout - _Threshold)<span class="operator"> / </span>_EdgeLength;</span><br><span class="line">	return lerp(_EdgeFirstColor, _EdgeSecondColor, degree);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128191932.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.3-TwoEdgeColor.shader">代码</a></p>
<h2 id="边界颜色混合物体颜色">2.3 边界颜色混合物体颜色</h2>
<p>从上面的动图可以看到，在“边界”区域只是边界的颜色，看起来有点不自然。下一步，就是对边界颜色和物体颜色进行混合，从而看起来更加地自然。主要代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br><span class="line">                </span><br><span class="line"><span class="built_in">float</span> degree = saturate((cutout - _Threshold)<span class="operator"> / </span>_EdgeLength);</span><br><span class="line">half4 edgeColor = lerp(_EdgeFirstColor, _EdgeSecondColor, degree);</span><br><span class="line">                </span><br><span class="line">half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">xy</span>)</span>;</span><br><span class="line">                </span><br><span class="line">half4 finalColor = lerp(edgeColor, col, degree);</span><br></pre></td></tr></table></figure>
<p>在上面的代码中，degree的范围是[0,1]，剔除区域是0，正常区域是1，而在“边界”区域，则在[0,1]之间。使用degree进行第一次插值，得到边界颜色，第二次插值，则混合了边界颜色和物体本身的颜色。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128192742.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.4-BlendOriginColor.shader">代码</a></p>
<h2 id="使用渐变纹理">2.4 使用渐变纹理</h2>
<p>为了让“边界”颜色更加丰富，可以使用渐变纹理。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128193032.png" /></p>
<p>然后就可以使用degree对渐变纹理进行采样，来得到边界的颜色。得到边界颜色后，与物体本身的颜色混合的过程，就与上面相同了。主要代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br><span class="line">                </span><br><span class="line"><span class="built_in">float</span> degree = saturate((cutout - _Threshold)<span class="operator"> / </span>_EdgeLength);</span><br><span class="line">half4 edgeColor = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_RampTex</span>, <span class="params">sampler_RampTex</span>, <span class="params">float2</span>(<span class="params">degree</span>, <span class="params">degree</span>)</span>);</span><br><span class="line">                </span><br><span class="line">half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">xy</span>)</span>;</span><br><span class="line">                </span><br><span class="line">half4 finalColor = lerp(edgeColor, col, degree);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128193230.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.5-Ramp.shader">代码</a></p>
<h1 id="从特定点开始消融">3、从特定点开始消融</h1>
<p>为了从特定点开始消融，必须将片元到特定点的距离考虑进来。</p>
<p>第一步，定义消融开始点的属性，该属性是在世界空间中定义的。在顶点着色器中将该点转换到物体的本地空间，然后将顶点的本地坐标和该点的本地空间坐标传递给片元着色器。在片元着色器中求出片元到该点的距离。代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Properties</span></span><br><span class="line"><span class="constructor">_StartPoint(<span class="string">&quot;Start Point&quot;</span>,Vector)</span> = (<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)   <span class="comment">//需要找到该点的世界坐标</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Vert</span></span><br><span class="line">output.objPos = input.positionOS.xyz;</span><br><span class="line">output.objStartPos = <span class="constructor">TransformWorldToObject(<span class="params">_StartPoint</span>.<span class="params">xyz</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Frag</span></span><br><span class="line"><span class="built_in">float</span> distance = length(input.objPos - input.objStartPos);</span><br></pre></td></tr></table></figure>
<p>第二步，求出网格内任意两点之间的最大距离，用来对上面求出的距离进行归一化处理。这一步需要在C#中实现，思路是遍历任意两点，然后求出最大距离。这里求出的是网格内任意两点之间的最大距离，所以上面定义的消融开始点最好在网格上面，这样效果才是对的。代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Dissolve</span> :</span> MonoBehaviour &#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Start</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">        Material mat = GetComponent&lt;MeshRenderer&gt; ().material;</span><br><span class="line">        mat.<span class="built_in">SetFloat</span> (<span class="string">&quot;_MaxDistance&quot;</span>, <span class="built_in">CalculateMaxDistance</span> ());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">float</span> <span class="title">CalculateMaxDistance</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> maxDistance = <span class="number">0</span>;</span><br><span class="line">        Vector3[] vertices = GetComponent&lt;MeshFilter&gt; ().mesh.vertices;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; vertices.Length; i++) &#123;</span><br><span class="line">            Vector3 v1 = vertices[i];</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; vertices.Length; k++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i == k) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">                Vector3 v2 = vertices[k];</span><br><span class="line">                <span class="keyword">float</span> mag = (v1 - v2).magnitude;</span><br><span class="line">                <span class="keyword">if</span> (maxDistance &lt; mag) maxDistance = mag;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxDistance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时，也要定义_MaxDistance属性来存放最大距离值。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">_MaxDistance</span>(<span class="string">&quot;Max Distance&quot;</span>,Float) = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>第三步就是归一化距离值。</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float normalizedDistance</span> = saturate(distance / _MaxDistance);</span><br></pre></td></tr></table></figure>
<p>第四步是定义_DistanceEffect属性，来控制距离对整个消融效果的影响程度。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Properties</span></span><br><span class="line"><span class="constructor">_DistanceEffect(<span class="string">&quot;Distance Effect&quot;</span>,Range(0,1)</span>) = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Frag</span></span><br><span class="line"><span class="built_in">float</span> cutout = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>.<span class="params">zw</span>)</span>.r<span class="operator"> * </span>(<span class="number">1.0</span> - _DistanceEffect) + normalizedDistance<span class="operator"> * </span>_DistanceEffect;</span><br><span class="line"><span class="constructor">AlphaDiscard(<span class="params">cutout</span>, <span class="params">_Threshold</span>)</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128200647.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.6-DissolveFromPoint.shader">代码</a></p>
<h1 id="应用场景切换">4、应用：场景切换</h1>
<p>利用上面的从特定点开始消融的原理，我们可以用来实现场景切换的效果。</p>
<p>如下图所示，就是我们要实现的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128202628.gif" /></p>
<p>因为我们在上面实现的是从特点点开始消融，而上图是从从外部向特定点开始消融，所以这里要做一些修改。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> normalizedDistance = <span class="number">1</span>.<span class="number">0</span> - saturate(distance / _MaxDistance);</span><br></pre></td></tr></table></figure>
<p>这样，就会从四周向中心点开始消融了。</p>
<p>然后，我们的距离是在局部空间计算的。但是这里有很多物体，再使用局部空间的话，就不太方便，所以，这里转到世界空间计算。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Vert</span></span><br><span class="line">output.worldPos = <span class="constructor">TransformObjectToWorld(<span class="params">input</span>.<span class="params">positionOS</span>.<span class="params">xyz</span>)</span>;</span><br><span class="line"><span class="comment">//Frag</span></span><br><span class="line"><span class="built_in">float</span> distance = length(input.worldPos - <span class="module-access"><span class="module"><span class="identifier">_StartPoint</span>.</span></span>xyz);</span><br></pre></td></tr></table></figure>
<p>接下来，需要获得场景所有物体的顶点到消融点的最大距离，用来对上面的距离做归一化处理，这一步，需要在C#中处理，<a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Script/DissolveEnvironment.cs">代码在这里</a>。</p>
<p>这样，场景中建一个空物体Environment，然后给Environment添加上面的C#脚本，再把其它物体都放到Environment下面即可。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128203543.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.7-ToPoint.shader">代码</a></p>
<h1 id="从特定方向开始消融">5、从特定方向开始消融</h1>
<p>理解了上面的从特定点开始消融，那么这里的从特定方向开始消融就很好理解了。</p>
<p>这里实行的是从X方向消融。</p>
<p>第一步，求出X方向的边界，传递给Shader。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">public <span class="keyword">class</span> DissolveDirection : MonoBehaviour &#123;</span><br><span class="line"></span><br><span class="line">    void Start <span class="literal">()</span> &#123;</span><br><span class="line">        Material mat = GetComponent&lt;Renderer&gt;<span class="literal">()</span>.material;</span><br><span class="line">        <span class="built_in">float</span> minX, maxX;</span><br><span class="line">        <span class="constructor">CalculateMinMaxX(<span class="params">out</span> <span class="params">minX</span>, <span class="params">out</span> <span class="params">maxX</span>)</span>;</span><br><span class="line">        mat.<span class="constructor">SetFloat(<span class="string">&quot;_MinBorderX&quot;</span>, <span class="params">minX</span>)</span>;</span><br><span class="line">        mat.<span class="constructor">SetFloat(<span class="string">&quot;_MaxBorderX&quot;</span>, <span class="params">maxX</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    void <span class="constructor">CalculateMinMaxX(<span class="params">out</span> <span class="params">float</span> <span class="params">minX</span>, <span class="params">out</span> <span class="params">float</span> <span class="params">maxX</span>)</span></span><br><span class="line">    &#123;</span><br><span class="line">        Vector3<span class="literal">[]</span> vertices = GetComponent&lt;MeshFilter&gt;<span class="literal">()</span>.mesh.vertices;</span><br><span class="line">        minX = maxX = vertices<span class="literal">[<span class="number">0</span>]</span>.x;</span><br><span class="line">        <span class="keyword">for</span>(<span class="built_in">int</span> i = <span class="number">1</span>; i &lt; vertices.Length; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">float</span> x = vertices<span class="literal">[<span class="identifier">i</span>]</span>.x;</span><br><span class="line">            <span class="keyword">if</span> (x &lt; minX)</span><br><span class="line">                minX = x;</span><br><span class="line">            <span class="keyword">if</span> (x &gt; maxX)</span><br><span class="line">                maxX = x;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二步，定义从X的正方向还是负方向开始消融，确定边界，然后求出各个片元在X方向上与边界的距离。再进行归一化处理。</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> <span class="built_in">range</span> = _MaxBorderX - _MinBorderX;</span><br><span class="line"><span class="built_in">float</span> <span class="built_in">border</span> = _MinBorderX;</span><br><span class="line"><span class="keyword">if</span> (_Direction == <span class="number">1</span>) //<span class="number">1</span>表示从X正方向开始，其他值则从负方向</span><br><span class="line">	<span class="built_in">border</span> = _MaxBorderX;</span><br><span class="line">                </span><br><span class="line"><span class="built_in">float</span> distance = <span class="built_in">abs</span>(input.objPosX - <span class="built_in">border</span>);</span><br><span class="line"><span class="built_in">float</span> normalizedDistance = saturate(distance / <span class="built_in">range</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128204249.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.8-DissolveFromDirectionX.shader">代码</a></p>
<h1 id="灰烬飞散效果">6、灰烬飞散效果</h1>
<p>第一步，灰烬向特定方向飞散。这一步可以在顶点着色器中通过顶点动画实现。</p>
<figure class="highlight ocaml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> cutout = <span class="type">GetNormalizeDistance</span>(output.positionWS.y);</span><br><span class="line">float3 localFlyDirection = <span class="type">TransformWorldToObjectDir</span>(_FlyDirection.xyz);</span><br><span class="line"><span class="built_in">float</span> flyDegree = (_Threshold- cutout) / _EdgeLength;</span><br><span class="line"><span class="built_in">float</span> <span class="keyword">val</span> = saturate(flyDegree * _FlyIntensity);</span><br><span class="line">input.positionOS.xyz += localFlyDirection * <span class="keyword">val</span>;</span><br></pre></td></tr></table></figure>
<p>第二步，从特定方向开始消融。上面已经介绍了。这里注意，因为要生成灰烬的效果，所以要延迟透明度剔除的时机。</p>
<figure class="highlight mel"><table><tr><td class="code"><pre><span class="line"><span class="keyword">float</span> edgeCutout = cutout - _Threshold;</span><br><span class="line"><span class="keyword">clip</span>(edgeCutout + _AshWidth);</span><br></pre></td></tr></table></figure>
<p>这样，可以在消融边缘留下大片的颜色。而我们需要的是细碎的灰烬，所以需要再次使用噪声图对这片颜色区域进行消融处理。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(degree &lt; <span class="number">0.001</span>)</span><br><span class="line">&#123;</span><br><span class="line">	clip(whiteNoise * <span class="variable">_AshDensity</span> + normalizedDistance * <span class="variable">_DistanceEffect</span> - <span class="variable">_Threshold</span>);</span><br><span class="line">	finalColor = <span class="variable">_AshColor</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128210450.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.9-DirectionAsh.shader">代码</a></p>
<h1 id="镜头遮挡消融">7、镜头遮挡消融</h1>
<p>这里要实现的，是当角色和镜头之间有障碍物时，对障碍物进行消融处理。</p>
<p>第一步，将角色的坐标传递给Shader，这一步是在C#中实现的。</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SendPlayerPos</span> :</span> MonoBehaviour &#123;</span><br><span class="line">    <span class="keyword">public</span> Transform player;</span><br><span class="line">    <span class="keyword">public</span> Material blockMat;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Update</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">        blockMat.<span class="built_in">SetVector</span> (<span class="string">&quot;_PlayerPos&quot;</span>, player.position);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二步，使用屏幕空间的遮罩纹理，对消融区域进行控制。对角色和镜头之间的片元，进行剔除处理。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> toCamera = distance(input.positionWS, _WorldSpaceCameraPos);</span><br><span class="line"><span class="built_in">float</span> playerToCamera = distance(<span class="module-access"><span class="module"><span class="identifier">_PlayerPos</span>.</span></span>xyz, _WorldSpaceCameraPos);</span><br><span class="line">                </span><br><span class="line">float2 wcoord = input.positionNDC.xy<span class="operator"> / </span>input.positionNDC.w;</span><br><span class="line"><span class="built_in">float</span> mask = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_ScreenSpaceMaskTex</span>, <span class="params">sampler_ScreenSpaceMaskTex</span>, <span class="params">wcoord</span>)</span>.r;</span><br><span class="line">half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line"><span class="built_in">float</span> gradient = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>.r;</span><br><span class="line">                </span><br><span class="line"><span class="keyword">if</span> (toCamera &lt; playerToCamera)</span><br><span class="line">	clip(gradient - mask + (toCamera - _WorkDistance)<span class="operator"> / </span>_WorkDistance);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-28/20201128213830.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.1-Dissolve/Shader/1.1.10-Trifox.shader">代码</a></p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://www.jianshu.com/p/d8b535efa9db">Unity Shader -
消融效果原理与变体</a></li>
<li>[2] 《Unity Shader入门精要​》</li>
<li>[3] <a
href="https://connect.unity.com/p/unityji-zhu-fen-xiang-trifox-zhong-de-zhe-dang-chu-li-he-rong-jie-zhao-se-qi-shang">Unity技术分享
|《Trifox》中的遮挡处理和溶解着色器（上）</a></li>
<li>[4] <a
href="http://kylehalladay.com/blog/tutorial/2015/11/10/Dissolve-Shader-Redux.html">A
Burning Paper Shader</a></li>
<li>[5] <a
href="http://www.codeavarice.com/dev-blog/tutorial-burning-edges-dissolve-shader-in-unity">Tutorial
- Burning Edges Dissolve Shader in Unity</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Dissolve</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(三)：表面凹凸技术</title>
    <url>/2020/11/29/2020-11-29-%EF%BC%88%E4%B8%89%EF%BC%89%E8%A1%A8%E9%9D%A2%E5%87%B9%E5%87%B8%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本篇是“练习项目”系列的第三篇，主要介绍一下利用表面凹凸技术提升物体的表面细节。为了提升模型表面的细节，一个可以想到的方式是制作更加复杂的网格，但这是不可取的。一方面会增加美术人员的工作量；另一方面，也会对机器的性能造成很大的消耗。本篇文章，将介绍一些表面凹凸的技术，来达到提高表面细节的目的。<span id="more"></span></p>
<h1 id="一凹凸贴图bump-mapping">一、凹凸贴图（Bump Mapping）</h1>
<p>这种技术，使用高度图来计算法线。给定一张高度图，通过计算相邻像素的高度差值来改变表面法向量。</p>
<p>为了计算(u,v)处的法向量，要经过以下几步。</p>
<p>第一步，在(u-1,v)和(u+1,v)处采样高度图，得到高度值u1、u2。由此，可以得到二者之间的差值du。进而，可以得到x方向的切向量：<span
class="math inline">\(tu = (1,0,du)\)</span>。</p>
<p>第二步，在(u,v-1)和(u,v+1)处采样高度图，得到高度值v1、v2。由此，可以得到二者之间的差值dv。进而，可以得到y方向的切向量：<span
class="math inline">\(tv = (0,1,dv)\)</span>。</p>
<p>第三步，tu和tv进行叉乘，从而得到法向量。</p>
<p>主要的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">float3 <span class="constructor">CalculateNormal(<span class="params">float2</span> <span class="params">uv</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	float2 du = float2(<span class="module-access"><span class="module"><span class="identifier">_DepthMap_TexelSize</span>.</span></span>x<span class="operator"> * </span><span class="number">0.5</span>,<span class="number">0</span>);</span><br><span class="line">	<span class="built_in">float</span> u1 = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>,<span class="params">sampler_DepthMap</span>,<span class="params">uv</span> - <span class="params">du</span>)</span>.r;</span><br><span class="line">	<span class="built_in">float</span> u2 = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>,<span class="params">sampler_DepthMap</span>,<span class="params">uv</span> + <span class="params">du</span>)</span>.r;</span><br><span class="line">	float3 tu = float3(<span class="number">1</span>,<span class="number">0</span>,(u2 - u1)*_Scale);</span><br><span class="line"></span><br><span class="line">	float2 dv = float2(<span class="number">0</span>,<span class="module-access"><span class="module"><span class="identifier">_DepthMap_TexelSize</span>.</span></span>y<span class="operator"> * </span><span class="number">0.5</span>);</span><br><span class="line">	<span class="built_in">float</span> v1 = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>,<span class="params">sampler_DepthMap</span>,<span class="params">uv</span> - <span class="params">dv</span>)</span>.r;</span><br><span class="line">	<span class="built_in">float</span> v2 = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>,<span class="params">sampler_DepthMap</span>,<span class="params">uv</span> + <span class="params">dv</span>)</span>.r;</span><br><span class="line">	float3 tv = float3(<span class="number">0</span>,<span class="number">1</span>,(v2 - v1)*_Scale);</span><br><span class="line"></span><br><span class="line">	return normalize(-cross(tu,tv));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129103807.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.1-Bump.shader">代码</a></p>
<h1 id="二法线贴图normal-mapping">二、法线贴图（Normal Mapping）</h1>
<p>法线贴图，在实际的生产过程中，应该是使用频率比较高的表面凹凸技术。恰好之前写了一篇关于法线贴图的文章，这里就不再赘述，有兴趣的可以去看一下。<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/05/17/2020-5-17-%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/">法线贴图那些事儿</a>。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129105601.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.2-NormalMapping.shader">代码</a></p>
<h1 id="三视差贴图parallax-mapping">三、视差贴图（Parallax
Mapping）</h1>
<p>根据视线方向与高度图（深度图）的交点，找到新的UV。</p>
<p>示意图如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129110126.png" /></p>
<p>实际使用的时候，要准确求得交点，计算量很大，因此会选择使用一些近似的方案。</p>
<h2 id="视差贴图简单版">1、视差贴图简单版</h2>
<p>直接根据当前UV采样的高度值，然后将该高度值乘以视线方向（单位向量），进而得到新的UV值。</p>
<p>如下图所示，我们根据当前的(u,v)得到深度值为d，然后将深度值乘以视线方向，能得到新的(u1,v1)，可以看见该结果还是离准确的结果（黄色）比较近的。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129111816.png" /></p>
<p>计算新的UV的主要代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">float2 <span class="constructor">ParallaxMapping(<span class="params">float2</span> <span class="params">uv</span>, <span class="params">float3</span> <span class="params">viewDir_tangent</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	float3 viewDir = normalize(viewDir_tangent);</span><br><span class="line">	<span class="built_in">float</span> height = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>, <span class="params">sampler_DepthMap</span>, <span class="params">uv</span>)</span>.r;</span><br><span class="line">	<span class="comment">//因为viewDir是在切线空间的（xy与uv对齐），所以只用xy偏移就行了</span></span><br><span class="line">	float2 p = viewDir.xy<span class="operator"> / </span>viewDir.z<span class="operator"> * </span>(height<span class="operator"> * </span>_HeightScale); <span class="comment">//_HeightScale用来调整高度（深度）</span></span><br><span class="line">	return uv - p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129112002.gif" /></p>
<p>在视差贴图的那个平面里你仍然能看到在边上有古怪的失真。原因是在平面的边缘上，纹理坐标超出了0到1的范围进行采样，根据纹理的环绕方式导致了不真实的结果。解决的方法是当它超出默认纹理坐标范围进行采样的时候就丢弃这个片元：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">if</span> (uv.x &gt; <span class="number">1</span>.<span class="number">0</span> || uv.y &gt; <span class="number">1</span>.<span class="number">0</span> || uv.x &lt; <span class="number">0</span>.<span class="number">0</span> || uv.y &lt; <span class="number">0</span>.<span class="number">0</span>) //去掉边上的一些古怪的失真，在平面上工作得挺好的</span><br><span class="line">	<span class="attribute">discard</span>;</span><br></pre></td></tr></table></figure>
<p>可以看见该简单版的实现很简单，但是效果并不十分好，只能用在平缓的凹凸面上，但表面凹凸很明显时，会有明显的失真。通过分析下面这张图就能知道为什么凹凸明显时会失真：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129112835.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-SimpleParallax.shader">代码</a></p>
<h2
id="带偏移量限制的视差贴图-parallax-mapping-with-offset-limiting">2、带偏移量限制的视差贴图
(Parallax Mapping with offset limiting)</h2>
<p>为了减轻视线与平面十分持平时（V.z很小导致偏移量过大）产生的怪异效果，可以去掉除以V.z这一步。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">float2 <span class="constructor">ParallaxMapping(<span class="params">float2</span> <span class="params">uv</span>, <span class="params">float3</span> <span class="params">viewDir_tangent</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	float3 viewDir = normalize(viewDir_tangent);</span><br><span class="line">	<span class="built_in">float</span> height = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>, <span class="params">sampler_DepthMap</span>, <span class="params">uv</span>)</span>.r;</span><br><span class="line">	<span class="comment">//因为viewDir是在切线空间的（xy与uv对齐），所以只用xy偏移就行了</span></span><br><span class="line">	float2 p = viewDir.xy<span class="operator"> * </span>(height<span class="operator"> * </span>_HeightScale); <span class="comment">//_HeightScale用来调整高度（深度）</span></span><br><span class="line">	return uv - p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129112957.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-SimpleParallaxWithOffsetLimit.shader">代码</a></p>
<h2 id="陡峭视差贴图-steep-parallax-mapping">3、陡峭视差贴图 (Steep
Parallax Mapping)</h2>
<p>陡峭视差贴图(Steep Parallax
Mapping)是视差贴图的扩展，原则是一样的，但不是使用一个样本而是多个样本来计算新的UV。即使在陡峭的高度变化的情况下，它也能得到更好的结果，原因在于该技术通过增加采样的数量提高了精确性。</p>
<p>陡峭视差贴图的基本思想是将总深度范围划分为同一个深度/高度的多个层。从每个层中我们沿着视线方向移动采样纹理坐标，直到我们找到一个采样低于当前层的深度值。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129132946.png" /></p>
<p>步骤如下：</p>
<ol type="1">
<li><p>找到视线方向与第0层的交点<span
class="math inline">\(T_0\)</span>，层深度是0.0，对应深度值为0.75，因为该点在深度图之上，所以找下一个点。</p></li>
<li><p>找到视线方向与第1层的交点<span
class="math inline">\(T_1\)</span>，层深度是0.125，对应深度值为0.625，因为该点在深度图之上，所以找下一个点。</p></li>
<li><p>找到视线方向与第2层的交点<span
class="math inline">\(T_2\)</span>，层深度是0.25，对应深度值为0.4，因为该点在深度图之上，所以找下一个点。</p></li>
<li><p>找到视线方向与第3层的交点<span
class="math inline">\(T_3\)</span>，层深度是0.375，对应深度值为0.2，因为该点在深度图之下，所以这就是我们要找的点。</p></li>
</ol>
<p>主要的代码如下：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>2 ParallaxMapping(<span class="built_in">float</span>2 uv, <span class="built_in">float</span>3 viewDir_tangent)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">float</span>3 viewDir = normalize(viewDir_tangent);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span> layerNum = lerp(_MaxLayerNum, _MinLayerNum, abs(dot(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>), viewDir)));<span class="comment">//一点优化：根据视角来决定分层数</span></span><br><span class="line">	<span class="built_in">float</span> layerDepth = <span class="number">1.0</span> / layerNum;</span><br><span class="line">	<span class="built_in">float</span> currentLayerDepth = <span class="number">0.0</span>;</span><br><span class="line">	<span class="built_in">float</span>2 deltaTexCoords = viewDir.xy / viewDir.z / layerNum * _HeightScale;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span>2 currentTexCoords = uv;</span><br><span class="line">	<span class="built_in">float</span> currentDepthMapValue = SAMPLE_TEXTURE2D(_DepthMap, sampler_DepthMap, currentTexCoords).r;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//unable to unroll loop, loop does not appear to terminate in a timely manner</span></span><br><span class="line">	<span class="comment">//上面这个错误是在循环内使用SAMPLE_TEXTURE2D导致的，需要加上unroll来限制循环次数或者改用SAMPLE_TEXTURE2D_LOD</span></span><br><span class="line">	<span class="comment">// [unroll(100)]</span></span><br><span class="line">	<span class="keyword">while</span>(currentLayerDepth &lt; currentDepthMapValue)</span><br><span class="line">	&#123;</span><br><span class="line">		currentTexCoords -= deltaTexCoords;</span><br><span class="line">		<span class="comment">// currentDepthMapValue = SAMPLE_TEXTURE2D(_DepthMap, sampler_DepthMap, currentTexCoords).r;</span></span><br><span class="line">		currentDepthMapValue = SAMPLE_TEXTURE2D_LOD(_DepthMap, sampler_DepthMap, currentTexCoords, <span class="number">0</span>).r;</span><br><span class="line">		currentLayerDepth += layerDepth;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> currentTexCoords;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129133926.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-SteepParallax.shader">代码</a></p>
<h2 id="浮雕视差贴图-relief-parallax-mapping">4、浮雕视差贴图 (Relief
Parallax Mapping)</h2>
<p>该方法是对陡峭视差贴图的进一步优化。在陡峭视差贴图的基础上，利用二分查找来细化结果。</p>
<p>如下图，假设我们利用陡峭视差贴图找到了T3，而T是准确的交点，二分查找的次数为3。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129134351.png" /></p>
<p>步骤：</p>
<ol type="1">
<li><p>取<span class="math inline">\(T_2\)</span>和<span
class="math inline">\(T_3\)</span>的中点<span
class="math inline">\(P_1\)</span>，因为<span
class="math inline">\(P_1\)</span>在下面，因此用<span
class="math inline">\(P_1\)</span>取代<span
class="math inline">\(T_3\)</span></p></li>
<li><p>取<span class="math inline">\(T_2\)</span>和<span
class="math inline">\(P_1\)</span>的中点<span
class="math inline">\(P_2\)</span>，因为<span
class="math inline">\(P_2\)</span>在上面，因此用<span
class="math inline">\(P_2\)</span>取代<span
class="math inline">\(T_2\)</span></p></li>
<li><p>取<span class="math inline">\(P_2\)</span>和<span
class="math inline">\(P_1\)</span>的中点<span
class="math inline">\(P_3\)</span>，因为<span
class="math inline">\(P_3\)</span>在下面，因此用<span
class="math inline">\(P_3\)</span>取代<span
class="math inline">\(P_1\)</span></p></li>
<li><p>到达二分查找次数上限，结果为<span
class="math inline">\(P_3\)</span>。</p></li>
</ol>
<p>主要代码如下：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>2 ParallaxMapping(<span class="built_in">float</span>2 uv, <span class="built_in">float</span>3 viewDir_tangent)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">float</span> layerNum = lerp(_MinLayerNum, _MaxLayerNum, abs(dot(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>), viewDir_tangent)));</span><br><span class="line">	<span class="built_in">float</span> layerDepth = <span class="number">1.0</span> / layerNum;</span><br><span class="line">	<span class="built_in">float</span> currentLayerDepth = <span class="number">0.0</span>;</span><br><span class="line">	<span class="built_in">float</span>2 deltaUV = viewDir_tangent.xy / viewDir_tangent.z * _HeightScale / layerNum;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span>2 currentTexCoords = uv;</span><br><span class="line">	<span class="built_in">float</span> currentDepthMapValue = SAMPLE_TEXTURE2D(_DepthMap, sampler_DepthMap, currentTexCoords).r;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//unable to unroll loop, loop does not appear to terminate in a timely manner</span></span><br><span class="line">	<span class="comment">//上面这个错误是在循环内使用SAMPLE_TEXTURE2D导致的，需要加上unroll来限制循环次数或者改用SAMPLE_TEXTURE2D_LOD</span></span><br><span class="line">	<span class="comment">// [unroll(100)]</span></span><br><span class="line">	<span class="keyword">while</span>(currentLayerDepth &lt; currentDepthMapValue)</span><br><span class="line">	&#123;</span><br><span class="line">		currentTexCoords -= deltaUV;</span><br><span class="line">		<span class="comment">// currentDepthMapValue = SAMPLE_TEXTURE2D(_DepthMap, sampler_DepthMap, currentTexCoords).r;</span></span><br><span class="line">		currentDepthMapValue = SAMPLE_TEXTURE2D_LOD(_DepthMap, sampler_DepthMap, currentTexCoords, <span class="number">0</span>).r;</span><br><span class="line">		currentLayerDepth += layerDepth;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//二分查找</span></span><br><span class="line">	<span class="built_in">float</span>2 halfDeltaUV = deltaUV / <span class="number">2</span>;</span><br><span class="line">	<span class="built_in">float</span> halfLayerDepth = layerDepth / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">	currentTexCoords += halfDeltaUV;</span><br><span class="line">	currentLayerDepth -= halfLayerDepth;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">int</span> numSearches = <span class="number">5</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; numSearches; i ++)</span><br><span class="line">	&#123;</span><br><span class="line">		halfDeltaUV = halfDeltaUV / <span class="number">2</span>;</span><br><span class="line">		halfLayerDepth = halfLayerDepth / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">		currentDepthMapValue = SAMPLE_TEXTURE2D_LOD(_DepthMap, sampler_DepthMap, currentTexCoords, <span class="number">0</span>).r;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (currentDepthMapValue &gt; currentLayerDepth)</span><br><span class="line">		&#123;</span><br><span class="line">			currentTexCoords -= halfDeltaUV;</span><br><span class="line">			currentLayerDepth += halfLayerDepth;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			currentTexCoords += halfDeltaUV;</span><br><span class="line">			currentLayerDepth -= halfLayerDepth;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> currentTexCoords;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129134955.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-ReliefParallax.shader">代码</a></p>
<h2 id="视差遮蔽贴图-parallax-occlusion-mapping-pom">5、视差遮蔽贴图
(Parallax Occlusion Mapping, POM)</h2>
<p>视差遮蔽贴图(Parallax Occlusion
Mapping)和陡峭视差贴图的原则相同，但不是用触碰的第一个深度层的纹理坐标，而是在触碰之前和之后，在深度层之间进行线性插值。我们根据表面的高度距离啷个深度层的深度层值的距离来确定线性插值的大小。</p>
<p>利用陡峭视差贴图得到最靠近交点的<span
class="math inline">\(T_2\)</span>和<span
class="math inline">\(T_3\)</span>后，根据这两者的深度与对应层深度的差值作为比例进行插值。</p>
<p>看看下面的图片就能了解它是如何工作的：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129135507.png" /></p>
<p>主要代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">float2 prevTexCoords = currentTexCoords + deltaTexCoords;</span><br><span class="line"><span class="built_in">float</span> prevLayerDepth = currentLayerDepth - layerDepth;</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span> afterDepth = currentDepthMapValue - currentLayerDepth;</span><br><span class="line"><span class="built_in">float</span> beforeDepth = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_DepthMap</span>, <span class="params">sampler_DepthMap</span>, <span class="params">prevTexCoords</span>)</span>.r - prevLayerDepth;</span><br><span class="line"><span class="built_in">float</span> weight = afterDepth<span class="operator"> / </span>(afterDepth - beforeDepth);</span><br><span class="line"><span class="comment">//权重越大，纹理坐标的比重越小</span></span><br><span class="line">float2 finalTexCoords = prevTexCoords<span class="operator"> * </span>weight + currentTexCoords<span class="operator"> * </span>(<span class="number">1.0</span> - weight);</span><br><span class="line"></span><br><span class="line">return finalTexCoords;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129135633.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-ParallaxOcclusion.shader">代码</a></p>
<h2 id="带自阴影的视差贴图">6、带自阴影的视差贴图</h2>
<p>上面的几种视差贴图都没有考虑自阴影（即凸起部分能向其他部分投射阴影）。要实现自阴影也不难，和制作深度图一样，此时沿着光线方向指向我们利用视差贴图找到的交点，然后判断该交点是否被其他部分遮蔽了。</p>
<p>实际上大部分操作和视差贴图类似，只是把操作的向量从视线向量改为光线向量而已。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129135935.png" /></p>
<p>主要的代码如下：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> ParallaxShadow(<span class="built_in">float</span>3 lightDir_tangent, <span class="built_in">float</span>2 initialUV, <span class="built_in">float</span> initialHeight)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">float</span>3 lightDir = normalize(lightDir_tangent);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">float</span> shadowMultiplier = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">float</span> minLayers = <span class="number">15</span>;</span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">float</span> maxLayers = <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//只算正对阳光的面</span></span><br><span class="line">	<span class="keyword">if</span> (dot(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>), lightDir) &gt; <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">float</span> numSamplesUnderSurface = <span class="number">0</span>;</span><br><span class="line">		<span class="built_in">float</span> numLayers = lerp(maxLayers, minLayers, abs(dot(<span class="built_in">float</span>3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>), lightDir))); <span class="comment">//根据光线方向决定层数</span></span><br><span class="line">		<span class="built_in">float</span> layerHeight = <span class="number">1</span> / numLayers;</span><br><span class="line">		<span class="built_in">float</span>2 texStep = _HeightScale * lightDir.xy / lightDir.z / numLayers;</span><br><span class="line"></span><br><span class="line">		<span class="built_in">float</span> currentLayerHeight = initialHeight - layerHeight;</span><br><span class="line">		<span class="built_in">float</span>2 currentTexCoords = initialUV + texStep;</span><br><span class="line">		<span class="built_in">float</span> heightFromTexture = SAMPLE_TEXTURE2D(_DepthMap, sampler_DepthMap, currentTexCoords).r;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">while</span>(currentLayerHeight &gt; <span class="number">0</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">if</span> (heightFromTexture &lt;= currentLayerHeight)</span><br><span class="line">				numSamplesUnderSurface += <span class="number">1</span>; <span class="comment">//统计被遮挡的层数</span></span><br><span class="line"></span><br><span class="line">			currentLayerHeight -= layerHeight;</span><br><span class="line">			currentTexCoords += texStep;</span><br><span class="line">			heightFromTexture = SAMPLE_TEXTURE2D_LOD(_DepthMap, sampler_DepthMap, currentTexCoords, <span class="number">0</span>).r;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		shadowMultiplier = <span class="number">1</span> - numSamplesUnderSurface / numLayers; <span class="comment">//根据被遮挡的层数来决定阴影深浅</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> shadowMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129140105.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-SteepParallaxWithShadow.shader">代码</a></p>
<h2 id="带软自阴影的视差贴图">7、带软自阴影的视差贴图</h2>
<p>为了美化上面的自阴影效果，这里使用软阴影。</p>
<p>主要的代码如下：</p>
<figure class="highlight nix"><table><tr><td class="code"><pre><span class="line">while(currentLayerHeight &gt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (heightFromTexture &lt; currentLayerHeight)</span><br><span class="line">	&#123;</span><br><span class="line">		numSamplesUnderSurface += <span class="number">1</span>;</span><br><span class="line">		float <span class="attr">newShadowMultiplier</span> = (currentLayerHeight - heightFromTexture) * (<span class="number">1.0</span> - stepIndex / numLayers);</span><br><span class="line">		<span class="attr">shadowMultiplier</span> = max(shadowMultiplier, newShadowMultiplier);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	stepIndex += <span class="number">1</span>;</span><br><span class="line">	currentLayerHeight <span class="attr">-=</span> layerHeight;</span><br><span class="line">	currentTexCoords += texStep;</span><br><span class="line">	<span class="attr">heightFromTexture</span> = SAMPLE_TEXTURE2D_LOD(_DepthMap, sampler_DepthMap, currentTexCoords, <span class="number">0</span>).r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(numSamplesUnderSurface &lt; <span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="attr">shadowMultiplier</span> = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="attr">shadowMultiplier</span> = <span class="number">1.0</span> - shadowMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-11-29/20201129140357.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.2-Bump/Shader/1.2.3-SteepParallaxWithSoftShadow.shader">代码</a></p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://www.jianshu.com/p/fea6c9fc610f">Unity Shader -
表面凹凸技术汇总</a></li>
<li>[2] 《Unity Shader入门精要​》</li>
<li>[3] <a
href="https://learnopengl-cn.github.io/05%20Advanced%20Lighting/05%20Parallax%20Mapping/">视差贴图</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Bump</tag>
        <tag>Nomal Map</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(四)：深度图基础及应用</title>
    <url>/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本篇是“练习项目”系列的第四篇，主要介绍一下深度图的原理，以及使用深度图实现一些炫酷的效果。这里再次说一下，本系列的文章，大部分是根据网上的博客，把项目从Build
in管线转到新版的URP管线。前面三篇文章，基本没遇到什么因为管线不同而产生的困难。但到了深度图和后处理，新旧管线之间还是有相当大的不同的，在这里绕了不少弯路，希望这里多注意一下。<span id="more"></span></p>
<h1 id="一原理">一、原理</h1>
<p>深度纹理实际就是一张渲染纹理，只不过它里面存储的像素值不是颜色值，而是一个高精度的深度值。由于被存储在一张纹理中，深度纹理里面的深度值范围是<span
class="math inline">\([0,1]\)</span>。</p>
<p>模型空间中的顶点，经过MVP变换后，变换到了裁剪空间。在裁剪空间的最后，所以的可见的点都在标准设备坐标系（NDC）中，即坐标坐落在范围<span
class="math inline">\([-1,1]^{3}\)</span>内。在得到NDC坐标后，深度纹理中的像素值就可以很方便地得到了，这些深度值就对应了NDC坐标中顶点坐标的Z分量的值。由于NDC中Z分量的范围为<span
class="math inline">\([-1,1]\)</span>，为了让这些值能存储在一张纹理中，我们需要使用下面的公式对其进行映射：​
<span class="math display">\[
d = 0.5 * z_{ndc} + 0.5
\]</span> 其中，<span
class="math inline">\(d\)</span>对应了深度纹理中的像素值，<span
class="math inline">\(z_{ndc}\)</span>对应了NDC坐标中Z分量的值。</p>
<p>在Unity的前向渲染中，获取深度纹理的具体实现大致如下：Unity会使用着色器替换（Shader
Replacement）技术选择那些渲染类型（即SubShader的RenderType标签）为Opaque的物体，判断它们使用的渲染队列是否小于等于2500（内置的Background、Geometry和AlphaTest渲染队列均在此范围内），如果满足条件，就把它渲染到深度纹理中。<strong>这里需要注意一下，Build
in管线会使用ShadowCaster
Pass来得到深度纹理；而新版的URP管线使用DepthOnly
Pass来得到深度纹理。</strong></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201201230808.png" /></p>
<h1 id="二访问深度纹理">二、访问深度纹理</h1>
<p>在之前Build in管线中，需要在相机上挂一个脚本，脚本里面设置:</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">Camera.main.depthTextureMode</span> = DepthTextureMode.Depth<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>然后通过_CameraDepthTexture变量访问深度纹理。</p>
<p>在URP管线中，这一步有了变换。首先，在管线配置文件中勾选深度图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201201231113.png" /></p>
<p>在Shader中，也是通过_CameraDepthTexture访问深度纹理。但这里比较方便的是，有个内置文件对深度纹理相关的操作做了封装，我们只需要添加相应的引用即可调用。</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl&quot;</span></span></span><br></pre></td></tr></table></figure>
<h1 id="三后处理流程">三、后处理流程</h1>
<p>URP的后处理与之前Unity的后处理写法完全不一样。原来的OnRenderImage、OnPreRender都失效了。</p>
<p>URP中内置了一些后处理效果，是通过Volume组件管理的。可以在Hierarchy视图中添加Volume组件，然后就可以管理后处理效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202075156.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202075215.png" /></p>
<p>可以仿照内置的后处理效果，自定义我们自己的后处理效果。</p>
<h2 id="添加自定义override">1、添加自定义Override</h2>
<p>我们想在Volume中Add
Overrides的时候看到自己定义的Override。模仿内置的代码，可以新建一个脚本，内容如下：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">UnityEngine.Rendering.Universal</span></span><br><span class="line">&#123;</span><br><span class="line">    [<span class="meta">Serializable, VolumeComponentMenu(<span class="meta-string">&quot;Custom Post-processing/Print Depth Map&quot;</span>)</span>]</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">sealed</span> <span class="keyword">class</span> <span class="title">PrintDepthMap</span> : <span class="title">VolumeComponent</span>, <span class="title">IPostProcessComponent</span></span><br><span class="line">    &#123;</span><br><span class="line">        [<span class="meta">Tooltip(<span class="meta-string">&quot;是否开启效果&quot;</span>)</span>]</span><br><span class="line">        <span class="keyword">public</span> BoolParameter enableEffect = <span class="keyword">new</span> BoolParameter(<span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="built_in">bool</span> <span class="title">IsActive</span>(<span class="params"></span>)</span> =&gt; enableEffect == <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="built_in">bool</span> <span class="title">IsTileCompatible</span>(<span class="params"></span>)</span> =&gt; <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样，在Add Override的时候，我们就可以看到自定义的组件了。</p>
<h2 id="实现后处理功能">2、实现后处理功能</h2>
<p>在上面添加完自定义Override之后，并没有什么效果。这是因为，Override相当于只是数据来源，真正的后处理功能还没有实现。参考内置的后处理源码，可以发现，它们的实现是在PostProcessPass.cs脚本中实现的。在实际的使用中，我也见过直接修改源码，把自定义的后处理跟内置的后处理写到一起的，这是可行了。但考虑到这只是一个练习的项目，尽量不去修改源码。本篇采用的方式，是使用Renderfeature实现后处理。</p>
<h3 id="自定义renderfeature">(1)自定义Renderfeature</h3>
<p>首先创建Renderfeature，这样就可以在管线配置文件中设置自定义的Renderfeature了。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> UnityEngine.Experiemntal.Rendering.Universal;</span><br><span class="line"><span class="keyword">using</span> UnityEngine.Rendering.Universal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">PrintDepthMapRendererFeature</span> : <span class="title">ScriptableRendererFeature</span></span><br><span class="line">&#123;</span><br><span class="line">    PrintDepthMapPass m_ScriptablePass;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">Create</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        m_ScriptablePass = <span class="keyword">new</span> PrintDepthMapPass();</span><br><span class="line">        m_ScriptablePass.renderPassEvent = RenderPassEvent.AfterRenderingPostProcessing;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">AddRenderPasses</span>(<span class="params">ScriptableRenderer renderer, <span class="keyword">ref</span> RenderingData renderingData</span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        <span class="keyword">var</span> dest = RenderTargetHandle.CameraTarget;</span><br><span class="line">        m_ScriptablePass.Setup(renderer.cameraColorTarget, dest);</span><br><span class="line">        renderer.EnqueuePass(m_ScriptablePass);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202075541.png" /></p>
<h3 id="自定义scriptablerenderpass">(2)自定义ScriptableRenderPass</h3>
<p>可以发现，上面的代码PrintDepthMapPass还没有定义，这是具体的后处理部分，类似Build
in管线中的OnRenderImage方法。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> UnityEngine.Rendering;</span><br><span class="line"><span class="keyword">using</span> UnityEngine.Rendering.Universal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">UnityEngine.Experiemntal.Rendering.Universal</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">PrintDepthMapPass</span> : <span class="title">ScriptableRenderPass</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">readonly</span> <span class="built_in">string</span> k_RenderTag = <span class="string">&quot;Print Depth Map&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> PrintDepthMap printDepthMap;</span><br><span class="line">        <span class="keyword">private</span> Material depthMapMat;</span><br><span class="line"></span><br><span class="line">        RenderTargetIdentifier currentTarget;</span><br><span class="line">        <span class="keyword">private</span> RenderTargetHandle destination &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">PrintDepthMapPass</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            <span class="keyword">var</span> shader = Shader.Find(<span class="string">&quot;RoadOfShader/1.3-Depth/Print Depth Map&quot;</span>);</span><br><span class="line">            depthMapMat = CoreUtils.CreateEngineMaterial(shader);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">Execute</span>(<span class="params">ScriptableRenderContext context, <span class="keyword">ref</span> RenderingData renderingData</span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            <span class="keyword">if</span> (depthMapMat == <span class="literal">null</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                UnityEngine.Debug.LogError(<span class="string">&quot;材质没找到！&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!renderingData.cameraData.postProcessEnabled) <span class="keyword">return</span>;</span><br><span class="line">            <span class="comment">//通过队列来找到HologramBlock组件，然后</span></span><br><span class="line">            <span class="keyword">var</span> stack = VolumeManager.instance.stack;</span><br><span class="line">            printDepthMap = stack.GetComponent&lt;PrintDepthMap&gt;();</span><br><span class="line">            <span class="keyword">if</span> (printDepthMap == <span class="literal">null</span>) &#123; <span class="keyword">return</span>; &#125;</span><br><span class="line">            <span class="keyword">if</span> (!printDepthMap.IsActive()) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">var</span> cmd = CommandBufferPool.Get(k_RenderTag);</span><br><span class="line">            Render(cmd, <span class="keyword">ref</span> renderingData);</span><br><span class="line">            context.ExecuteCommandBuffer(cmd);</span><br><span class="line">            CommandBufferPool.Release(cmd);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">Render</span>(<span class="params">CommandBuffer cmd, <span class="keyword">ref</span> RenderingData renderingData</span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            <span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) <span class="keyword">return</span>;</span><br><span class="line">            <span class="keyword">var</span> source = currentTarget;</span><br><span class="line"></span><br><span class="line">            Blit(cmd, source, destination.Identifier(), depthMapMat);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Setup</span>(<span class="params"><span class="keyword">in</span> RenderTargetIdentifier currentTarget, RenderTargetHandle dest</span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            <span class="keyword">this</span>.destination = dest;</span><br><span class="line">            <span class="keyword">this</span>.currentTarget = currentTarget;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Renderfeature通过调用Setup方法传递数据进来。主要的逻辑是在Execute中实现了，类似于Build
in管线中的OnRenderImage方法。</p>
<h3 id="实现shader">(3)实现Shader</h3>
<p>可以发现，在上面的实现中，会查找Shader来生成一个材质。最后一步要做的，就是实现自己的Shader。这一部分没太多可说的，就是平常的实现Shader的步骤，此处不再赘述。</p>
<h1 id="四从深度图重建世界坐标">四、从深度图重建世界坐标</h1>
<p>利用覆盖满屏幕的UV值和深度纹理中的深度值，我们可以重新计算出物体在世界空间中的坐标。主要有以下两种实现方式。</p>
<h2 id="利用vp逆矩阵重建">1、利用VP逆矩阵重建</h2>
<p>将顶点从世界空间转换到裁剪空间，需要经过VP的变换。由于这个变换是可逆的，所以我们可以使用VP的逆矩阵，将顶点从裁剪空间变换到世界空间。</p>
<p>首先，需要在C#中将VP逆矩阵传递给Shader。这一步可以在自定义的ScriptableRenderPass的Execute中实现。</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">var</span> camera = renderingData.cameraData.camera;</span><br><span class="line"><span class="built_in">var</span> proj = camera.projectionMatrix;</span><br><span class="line"><span class="built_in">var</span> <span class="built_in">view</span> = camera.worldToCameraMatrix;</span><br><span class="line"><span class="built_in">var</span> viewProj = proj * <span class="built_in">view</span>;</span><br><span class="line"></span><br><span class="line">customMotionBlurMat.SetMatrix(<span class="string">&quot;_CurrentInverseVP&quot;</span>, viewProj.inverse);</span><br></pre></td></tr></table></figure>
<p>然后，在片元着色器中，可以根据UV值和深度值重建出NDC坐标。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> depth = SampleSceneDepth(input.uv);</span><br><span class="line"><span class="attribute">float4</span> HCoord = float<span class="number">4</span>(input.uv.x * <span class="number">2</span> -<span class="number">1</span>,input.uv.y * <span class="number">2</span> -<span class="number">1</span>,depth * <span class="number">2</span> -<span class="number">1</span> ,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>最后，可以使用VP逆矩阵，将坐标从NDC坐标转换到世界坐标。</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>4 currentPos = HCoord;</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span>4 D = mul(_CurrentInverseVP,HCoord);</span><br><span class="line"><span class="built_in">float</span>4 positionWS = D / D.w;</span><br></pre></td></tr></table></figure>
<p>具体过程，可以到CustomMotionBlurPass实例中查看。</p>
<h2 id="利用方向向量重建">2、利用方向向量重建</h2>
<p>深度纹理，是一张和屏幕分辨率相同的纹理。而屏幕中所看到的，可以认为是相机的近裁剪平面。所以，深度纹理的四个顶点，可以认为和相机的近裁剪平面的四个点重合的。</p>
<h3 id="计算近裁剪平面的宽高">(1)计算近裁剪平面的宽、高。</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202221109.png" /></p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> tanHalfFOV = Mathf.<span class="constructor">Tan(0.5f <span class="operator">*</span> <span class="params">cam</span>.<span class="params">fieldOfView</span> <span class="operator">*</span> Mathf.Deg2Rad)</span>;</span><br><span class="line"><span class="built_in">float</span> halfHeight = tanHalfFOV<span class="operator"> * </span>cam.nearClipPlane;</span><br><span class="line"><span class="built_in">float</span> halfWidth = halfHeight<span class="operator"> * </span>cam.aspect;</span><br></pre></td></tr></table></figure>
<h3 id="计算相机到四个顶点的向量">(2)计算相机到四个顶点的向量</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202221133.png" /></p>
<figure class="highlight pf"><table><tr><td class="code"><pre><span class="line">Vector3 <span class="keyword">to</span>Top = cam.transform.up * halfHeight;</span><br><span class="line">Vector3 <span class="keyword">to</span>Right = cam.transform.right * halfWidth;</span><br><span class="line">Vector3 forward = cam.transform.forward * cam.nearClipPlane;</span><br><span class="line">Vector3 <span class="keyword">to</span>TopLeft = forward + <span class="keyword">to</span>Top - <span class="keyword">to</span>Right;</span><br><span class="line">Vector3 <span class="keyword">to</span>BottomLeft = forward - <span class="keyword">to</span>Top - <span class="keyword">to</span>Right;</span><br><span class="line">Vector3 <span class="keyword">to</span>TopRight = forward + <span class="keyword">to</span>Top + <span class="keyword">to</span>Right;</span><br><span class="line">Vector3 <span class="keyword">to</span>BottomRight = forward - <span class="keyword">to</span>Top + <span class="keyword">to</span>Right;</span><br></pre></td></tr></table></figure>
<h3 id="传递给shader">(3)传递给Shader</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202221229.png" /></p>
<p>如上图所示，假设有个绿点在toTopLeft所在方向上，根据相似三角形，可以得到：
<span class="math display">\[
toGreen / depth = toTopLeft / near
\]</span>
上式中，toTopLeft、near都是已知的，而depth可以在Shader中采样深度纹理获得。所以只需要传递<span
class="math inline">\(toTopLeft /
near\)</span>给Shader即可计算出toGreen。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">toTopLeft /= cam.nearClipPlane;</span><br><span class="line">toBottomLeft /= cam.nearClipPlane;</span><br><span class="line">toTopRight /= cam.nearClipPlane;</span><br><span class="line">toBottomRight /= cam.nearClipPlane;</span><br><span class="line"></span><br><span class="line">Matrix4x4 frustumDir = <span class="module-access"><span class="module"><span class="identifier">Matrix4x4</span>.</span></span>identity;</span><br><span class="line">frustumDir.<span class="constructor">SetRow(0, <span class="params">toBottomLeft</span>)</span>;</span><br><span class="line">frustumDir.<span class="constructor">SetRow(1, <span class="params">toBottomRight</span>)</span>;</span><br><span class="line">frustumDir.<span class="constructor">SetRow(2, <span class="params">toTopLeft</span>)</span>;</span><br><span class="line">frustumDir.<span class="constructor">SetRow(3, <span class="params">toTopRight</span>)</span>;</span><br><span class="line">verticalFogMat.<span class="constructor">SetMatrix(<span class="string">&quot;_FrustumDir&quot;</span>, <span class="params">frustumDir</span>)</span>;</span><br></pre></td></tr></table></figure>
<h3
id="在vertex中判断对应顶点所在的向量">(4)在Vertex中判断对应顶点所在的向量</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202221913.png" /></p>
<p>这里需要注意一下，在上面一个步骤传递矩阵给Shader时，构造矩阵的顺序。</p>
<p>可以看到，UV值和对应的索引值正好是二进制的关系，所以可以得出：</p>
<figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ix = (<span class="keyword">int</span>)<span class="keyword">output</span><span class="variable">.uv</span><span class="variable">.x</span>;</span><br><span class="line"><span class="keyword">int</span> iy = (<span class="keyword">int</span>)<span class="keyword">output</span><span class="variable">.uv</span><span class="variable">.y</span>;</span><br><span class="line"><span class="keyword">output</span><span class="variable">.frustumDir</span> = <span class="number">_</span>FrustumDir[ix + <span class="number">2</span> * iy];</span><br></pre></td></tr></table></figure>
<p>看完上述内容，可能有些疑惑：上面只是求出四个顶点的向量，怎么能得出每个像素的向量的呢？这是因为，从顶点着色器到片元着色器，是经过插值的，这样，就可以根据四个顶点的向量，插值得出每个像素的向量。</p>
<p>然后，就可以在片元着色器中重建世界坐标了。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> depth = <span class="constructor">SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line"><span class="built_in">float</span> linearEyeDepth = <span class="constructor">LinearEyeDepth(<span class="params">depth</span>, <span class="params">_ZBufferParams</span>)</span>;</span><br><span class="line"></span><br><span class="line">float3 positionWS = <span class="constructor">GetCameraPositionWS()</span> + input.frustumDir.xyz<span class="operator"> * </span>linearEyeDepth;</span><br></pre></td></tr></table></figure>
<p>具体的实现，可以在垂直雾效的例子中找到。</p>
<h1 id="五实例">五、实例</h1>
<h2 id="渲染深度图">1、渲染深度图</h2>
<p>这里需要使用后处理来渲染深度图。</p>
<p>按照上面提到的后处理的流程，需要新建一下四个脚本：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202222959.png" /></p>
<p>在Shader中，采样深度图，转化为<span
class="math inline">\([0,1]\)</span>范围的深度值，输出即可。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> depth = <span class="constructor">SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line"><span class="built_in">float</span> linear01Depth = <span class="constructor">Linear01Depth(<span class="params">depth</span>, <span class="params">_ZBufferParams</span>)</span>;</span><br><span class="line"></span><br><span class="line">return linear01Depth;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221453.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.1-PrintDepthMap.shader">代码</a></p>
<h2 id="相交高亮">2、相交高亮</h2>
<p>思路就是判断当前片元的深度值与深度纹理中对应的深度值是否在一定的范围内，如果是的话，就判定为相交。</p>
<p>首先，肯定要在顶点着色器中计算顶点的深度值，传递给片元着色器。然后，由于不需要后处理，所以需要把顶点的屏幕坐标传递给片元着色器。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Vert</span></span><br><span class="line">output.positionScreen = vertexInput.positionNDC;</span><br><span class="line">output.eyeZ = -vertexInput.positionVS.z;</span><br><span class="line">                </span><br><span class="line"><span class="comment">//Frag</span></span><br><span class="line"><span class="built_in">float</span> screenZ = <span class="constructor">LinearEyeDepth(SampleSceneDepth(<span class="params">input</span>.<span class="params">positionScreen</span>.<span class="params">xy</span> <span class="operator">/</span> <span class="params">input</span>.<span class="params">positionScreen</span>.<span class="params">w</span>)</span>, _ZBufferParams);</span><br></pre></td></tr></table></figure>
<p>最后，在片元着色器中进行相交判断。</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> halfWidth = _IntersectionWidth / <span class="number">2</span>;</span><br><span class="line"><span class="built_in">float</span> <span class="built_in">diff</span> = saturate(<span class="built_in">abs</span>(input.eyeZ - screenZ) / halfWidth);</span><br><span class="line"></span><br><span class="line">half4 finalColor = lerp(_IntersectionColor, <span class="built_in">color</span>, <span class="built_in">diff</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221514.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.2-IntersectionHighlight.shader">代码</a></p>
<h2 id="能量场">3、能量场</h2>
<p>在相交高亮的基础上，加上<strong>半透明</strong>和<strong>边缘高亮</strong>，就能制造出一个简单的能量场效果。</p>
<p>首先，计算相交部分的数值。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> screenZ = <span class="constructor">LinearEyeDepth(SampleSceneDepth(<span class="params">input</span>.<span class="params">positionScreen</span>.<span class="params">xy</span> <span class="operator">/</span> <span class="params">input</span>.<span class="params">positionScreen</span>.<span class="params">w</span>)</span>, _ZBufferParams);</span><br><span class="line"><span class="built_in">float</span> intersect = (<span class="number">1</span> - (screenZ - input.eyeZ))<span class="operator"> * </span>_IntersectionPower;</span><br></pre></td></tr></table></figure>
<p>然后，计算<strong>边缘高亮</strong>的数值。</p>
<figure class="highlight glsl"><table><tr><td class="code"><pre><span class="line">float3 normalWS = <span class="built_in">normalize</span>(input.normalWS);</span><br><span class="line">float3 viewDirWS = <span class="built_in">normalize</span>(input.viewDirWS);</span><br><span class="line"><span class="type">float</span> rim = <span class="number">1</span> - saturate(<span class="built_in">dot</span>(normalWS, viewDirWS)) * _RimPower;</span><br></pre></td></tr></table></figure>
<p>取二者之中的较大值，乘以颜色值。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> v <span class="operator">=</span> <span class="built_in">max</span>(rim, <span class="keyword">intersect</span>);</span><br><span class="line"></span><br><span class="line">half4 finalColor <span class="operator">=</span> _MainColor <span class="operator">*</span> v;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> finalColor;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221605.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.3-ForceField.shader">代码</a></p>
<h2 id="全局雾效">4、全局雾效</h2>
<p>思路是让雾的浓度随着深度值的增大而增大，然后进行原图颜色和雾颜色的插值。</p>
<p>这里需要使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202225037.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221632.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.4-Fog.shader">代码</a></p>
<h2 id="扫描线">5、扫描线</h2>
<p>思路与相交高亮效果类似，只是这里需要使用后处理。自定义一个<span
class="math inline">\([0,1]\)</span>范围变化的变量_CurValue，根据_CurValue与深度值的差进行颜色的插值。</p>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202225515.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221658.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.5-ScanLine.shader">代码</a></p>
<h2 id="水淹">6、水淹</h2>
<p>思路是：利用方向向量重建世界坐标，判断该坐标的Y值是否在给定的阈值下，如果是，则混合原图颜色和水的颜色。</p>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202230021.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221720.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.6-WaterFlooded.shader">代码</a></p>
<h2 id="垂直雾效">7、垂直雾效</h2>
<p>思路是：利用方向向量重建世界坐标，让雾的浓度随着Y值变化。</p>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202230315.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221748.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.7-VerticalFog.shader">代码</a></p>
<h2 id="边缘检测">8、边缘检测</h2>
<p>思路是：取当前像素上下、左右相邻的四个像素，分别计算出上下、左右像素的深度值差异，将两个深度值差异相乘就得到我们判断边缘的值。</p>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201202230756.png" /></p>
<p>首先，在顶点着色器中，计算上下、左右相邻像素的UV值，传递给片元着色器中。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Robers算子</span></span><br><span class="line">output.uv<span class="literal">[<span class="number">1</span>]</span> = uv + <span class="module-access"><span class="module"><span class="identifier">_MainTex_TexelSize</span>.</span></span>xy<span class="operator"> * </span>float2(-<span class="number">1</span>, -<span class="number">1</span>);</span><br><span class="line">output.uv<span class="literal">[<span class="number">2</span>]</span> = uv + <span class="module-access"><span class="module"><span class="identifier">_MainTex_TexelSize</span>.</span></span>xy<span class="operator"> * </span>float2(-<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">output.uv<span class="literal">[<span class="number">3</span>]</span> = uv + <span class="module-access"><span class="module"><span class="identifier">_MainTex_TexelSize</span>.</span></span>xy<span class="operator"> * </span>float2(<span class="number">1</span>, -<span class="number">1</span>);</span><br><span class="line">output.uv<span class="literal">[<span class="number">4</span>]</span> = uv + <span class="module-access"><span class="module"><span class="identifier">_MainTex_TexelSize</span>.</span></span>xy<span class="operator"> * </span>float2(<span class="number">1</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>然后，在片元着色器中，可以根据上面的UV值采样深度纹理得到深度值。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> sample1 = <span class="constructor">Linear01Depth(SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>[1])</span>, _ZBufferParams);</span><br><span class="line"><span class="built_in">float</span> sample2 = <span class="constructor">Linear01Depth(SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>[2])</span>, _ZBufferParams);</span><br><span class="line"><span class="built_in">float</span> sample3 = <span class="constructor">Linear01Depth(SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>[3])</span>, _ZBufferParams);</span><br><span class="line"><span class="built_in">float</span> sample4 = <span class="constructor">Linear01Depth(SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>[4])</span>, _ZBufferParams);</span><br></pre></td></tr></table></figure>
<p>最后，就是根据两个差异值相乘得到判断边缘的值。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> edge <span class="operator">=</span> <span class="number">1.0</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>对角线的差异相乘</span><br><span class="line">edge <span class="operator">*</span><span class="operator">=</span> <span class="built_in">abs</span>(sample1 <span class="operator">-</span> sample4) <span class="operator">&lt;</span> _EdgeThreshold ? <span class="number">1.0</span>: <span class="number">0.0</span>;</span><br><span class="line">edge <span class="operator">*</span><span class="operator">=</span> <span class="built_in">abs</span>(sample2 <span class="operator">-</span> sample3) <span class="operator">&lt;</span> _EdgeThreshold ? <span class="number">1.0</span>: <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> edge;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221819.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.8-EdgeDetection.shader">代码</a></p>
<h2 id="运动模糊">9、运动模糊</h2>
<p>运动模糊在游戏中主要用来体现速度感。下面要实现的运动模糊，只适用于<strong>物体不同，相机移动</strong>的情形。</p>
<p>思路：</p>
<p>(1). 重建运动后的NDC坐标，然后利用VP逆矩阵重建世界坐标；</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> depth = SampleSceneDepth(<span class="keyword">input</span>.uv);</span><br><span class="line"><span class="type">float4</span> HCoord = <span class="type">float4</span>(<span class="keyword">input</span>.uv.x * <span class="number">2</span> <span class="number">-1</span>,<span class="keyword">input</span>.uv.y * <span class="number">2</span> <span class="number">-1</span>,depth * <span class="number">2</span> <span class="number">-1</span> ,<span class="number">1</span>);</span><br><span class="line"><span class="type">float4</span> currentPos = HCoord;</span><br><span class="line"></span><br><span class="line"><span class="type">float4</span> D = mul(_CurrentInverseVP,HCoord);</span><br><span class="line"><span class="type">float4</span> positionWS = D / D.w;</span><br></pre></td></tr></table></figure>
<p>(2).
由于物体是不动的，可以根据上面重建得到的世界坐标、记录下来的上次的VP矩阵，得到运动前的NDC坐标；</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float4</span> <span class="literal">last</span>Pos = mul(_LastVP,positionWS);</span><br><span class="line"><span class="attribute">lastPos</span> /= <span class="literal">last</span>Pos.w;</span><br></pre></td></tr></table></figure>
<p>(3).
利用运动前后的NDC坐标，可以计算出速度向量，在该向量上多次采样、模糊即可。</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">float2 velocity = (currentPos - lastPos).xy / <span class="number">2.0</span>;</span><br><span class="line"></span><br><span class="line">half4 col = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, <span class="keyword">input</span>.uv);</span><br><span class="line"></span><br><span class="line">float2 uv = <span class="keyword">input</span>.uv;</span><br><span class="line">uv += velocity;</span><br><span class="line"><span class="type">int</span> numSamples = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> <span class="keyword">index</span> = <span class="number">1</span>; <span class="keyword">index</span> &lt; numSamples;<span class="keyword">index</span>++,uv+=velocity)</span><br><span class="line">&#123;</span><br><span class="line">	col += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">col /= numSamples;</span><br></pre></td></tr></table></figure>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203213935.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221841.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.9-CustomMotionBlur.shader">代码</a></p>
<h2 id="景深">10、景深</h2>
<p>景深，是一种聚焦处清晰，其它处模糊的效果。</p>
<p>思路：先渲染一张模糊的图；然后在深度纹理中找到聚焦点出对应的深度值，该深度附近用原图，其它地方渐变至模糊图。</p>
<p>(1). 使用SimpleBlur
Shader渲染模糊的图，这里只是简单的采样当前像素附近的9个像素然后平均，你也可以选择其它模糊算法。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Vert</span></span><br><span class="line">output.uv[<span class="number">0</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(-<span class="number">1</span>, -<span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">1</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(-<span class="number">1</span>, <span class="number">0</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">2</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(-<span class="number">1</span>, <span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">3</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">0</span>, -<span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">4</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">0</span>, <span class="number">0</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">5</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">0</span>, <span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">6</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">1</span>, -<span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">7</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">1</span>, <span class="number">0</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">output.uv[<span class="number">8</span>] = uv + <span class="variable">_MainTex_TexelSize</span>.xy * float2(<span class="number">1</span>, <span class="number">1</span>) * <span class="variable">_BlurLevel</span>;</span><br><span class="line">                </span><br><span class="line"><span class="comment">//Frag</span></span><br><span class="line">half4 col = SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">0</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">1</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">2</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">3</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">4</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">5</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">6</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">7</span>]);</span><br><span class="line">col += SAMPLE_TEXTURE2D(<span class="variable">_MainTex</span>, sampler_MainTex, input.uv[<span class="number">8</span>]);</span><br><span class="line"></span><br><span class="line">col /= <span class="number">9</span>;</span><br></pre></td></tr></table></figure>
<p>(2). 传递上面生成的模糊的图给DepthOfField Shader；</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">cmd.<span class="constructor">GetTemporaryRT(<span class="params">blurTex</span>, <span class="params">m_Descriptor</span>, FilterMode.Bilinear)</span>;</span><br><span class="line"></span><br><span class="line">var blurLevel = customDepthOfField.<span class="module-access"><span class="module"><span class="identifier">_BlurLevel</span>.</span></span>value;</span><br><span class="line">simpleBlurMat.<span class="constructor">SetFloat(<span class="string">&quot;_BlurLevel&quot;</span>, <span class="params">blurLevel</span>)</span>;</span><br><span class="line"><span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">blurTex</span>, <span class="params">simpleBlurMat</span>)</span>;</span><br><span class="line">cmd.<span class="constructor">SetGlobalTexture(<span class="params">blurTex</span>, <span class="params">blurTex</span>)</span>;</span><br></pre></td></tr></table></figure>
<p>(3). 根据焦点混合原图颜色好模糊图颜色。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">half4 blurCol = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_BlurTex</span>, <span class="params">sampler_BlurTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">float</span> linear01Depth = <span class="constructor">Linear01Depth(SampleSceneDepth(<span class="params">input</span>.<span class="params">uv</span>)</span>, _ZBufferParams);</span><br><span class="line"><span class="built_in">float</span> v = saturate(abs(linear01Depth - _FocusDistance)<span class="operator"> * </span>_FocusLevel);</span><br><span class="line"></span><br><span class="line">return lerp(col, blurCol, v);</span><br></pre></td></tr></table></figure>
<p>这里使用后处理，需要新建以下脚本。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203215244.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-01/20201203221908.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.3-Depth/Shader/1.3.10-CustomDepthOfField.shader">代码</a></p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://www.jianshu.com/p/80a932d1f11e">Unity Shader -
深度图基础及应用</a></li>
<li>[2] 《Unity Shader入门精要​》</li>
<li>[3] <a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a></li>
<li>[4] <a href="https://zhuanlan.zhihu.com/p/161658349">如何扩展Unity
URP的后处理Volume组件</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Depth Map</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(五)：程序化生成多边形</title>
    <url>/2020/12/05/2020-12-05-%EF%BC%88%E4%BA%94%EF%BC%89%E7%A8%8B%E5%BA%8F%E5%8C%96%E7%94%9F%E6%88%90%E5%A4%9A%E8%BE%B9%E5%BD%A2/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本篇是“练习项目”系列的第五篇，主要练习程序化生成各种多边形的例子。这一篇博客，主要都是一些数学知识，这里推荐一个软件：GeoGebra。这个软件可以很方便地画出各种函数的几何表示，对于问题的分析很有帮助。<span id="more"></span></p>
<h1 id="实例">实例</h1>
<h2 id="圆形">1、圆形</h2>
<p>在UV坐标系中，根据给定的圆心和半径，判断当前片元的UV值到圆心的距离是否小于半径。</p>
<p>主要的代码如下：</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> Circle(float2 <span class="built_in">center</span>, <span class="built_in">float</span> <span class="built_in">radius</span>, float2 uv)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">return</span> <span class="number">1</span> - <span class="keyword">step</span>(<span class="built_in">radius</span>, distance(uv, <span class="built_in">center</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里对step方法不熟悉的话，可以查一下资料。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205202121.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.1-Circle.shader">代码</a></p>
<h2 id="柔和的圆形">2、柔和的圆形</h2>
<p>可以看到，上面白色区域与黑色区域的交界非常尖锐，下面会对边界做柔和操作。</p>
<p>主要的改变，就是不再使用step方法，而是使用smoothstep方法。这样，可以在边界处柔和混合两种颜色。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> <span class="constructor">SmoothCircle(<span class="params">float2</span> <span class="params">center</span>, <span class="params">float</span> <span class="params">radius</span>, <span class="params">float</span> <span class="params">smoothWidth</span>, <span class="params">float2</span> <span class="params">uv</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	return <span class="number">1</span> - smoothstep(radius - smoothWidth, radius, distance(uv, center));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对smoothstep方法不熟悉的，可以查一下其它资料。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205202446.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.2-SmoothCircle.shader">代码</a></p>
<h2 id="多边形">3、多边形</h2>
<p>这里比较复杂，需要比较多的运算变换，下面一步步来介绍。注意，这里以三角形为例，其它多边形原理相同。</p>
<p>原始的UV坐标系，U和V的值域为<span
class="math inline">\([0,1]\)</span>，如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205202718.png" /></p>
<p>将值域从<span class="math inline">\([0,1]\)</span>变换到<span
class="math inline">\([-1,1]\)</span>。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">input</span>.uv = input.uv * <span class="number">2</span> - <span class="number">1</span>; //[-<span class="number">1</span>, <span class="number">1</span>]，(<span class="number">0</span>,<span class="number">0</span>)在正中心</span><br></pre></td></tr></table></figure>
<p>此时，UV坐标系如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205203102.png" /></p>
<p>将直角坐标系转化为极坐标系。</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">float <span class="keyword">a</span> = <span class="built_in">atan2</span>(input.uv.y, input.uv.x) + <span class="literal">PI</span>;<span class="comment"> //[0, 2π]，将整个界面变成角度分布（极坐标系）</span></span><br></pre></td></tr></table></figure>
<p>这里要注意 ，atan2函数返回的是原点至点(x,y)的方位角，即与 x
轴的夹角。返回值的单位为弧度，取值范围为<span
class="math inline">\([-\pi,\pi]\)</span>。这里，加上PI是为了把值域转化到<span
class="math inline">\([0,\pi]\)</span>。</p>
<p>对于UV坐标<span
class="math inline">\((1,1)\)</span>来说，相当于逆时针旋转<span
class="math inline">\(\pi\)</span>弧度，向量<span
class="math inline">\(u\)</span>旋转到了向量<span
class="math inline">\(v\)</span>。如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205203849.png" /></p>
<p>根据多边形的变数，把整个圆周均分，得出每条边对于的弧度。</p>
<figure class="highlight processing"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> r = (<span class="number">2</span> * <span class="literal">PI</span>) / <span class="built_in">float</span>(_Num); <span class="comment">//一条边对应的角度（中心连接边的两个端点）</span></span><br></pre></td></tr></table></figure>
<p>对于三角形，如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205204305.png" /></p>
<p>下面，需要计算向量<span
class="math inline">\(v\)</span>在最近的一条分界边的投影。</p>
<p>先计算经过了几条边：<span class="math inline">\(a/r\)</span>。</p>
<p>向上取整：<span class="math inline">\(floor(0.5 + a/r)\)</span>。</p>
<p>计算经过的几条边的所有弧度：<span class="math inline">\(floor(0.5 +
a/r) * r\)</span>。</p>
<p>计算向量<span
class="math inline">\(v\)</span>到最近的一条分界边的弧度：<span
class="math inline">\(floor(0.5 + a/r) * r - a\)</span>。</p>
<p>计算夹角的余弦值：<span class="math inline">\(cos(floor(0.5 + a/r) *
r - a)\)</span>。</p>
<p>得到向量<span class="math inline">\(v\)</span>在分界边上的投影：<span
class="math inline">\(cos(floor(0.5 + a/r) * r - a) *
length(input.uv)\)</span>。</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> d = cos(floor(<span class="number">0.5</span> + a / r) * r - a) * length(<span class="keyword">input</span>.uv);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205204438.png" /></p>
<p>得到投影距离后，与配置的size比较，判断是否在多边形范围内。</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line">half3 <span class="built_in">col</span> = <span class="number">1</span> - <span class="keyword">step</span>(_Size, d);</span><br></pre></td></tr></table></figure>
<p>此时，得到的多边形如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205205627.png" /></p>
<p>这样看起来有点不太舒服，翻转XY轴，可以得到如下效果：</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> a = atan2(<span class="keyword">input</span>.uv.x, <span class="keyword">input</span>.uv.y) + PI;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205205826.png" /></p>
<p>最终的效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205205909.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.3-Polygon.shader">代码</a></p>
<h2 id="矩形">4、矩形</h2>
<p>这里比较简单，添加一个Vector类型的属性接口，x、y、z、w分别代表矩形区域的四条边与UV四条边的距离。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201206221617.png" /></p>
<p>一个片元到四条边的距离必须都满足条件，才认为在矩形内部。</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line">//<span class="built_in">border</span> : (left, right, bottom, top), all should be [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">float</span> Rect(float4 <span class="built_in">border</span>, float2 uv)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">float</span> v1 = <span class="keyword">step</span>(<span class="built_in">border</span>.x, uv.x);</span><br><span class="line">	<span class="built_in">float</span> v2 = <span class="keyword">step</span>(<span class="built_in">border</span>.y, <span class="number">1</span> - uv.x);</span><br><span class="line">	<span class="built_in">float</span> v3 = <span class="keyword">step</span>(<span class="built_in">border</span>.z, uv.y);</span><br><span class="line">	<span class="built_in">float</span> v4 = <span class="keyword">step</span>(<span class="built_in">border</span>.w, <span class="number">1</span> - uv.y);</span><br><span class="line">	<span class="built_in">return</span> v1 * v2 * v3 * v4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201205215002.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.4-Rect.shader">代码</a></p>
<h2 id="直线">5、直线</h2>
<p>一般直线的方程是<span class="math inline">\(y = kx +
b\)</span>，根据给定的两点<span
class="math inline">\((x_1,y_1)\)</span>、<span
class="math inline">\((x_2,y_2)\)</span>，可以分别求出<span
class="math inline">\(k\)</span>、<span
class="math inline">\(b\)</span>： <span class="math display">\[
\begin{cases}
k = (y_2 - y_1)/(x_2 - x_1) \\
b = y_1 - k * x_1 \\
\end{cases}
\]</span> 下一步，就是求平面任意一点到直线的垂直距离。如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201206222444.png" /></p>
<p>直线与X轴正方形的夹角为<span
class="math inline">\(\beta\)</span>，根据相似三角形法则，可以求得：<span
class="math inline">\(cos(\beta) = 1/\sqrt{k^2+1}\)</span>。</p>
<p>同样，根据等角原理，<span class="math inline">\(\gamma =
\beta\)</span>，所以<span class="math inline">\(cos(\gamma) =
cos(\beta)\)</span>。</p>
<p>而任意一点距离直线的距离为<span
class="math inline">\(i\)</span>，距离直线的垂直距离为<span
class="math inline">\(g\)</span>，所以可以求得<span
class="math inline">\(i = g * cos(\gamma)\)</span>。</p>
<p>最后，根据上面求出的距离<span
class="math inline">\(i\)</span>与配置的直线的宽度比较，可以判断一个点是否在直线上。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> k = (point<span class="number">1</span>.y - point<span class="number">2</span>.y) / (point<span class="number">1</span>.x - point<span class="number">2</span>.x);</span><br><span class="line"><span class="attribute">float</span> b = point<span class="number">1</span>.y - k * point<span class="number">1</span>.x;</span><br><span class="line"></span><br><span class="line"><span class="attribute">float</span> d = abs(k * uv.x - uv.y + b) / sqrt(k * k + <span class="number">1</span>);</span><br><span class="line"><span class="attribute">float</span> t = smoothstep(width/<span class="number">2</span>.<span class="number">0</span>, width/<span class="number">2</span>.<span class="number">0</span> + aa, d);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201206223809.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.5-Line.shader">代码</a></p>
<h2 id="线段">6、线段</h2>
<p>与上面画直线的原理相同，只是需要根据给定的两点的坐标，把直线“截断”。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207084106.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.6-LineSegment.shader">代码</a></p>
<h2 id="方程">7、方程</h2>
<p>与上面画直线、线段的思路类似。不过上面是先根据两点计算出直线的方程，这里是直接给出曲线的方程。判断平面上一点是否在曲线上，这里只是简单比较垂直方向的距离，所以曲线的粗细不一致。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> <span class="constructor">Equation(<span class="params">float2</span> <span class="params">uv</span>, <span class="params">float</span> <span class="params">kx</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	return smoothstep(kx - <span class="number">0.01</span>, kx, uv.y) - smoothstep(kx, kx + <span class="number">0.01</span>, uv.y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207220055.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.7-Equation.shader">代码</a></p>
<h2 id="点">8、点</h2>
<p>给定一个坐标点和尺寸，判断平面上任意一点是否在区域内。思路是分别判断x、y到坐标点的距离是否都在范围内，只有都在范围内，才认为点在区域内。</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">Point</span><span class="params">(float2 position, <span class="keyword">float</span> size, float2 uv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	float2 v = <span class="number">1</span> - <span class="built_in">step</span>(size / <span class="number">2.0</span>, <span class="built_in">abs</span>(uv - position.xy));</span><br><span class="line">	<span class="keyword">return</span> v.x * v.y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207220545.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.8-Point.shader">代码</a></p>
<h2 id="同心圆">9、同心圆</h2>
<p>这里先介绍一下<span class="math inline">\(frac\)</span>函数。<span
class="math inline">\(frac\)</span>函数返回标量或每个矢量中各分量的小数部分。观察下图可以发现，对于函数<span
class="math inline">\(frac(ax)\)</span>，随着<span
class="math inline">\(a\)</span>的增大，线条逐渐变密。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207221807.gif" /></p>
<p>先求出平面上一点距离圆心的距离，然后以距离作为上面的变量<span
class="math inline">\(x\)</span>，以配置的同心圆的数量作为上面的变量<span
class="math inline">\(a\)</span>，当同心圆数量为10时，可以得到下面的图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207222535.png" /></p>
<p>可以发现，圆环与圆环之间区域的颜色是有过度的，可以对上面的结果使用<span
class="math inline">\(Step\)</span>函数截取，非黑即白。如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207222721.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.9-ConcentricCircle.shader">代码</a></p>
<h2 id="多个圆">10、多个圆</h2>
<p>同样是利用<span
class="math inline">\(frac\)</span>函数。平面上点的X、Y方向的范围都是<span
class="math inline">\([0,1]\)</span>，经过<span
class="math inline">\(frac\)</span>作用后，随着圆的数量的变换如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207225158.gif" /></p>
<p>相当于对UV坐标做了<span
class="math inline">\(Scale\)</span>变换。此时，再根据圆心和半径判断一个点是否在圆内。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">float2 st = frac(input.uv<span class="operator"> * </span>_Num);</span><br><span class="line">half3 col = <span class="constructor">Circle(<span class="params">_Center</span>, <span class="params">_Radius</span>, <span class="params">st</span>)</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> Circle(float2 <span class="built_in">center</span>, <span class="built_in">float</span> <span class="built_in">radius</span>, float2 uv)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">return</span> <span class="number">1</span> - <span class="keyword">step</span>(<span class="built_in">radius</span>, distance(uv, <span class="built_in">center</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201207225542.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.10-MultiCircle.shader">代码</a></p>
<h2 id="多个同心圆">11、多个同心圆</h2>
<p>这个比较简单，先执行上面“多个圆”的操作，再执行上面“同心圆”的操作，即可得到效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208221440.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.11-MultiConcentricCircle.shader">代码</a></p>
<h2 id="同心圆1">12、同心圆（1）</h2>
<p>首先，在9、同心圆的基础上修改圆心为<span
class="math inline">\((0.3,0.3)\)</span>，不进行<span
class="math inline">\(step\)</span>操作，可得到如下图像：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208222331.png" /></p>
<p>然后，将UV坐标从<span class="math inline">\([0,1]\)</span>映射到<span
class="math inline">\([-1,-1]\)</span>，即执行：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float2</span> st = input.uv * <span class="number">2</span> - <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>可以得到如下图像：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208222600.png" /></p>
<p>可以看到，是圆心为<span
class="math inline">\((0.3,0.3)\)</span>的同心圆。</p>
<p>下一步，对上面的UV坐标取绝对值操作。相当于第二、三、四象限的图像，都是第一象限图像的镜像。如下图：</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">float2 st =<span class="meta"> abs(</span><span class="meta">input</span>.uv <span class="comment">* 2 - 1);</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208222908.png" /></p>
<p>调节Num到合适的值，就可以得到如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208223045.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.12-ConcentricCircle1.shader">代码</a></p>
<h2 id="同心圆2">13、同心圆（2）</h2>
<p>首先，将UV坐标从<span class="math inline">\([0,1]\)</span>映射到<span
class="math inline">\([-1,-1]\)</span>，即执行：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float2</span> st = input.uv * <span class="number">2</span> - <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>直线<span class="math inline">\(min(st,
0)\)</span>操作，相当于把第二象限“压缩”到X轴负方向，把第四象限“压缩”到Y轴负方向，把第一象限“压缩”到原点，第三象限不变。</p>
<p>然后执行：</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">float v = <span class="built_in">distance</span>(<span class="built_in">min</span>(st - <span class="variable">_Val</span>, <span class="number">0</span>), <span class="variable">_Center</span>);</span><br></pre></td></tr></table></figure>
<p>当<span class="math inline">\(\_Val =
0\)</span>时，此时，对于第二象限，v只与X的值有关，表现为同一垂直方向图案相同；对于第四象限，v只与Y的值有关，表现为同一水平方向，图案相同；对于第一象限，都“压缩”到了原点，所以v值相同，表现为同一颜色；第三象限正常表现同心圆现象。如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208224720.png" /></p>
<p>对于<span
class="math inline">\(\_Val\)</span>的改变，相当于是平移了圆心。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208224937.gif" /></p>
<p>调整属性，可以得到如下图像：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208225149.png" /></p>
<p>再对UV取绝对值，相当于其它三个象限的图像都是第一象限的镜像，可以得到：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208225247.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.13-ConcentricCircle2.shader">代码</a></p>
<h2 id="同心圆3">14、同心圆（3）</h2>
<p>与上面的同心圆（2）的原理基本类似，只是上面是执行<span
class="math inline">\(min\)</span>操作，这里是执行<span
class="math inline">\(max\)</span>操作，其它流程都相同，这里不再赘述。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208225953.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.14-ConcentricCircle3.shader">代码</a></p>
<h2 id="同心圆4">15、同心圆（4）</h2>
<p>首先，将UV坐标从<span class="math inline">\([0,1]\)</span>映射到<span
class="math inline">\([-1,-1]\)</span>，即执行：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float2</span> st = input.uv * <span class="number">2</span> - <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>然后计算平面上每个点到圆心的距离，使用距离和一个阈值执行<span
class="math inline">\(step\)</span>操作，即可得到如下图像：</p>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> v = distance(st, _Center);</span><br><span class="line">half3 <span class="built_in">col</span> = <span class="keyword">step</span>(_Val, v);</span><br><span class="line"><span class="built_in">return</span> half4(<span class="built_in">col</span>, <span class="number">1.0</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208230552.png" /></p>
<p>再对UV取绝对值，相当于其它三个象限的图像都是第一象限的镜像，可以得到：</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">float2 st =<span class="meta"> abs(</span><span class="meta">input</span>.uv <span class="comment">* 2 - 1);</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208230715.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.15-ConcentricCircle4.shader">代码</a></p>
<h2 id="同心圆5">16、同心圆（5）</h2>
<p>与上面类似，只是不是使用一个阈值判断，而是使用两个阈值确定一个范围。</p>
<figure class="highlight sqf"><table><tr><td class="code"><pre><span class="line">float2 st = <span class="built_in">abs</span>(input.uv * <span class="number">2</span> - <span class="number">1</span>);</span><br><span class="line">float v = <span class="built_in">distance</span>(st, <span class="variable">_Center</span>);</span><br><span class="line">half3 col = <span class="built_in">step</span>(<span class="variable">_Val</span>, v) * <span class="built_in">step</span>(v, <span class="variable">_Val2</span>);</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208230933.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.16-ConcentricCircle5.shader">代码</a></p>
<h2 id="极坐标图案1">17、极坐标图案（1）</h2>
<p>先对UV坐标进行平移，使<span
class="math inline">\((0,0)\)</span>在UV坐标的中心。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float2</span> uv = input.uv - <span class="number">0</span>.<span class="number">5</span>;</span><br></pre></td></tr></table></figure>
<p>然后，计算平面上每个点的极坐标的角度值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">float</span> a = <span class="built_in">atan2</span>(uv.y, uv.x);</span><br></pre></td></tr></table></figure>
<p>对于第一、二象限，a的值域是<span
class="math inline">\([0,\pi]\)</span>，第三、四象限与第二、一象限对称。这里只分析第一、二象限。</p>
<p>对于<span class="math inline">\([0,\pi]\)</span>的定义域，<span
class="math inline">\(cos\)</span>函数的图像如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208232035.png" /></p>
<p>可以发现，函数在<span
class="math inline">\([0,\pi]\)</span>范围内是单调递减的。得到的图案的效果是：在第一象限颜色逐渐变暗；在第二象限，由于<span
class="math inline">\(cos\)</span>的值是负值，所以全部是黑色。如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208232318.png" /></p>
<p>随着Num的变化，逐渐得到如下图案：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201208232528.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.17-Polar1.shader">代码</a></p>
<h2 id="极坐标图案2">18、极坐标图案（2）</h2>
<p>首先，将UV坐标的中心移动到原点。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float2</span> uv = input.uv - <span class="number">0</span>.<span class="number">5</span>; //[-<span class="number">0</span>.<span class="number">5</span>, <span class="number">0</span>.<span class="number">5</span>], make (<span class="number">0</span>,<span class="number">0</span>) in the center</span><br></pre></td></tr></table></figure>
<p>然后，转化为极坐标系，画出<span
class="math inline">\(cos(\theta)\)</span>的图案，如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210072628.png" /></p>
<p>UV点坐标的长度，其实就是上述整个矩形区域，为了使矩形能完全包含圆形区域，将UV点坐标的长度扩大两倍。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> r = length(uv) * <span class="number">2</span>.<span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210080343.png" /></p>
<p>将UV点长度与极轴的距离做对比，可以发现，在圆形区域内，UV点长度小于极轴的距离，反映在图像上，如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210221248.png" /></p>
<p>当<span class="math inline">\(Num =
2\)</span>时，在坐标系中的关系如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210221509.png" /></p>
<p>此时，余弦曲线的定义域是<span
class="math inline">\([-2\pi,2\pi]\)</span>，对于X正方形<span
class="math inline">\([0,2\pi]\)</span>范围，有两个大于0的“凸起”，在此范围内，极轴的距离大于UV点的长度；而对于其他小于0的范围，极轴的距离为负值，而UV点的长度始终为正值，所以极轴的距离肯定小于UV点的长度。对于<span
class="math inline">\([-2\pi,0]\)</span>范围，与上面对称，不再赘述。</p>
<p>此时的图案如下图，与上面的分析吻合。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210222205.png" /></p>
<p>通过调节<span
class="math inline">\(Num\)</span>的值，最终可以得到如下的图案，相关的分析与上面相同。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201210222303.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.18-Polar2.shader">代码</a></p>
<h2 id="极坐标图案3">19、极坐标图案（3）</h2>
<p>可以看到，上面得到的<strong>极坐标图案（2）</strong>边缘处非常锐利。这里将对其进行改善，柔化边缘。使用的方法，主要是使用<strong>smoothstep</strong>函数替代<strong>step</strong>函数，然后再添加了一个柔和**_Smooth**属性，其它都基本相同。</p>
<figure class="highlight fix"><table><tr><td class="code"><pre><span class="line"><span class="attr">half3 col </span>=<span class="string"> smoothstep(f, f + _Smooth, r);</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212075726.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.19-Polar3.shader">代码</a></p>
<h2 id="极坐标图案4">20、极坐标图案（4）</h2>
<p>这里，也是在<strong>极坐标图案（2）</strong>的基础上改的，主要的区别是极坐标曲线不同。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> f <span class="operator">=</span> <span class="built_in">abs</span>(<span class="built_in">cos</span>(a)) <span class="operator">*</span> <span class="number">0.5</span> <span class="operator">+</span> <span class="number">0.3</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212082645.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212192839.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.20-Polar4.shader">代码</a></p>
<h2 id="极坐标图案5">21、 极坐标图案（5）</h2>
<p>这里，也是在<strong>极坐标图案（2）</strong>的基础上改的，主要的区别是极坐标曲线不同。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> f <span class="operator">=</span> <span class="built_in">abs</span>(<span class="built_in">cos</span>(a <span class="operator">*</span> <span class="number">12</span>) <span class="operator">*</span> <span class="built_in">sin</span>(a <span class="operator">*</span> <span class="number">3</span>)) <span class="operator">*</span> <span class="number">0.5</span> <span class="operator">+</span> <span class="number">0.3</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212083122.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212192919.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.21-Polar5.shader">代码</a></p>
<h2 id="极坐标图案6">22、极坐标图案（6）</h2>
<p>这里，也是在<strong>极坐标图案（2）</strong>的基础上改的，主要的区别是极坐标曲线不同。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> f = smoothstep(-<span class="number">0</span>.<span class="number">5</span>, <span class="number">1</span>.<span class="number">0</span>, cos(a * <span class="number">10</span>)) * <span class="number">0</span>.<span class="number">2</span> + <span class="number">0</span>.<span class="number">5</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212084912.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212192943.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.22-Polar6.shader">代码</a></p>
<h2 id="极坐标图案7">23、极坐标图案（7）</h2>
<p>这里，也是在<strong>极坐标图案（2）</strong>的基础上改的，但相比较上面几个，这个更复杂了，牵涉到了图像的并集、补集等。</p>
<p>首先，定义了两个极坐标曲线：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> f <span class="operator">=</span> <span class="built_in">abs</span>(<span class="built_in">cos</span>(a)) <span class="operator">*</span> <span class="number">0.5</span> <span class="operator">+</span> <span class="number">0.3</span>;</span><br><span class="line"><span class="type">float</span> f2 <span class="operator">=</span> <span class="built_in">abs</span>(<span class="built_in">cos</span>(a <span class="operator">*</span> <span class="number">3</span>));</span><br></pre></td></tr></table></figure>
<p>然后，下面的代码的意思是，子集f在集合r中的补集：</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">1 </span>- <span class="keyword">step</span>(f, r)</span><br></pre></td></tr></table></figure>
<p>而下面代码的意思是，两个补集的并集，即r中不属于f或f2的区域：</p>
<figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">half3 col = (<span class="number">1</span> - step(<span class="name">f</span>, r)) + (<span class="number">1</span> - step(<span class="name">f2</span>, r))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>下面的代码，得出的是r中属于f或f2的区域：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">col</span> = <span class="number">1</span> - col<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>最终，可以得到如下图案：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212195039.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212193007.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.23-Polar7.shader">代码</a></p>
<h2 id="并集">24、并集</h2>
<p>这里比较简单，上面介绍了<strong>1、圆形</strong>和<strong>4、矩形</strong>，这里是为了得到二者的并集。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">return <span class="constructor">Rect(<span class="params">_Border</span>, <span class="params">input</span>.<span class="params">uv</span>)</span> + <span class="constructor">Circle(<span class="params">_CircleCenter</span>.<span class="params">xy</span>, <span class="params">_CircleRadius</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212200404.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.24-Union.shader">代码</a></p>
<h2 id="差集">25、差集</h2>
<p>与上面类似，不过这里不是求并集，而是求差集，即属于矩形，但不属于圆形的区域。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">return <span class="constructor">Rect(<span class="params">_Border</span>, <span class="params">input</span>.<span class="params">uv</span>)</span> - <span class="constructor">Circle(<span class="params">_CircleCenter</span>.<span class="params">xy</span>, <span class="params">_CircleRadius</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212200421.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.25-Difference.shader">代码</a></p>
<h2 id="带颜色的差集">26、带颜色的差集</h2>
<p>在上面<strong>差集</strong>的基础之上，添加一些颜色。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> v = <span class="constructor">Rect(<span class="params">_Border</span>, <span class="params">input</span>.<span class="params">uv</span>)</span> - <span class="constructor">Circle(<span class="params">_CircleCenter</span>.<span class="params">xy</span>, <span class="params">_CircleRadius</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">return v<span class="operator"> * </span>_Color;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212200441.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.26-Color.shader">代码</a></p>
<h2 id="日出">27、日出</h2>
<p>这里，在<strong>1、圆形</strong>和<strong>17、极坐标图案（1）</strong>的基础上改进。</p>
<p>首先，得出极坐标图案和圆形区域：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> f = cos(a);</span><br><span class="line"><span class="attribute">float</span> cir = Circle(float<span class="number">2</span>(<span class="number">0</span>.<span class="number">5</span>, <span class="number">0</span>.<span class="number">5</span>), <span class="number">0</span>.<span class="number">2</span>, input.uv);</span><br></pre></td></tr></table></figure>
<p>给圆形区域赋予红色：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> circleCol = cir * half<span class="number">3</span>(<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>对于非圆形区域，对不属于f的区域赋予白色，对属于f的区域赋予颜色<strong>half3(0.9,0.9,0)</strong>：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> lineCol = (<span class="number">1</span> - cir) * ((<span class="number">1</span> - f) + f * half<span class="number">3</span>(<span class="number">0</span>.<span class="number">9</span>,<span class="number">0</span>.<span class="number">9</span>,<span class="number">0</span>));</span><br></pre></td></tr></table></figure>
<p>最后，把圆形区域的颜色和线的颜色相加，即可得到最终效果：</p>
<figure class="highlight fix"><table><tr><td class="code"><pre><span class="line"><span class="attr">half3 col </span>=<span class="string"> circleCol + lineCol;</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212200527.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.27-RisingSun.shader">代码</a></p>
<h2 id="齿轮">28、齿轮</h2>
<p>这里，在<strong>1、圆形</strong>和<strong>22、极坐标图案（6）</strong>的基础上改进。</p>
<p>首先，得出三个图形区域：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> v<span class="number">1</span> = smoothstep(-<span class="number">0</span>.<span class="number">5</span>, <span class="number">1</span>.<span class="number">0</span>, cos(a * <span class="number">10</span>)) * <span class="number">0</span>.<span class="number">2</span> + <span class="number">0</span>.<span class="number">5</span>;</span><br><span class="line"><span class="attribute">float</span> v<span class="number">2</span> = Circle(float<span class="number">2</span>(<span class="number">0</span>.<span class="number">5</span>,<span class="number">0</span>.<span class="number">5</span>), <span class="number">0</span>.<span class="number">2</span>, input.uv);</span><br><span class="line"><span class="attribute">float</span> v<span class="number">3</span> = <span class="number">1</span> - Circle(float<span class="number">2</span>(<span class="number">0</span>.<span class="number">5</span>,<span class="number">0</span>.<span class="number">5</span>), <span class="number">0</span>.<span class="number">1</span>, input.uv);</span><br></pre></td></tr></table></figure>
<p>然后，先求v1与矩形区域的交集，再求v2和v3之间的交集，最后，求出两个交集之间的并集：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> col = step(v<span class="number">1</span>, r) + v<span class="number">2</span> * v<span class="number">3</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212201843.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.28-Gear.shader">代码</a></p>
<h2 id="花朵">29、花朵</h2>
<p>这里，在<strong>1、圆形</strong>和<strong>22、极坐标图案（4）</strong>的基础上改进。</p>
<p>首先，得出三个图像区域：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">float</span> f = abs(cos(a)) * <span class="number">0</span>.<span class="number">5</span> + <span class="number">0</span>.<span class="number">3</span>;</span><br><span class="line"><span class="attribute">float</span> cir = Circle(float<span class="number">2</span>(<span class="number">0</span>.<span class="number">5</span>, <span class="number">0</span>.<span class="number">5</span>), <span class="number">0</span>.<span class="number">15</span>, input.uv);</span><br><span class="line"><span class="attribute">float</span> cir<span class="number">2</span> = Circle(float<span class="number">2</span>(<span class="number">0</span>.<span class="number">5</span>, <span class="number">0</span>.<span class="number">5</span>), <span class="number">0</span>.<span class="number">13</span>, input.uv);</span><br></pre></td></tr></table></figure>
<p>然后，给“花瓣”着色。1 - cir保证花瓣的函数在大圆之外执行，step(f, r) *
step(r, f + 0.1)描边，(1 - step(f, r)) * fixed3(1, 0,
1)花瓣着色。1减去上面的结果，相当于简单的颜色相减。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> col<span class="number">1</span> = (<span class="number">1</span> - cir) * (<span class="number">1</span> - (step(f, r) * step(r, f + <span class="number">0</span>.<span class="number">1</span>) + (<span class="number">1</span> - step(f, r)) * half<span class="number">3</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>)));</span><br></pre></td></tr></table></figure>
<p>接着，得出中间圆形区域的颜色。先计算cir2之外，属于cir的区域的颜色；再计算cir2区域的颜色。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> col<span class="number">2</span> = (<span class="number">1</span> - cir<span class="number">2</span>) * cir * half<span class="number">3</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>) + cir<span class="number">2</span> * half<span class="number">3</span>(<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>最后，得出最终的颜色。</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half3</span> col = col<span class="number">1</span> + col<span class="number">2</span>;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-12-05/20201212202939.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.4-Shape/Shader/1.4.1.29-Flower.shader">代码</a></p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://www.icourse163.org/course/icourse-1002415002">动态几何画板Geogebra教学应用</a></li>
<li>[2] 《Unity Shader入门精要​》</li>
<li>[3] <a
href="https://baike.baidu.com/item/atan2/10931300?fr=aladdin">atan2</a></li>
<li>[4] <a
href="https://zhuanlan.zhihu.com/p/158462351">Shader实验室：frac函数</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Procedural</tag>
      </tags>
  </entry>
  <entry>
    <title>使用hexo在github上搭建个人博客</title>
    <url>/2020/03/27/2020-3-27-%E4%BD%BF%E7%94%A8hexo%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="一-软件的安装">一、 软件的安装</h1>
<h2 id="在github创建个人仓库">1. 在Github创建个人仓库</h2>
<p>在Github上Create a new repository，需要注意的是，Repository
name应该为：<code>xxx.github.io</code>，其中<code>xxx</code>是你的用户名。<span id="more"></span></p>
<h2 id="安装git">2.安装Git</h2>
<p>这里推荐廖雪峰的官方网站的<a
href="https://www.liaoxuefeng.com/wiki/896043488029600/896067074338496">Git教程</a></p>
<p>这里要特别说一下，按照教程操作完成后，还要配置一下ssh：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你的GitHub注册邮箱&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后按照提示回车即可，默认不需要设置密码。</p>
<p>然后找到生成的.ssh文件夹（我的在C:\.ssh）下的id_rsa.pub密钥，将内容全部复制。</p>
<p>打开<a
href="https://github.com/settings/keys">Github_settings_keys</a>，新建New
SSH keys。Titile随便取，Key输入上面复制的id_rsa.pub密钥即可。</p>
<p>完成后，在Git Bash中检测Github公钥是否设置成功。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh git@github.com</span><br></pre></td></tr></table></figure>
<p>根据提示，判断设置是否成功。</p>
<h2 id="安装node.js">3.安装Node.js</h2>
<p>Node.js的<a
href="https://nodejs.org/en/download/">下载地址</a>。安装完成后，在CMD命令行输入以下命令检测是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure>
<h2 id="安装hexo">4.安装Hexo</h2>
<p>Hexo就是我们的个人博客网站的框架。首先先建一个文件夹，可以，命名为Hexo，Hexo框架和你以后发布的网页都在这个文件夹。创建好文件后，进入Hexo文件夹，在这里右键，点击Git
Bash Here选项。</p>
<p>首先安装Hexo，输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli </span><br></pre></td></tr></table></figure>
<p>估计安装时间较长，请耐心等待。安装完成后，初始化博客：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init blog</span><br></pre></td></tr></table></figure>
<p>以上两个命令，都是在Hexo文件夹操作的。</p>
<p>现在Hexo文件夹下应该有一个blog文件夹，是上面初始化博客的时候生成的。关闭Git
Bash，进入blog文件夹，右键打开Git
Bash。现在检测我们的博客雏形了。分别输入以下三条命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;第一个博客&quot;</span></span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<p>没有错误的话，现在在浏览器中输入网址：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">localhost</span>:<span class="number">4000</span></span><br></pre></td></tr></table></figure>
<p>顺利的话，会看到第一个博客。</p>
<h2 id="推送网站">5.推送网站</h2>
<p>上面的操作，只是在本地预览，下面要做的，就是将博客推送到Github远端，从而可以通过互联网访问我们的博客。在进行下一步之前，有一个概念要说一下。</p>
<p>在blog根目录下面，有一个**_config.yml**文件，被称为站点配置文件。</p>
<p>进入根目录的themes文件夹，里面也有个**_config.yml<strong>文件，被称为</strong>主题**配置文件。</p>
<p>下面，我们需要将Hexo与Github关联起来。打开站点配置文件_config.yml，搜索到下面的对应部分进行修改：</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">deploy:</span></span><br><span class="line"><span class="symbol">  type:</span> git</span><br><span class="line"><span class="symbol">  repo:</span> 这里填入你之前在GitHub上创建仓库的完整路径</span><br><span class="line"><span class="symbol">  branch:</span> master</span><br></pre></td></tr></table></figure>
<p>完成之后，保存，在blog文件下加执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p>然后，分别输入以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>
<p>完成之后，打开浏览器，输入类型<code>xxx.github.io</code>的地址，没有问题的话，可以打开博客了。</p>
<h1 id="二更换主题">二、更换主题</h1>
<p>可以在blog目录下的themes文件夹里面查看自己的主题是什么。<a
href="https://hexo.io/themes/">这里</a>是Hexo的主题合集，一般在主题的Github主页中都会有安装方法的。下面介绍一下更换NexT的主题。在blog目录中执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>下载完成后，themes文件夹下应该有next文件夹。打开站点配置文件_config_yml，修改主题为NexT：</p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: https:<span class="comment">//hexo.io/plugins/</span></span><br><span class="line">## Themes: https:<span class="comment">//hexo.io/themes/</span></span><br><span class="line">theme: next</span><br></pre></td></tr></table></figure>
<p>然后，打开next的主题配置文件_config.yml。这里可以选择显示方案：</p>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># Schemes</span></span><br><span class="line"><span class="meta">#scheme: Muse</span></span><br><span class="line"><span class="meta">#scheme: Mist</span></span><br><span class="line"><span class="meta">#scheme: Pisces</span></span><br><span class="line">scheme: Gemini</span><br></pre></td></tr></table></figure>
<p>只需要取消#，即可选择相应的主题（在其他的方案前面要加#）。</p>
<p>选择好相应的主题之后，可以查找相关资料，装扮我们的博客。</p>
<h1 id="三数学工具的安装">三、数学工具的安装</h1>
<p>目前，使用的主题是Hexo的NexT主题。</p>
<p>NexT 内部提供数学公式渲染的引擎，这样你就不需要自己手动在模板中引入
JS 或者 CSS； 只需要选择对应的渲染引擎，并在 next/_config.yml 中将其
enable 选项改为 true 即可。</p>
<p>需要注意的是，仅仅将 enable
打开并不能让你看到数学公式，你还需要使用对应的 Hexo 渲染器(Renderer)
才能真正在博客页面中显示出数学公式。</p>
<ol type="1">
<li><p>需要安装<a
href="https://pandoc.org/installing.html">pandoc</a>。（version &gt;=
2.0）</p></li>
<li><p>在blog文件夹，卸载原有的渲染器==hexo-renderer-marked==，再安装==hexo-renderer-pandoc==:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked</span><br><span class="line">npm install hexo-renderer-pandoc</span><br></pre></td></tr></table></figure></li>
<li><p>在<code>next/_config.yml</code>中将mathjax的enable打开：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">math:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">mathjax:</span></span><br><span class="line">      <span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li><p>在需要显示公式的文章开头，还需要打开<code>mathjax</code>开关，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">index.html</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2018-07-05 12:01:30</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">--</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="四源码的管理">四、源码的管理</h1>
<p>上面使用<code>hexo d</code>命令，只是把hexo生成的博客文件上传到了Github，但是博客的源文件并没有上传上去。下一步，我们将要把博客的源文件上传到Github。</p>
<p>在浏览器中，打开上面新建的Github仓库。目前，只有一个master分支，我们需要新建一个hexo分支来存储我们的博客源文件。在左侧Branch:master的位置，输入分支的名称，下面会有提示创建新的分支。</p>
<p>然后，在settings-&gt;Branches-&gt;Default
branch中，将hexo设为默认分支。</p>
<p>在新的文件夹中，使用Git Bash将仓库克隆到本地。</p>
<p>显示隐藏文件，将除了.git文件夹以外的都删除。</p>
<p>把我们之前的博客源文件全复制过来，除了<code>.deploy_git</code>。这里注意一下，复制过来的源文件应该有一个<code>.gitignore</code>，用来忽略一些不需要的文件，如果没有的话，自己新建一个，内容如下：</p>
<figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line"><span class="meta">.DS_Store</span></span><br><span class="line">Thumbs<span class="number">.</span><span class="built_in">db</span></span><br><span class="line"><span class="built_in">db</span><span class="number">.</span>json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line"><span class="meta">public</span>/</span><br><span class="line"><span class="meta">.deploy</span>*/</span><br></pre></td></tr></table></figure>
<p>还要注意一下，如果之前克隆过theme中的主题文件，那么也应该把主题文件中的<code>.git</code>文件夹删除。</p>
<p>而后，将博客源文件上传到hexo分支。</p>
<p>这样，更换电脑之后，只要将环境配置好，然后把仓库克隆下来，进入克隆下来的文件夹，先运行<code>hexo clean</code>试试。根据提示进行一些操作即可。<a
href="https://zhuanlan.zhihu.com/p/44213627">这里</a>有比较详细的步骤可以参考一下，之前做的时候在这一步也耽误了好久。</p>
<h1 id="五markdown的编辑器">五、Markdown的编辑器</h1>
<p>测试了markdownpad2、vscode等，最终选择了Typora编辑器。但要注意的是，Typora有一些markdown的扩展功能，需要在文件-&gt;偏好设置里面设置一下，才会有效果，例如==高亮==等。</p>
<h1 id="六一些有帮助的工具软件">六、一些有帮助的工具软件</h1>
<ol type="1">
<li><p>ScreenToGif：截屏，生成动态图的软件。</p></li>
<li><p>GeoGebra：动态画图软件，可以很方便的得到各种函数的几何图案。</p></li>
</ol>
<h1 id="七一些有用的包">七、一些有用的包</h1>
<ol type="1">
<li><p>serve</p>
<p>hexo
g生成的文件在public文件夹，与网页真正使用的资源文件一致。可以通过打开public里面的网页判断发布的网站是否有问题。</p>
<p>安装serve：</p>
<blockquote>
<p>npm install -g serve</p>
</blockquote>
<p>开启serve：</p>
<blockquote>
<p>serve</p>
</blockquote></li>
</ol>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://zhuanlan.zhihu.com/p/26625249">GitHub+Hexo
搭建个人网站详细教程</a></li>
<li>[2] <a
href="https://github.com/wzpan/hexo-renderer-pandoc">hexo-renderer-pandoc</a></li>
<li>[3] <a
href="https://github.com/theme-next/hexo-theme-next">hexo-theme-next</a></li>
<li>[4] <a
href="https://segmentfault.com/a/1190000009544924">hexo的next主题个性化配置教程</a></li>
<li>[5] <a
href="https://blog.csdn.net/mingzhuo_126/article/details/82722455">使用Typora添加数学公式</a></li>
<li>[6] <a
href="https://zhuanlan.zhihu.com/p/44213627">hexo超完整的搭建教程，让你拥有一个专属个人博客</a></li>
<li>[7] <a href="https://github.com/vercel/serve">serve</a></li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>渲染管线中的顶点变换</title>
    <url>/2020/04/04/2020-4-4-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%AD%E7%9A%84%E9%A1%B6%E7%82%B9%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>在图形学渲染管线中，一个顶点坐标，大概要经历局部坐标系、世界坐标系、相机坐标系、裁剪坐标系，最后到窗口坐标系，显示在屏幕上。<span id="more"></span></p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20200408151129.png"
alt="坐标空间变换示意图" />
<figcaption aria-hidden="true">坐标空间变换示意图</figcaption>
</figure>
<p>在这些过程中，从一个坐标系到另一个坐标系，都需要进行一定的变换。下面，将介绍每次变换的方式。</p>
<p>注意，本文是针对OpenGL的。</p>
<h1 id="局部空间-世界空间">局部空间-&gt;世界空间</h1>
<p>这一变换过程，主要是将模型放置在世界空间中，进行一定的缩放、旋转或平移。这一步比较简单，只要将相应的矩阵作用到模型的局部空间坐标即可。</p>
<p>比如，对模型缩放<span class="math inline">\(\left(S_{x},S_{y},S_{z}
\right)\)</span>，然后绕Z轴旋转<span
class="math inline">\(\theta\)</span>度，再进行<span
class="math inline">\(\left(T_{x},T_{y},T_{z}
\right)\)</span>的平移。注意，这里的变换顺序是不能变的，即要先进行缩放，再进行旋转，最后进行平移。据此，我们可以构建模型变换矩阵。
<span class="math display">\[
M_{model}=
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; T_{x} \\
0 &amp; 1 &amp; 0 &amp; T_{y} \\
0 &amp; 0 &amp; 1 &amp; T_{z} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
\cos{\theta} &amp; -\sin{\theta} &amp; 0 &amp; 0 \\
\sin{\theta} &amp; \cos{\theta} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
S_{x} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; S_{y} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; S_{z} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<h1 id="世界空间-相机空间">世界空间-&gt;相机空间</h1>
<p>首先定义一下相机：</p>
<ul>
<li><p>坐标为<span class="math inline">\(\vec{e}\)</span></p></li>
<li><p>观察方向<span class="math inline">\(\vec{g}\)</span></p></li>
<li><p>向上方向<span class="math inline">\(\vec{t}\)</span></p></li>
</ul>
<p>示意图如下所示：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20200408093309.png"
alt="相机坐标系示意图" />
<figcaption aria-hidden="true">相机坐标系示意图</figcaption>
</figure>
<p>有一个性质注意一下：<strong>当相机和相机“看“到的物体一起变换时，相机”看“到的内容是不变的。</strong>这样，可以将相机的坐标移动到世界坐标的原点，向上方向对齐世界坐标的Y轴，观察方向对齐世界坐标的-Z轴。然后，对物体进行相同的变换即可。</p>
<p>在数学上，这个过程大概这样：</p>
<ul>
<li>将相机移动到坐标原点</li>
<li>旋转观察方向<span class="math inline">\(\vec{g}\)</span>到-Z轴</li>
<li>旋转向上方向<span class="math inline">\(\vec{t}\)</span>到Y轴</li>
<li>旋转(<span class="math inline">\(\vec{g} \times
\vec{t}\)</span>)到X轴</li>
</ul>
<p>大体分为两步：先位移，后旋转。即<span class="math inline">\(M_{view}
= R_{view}T_{view}\)</span>。</p>
<p>平移部分： <span class="math display">\[
T_{view} =
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -x_{e} \\
0 &amp; 1 &amp; 0 &amp; -y_{e} \\
0 &amp; 0 &amp; 1 &amp; -z_{e} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span> 对于旋转部分，先补充一些知识点。对于二维空间来说： <span
class="math display">\[
R_{\theta} =
\begin{pmatrix}
\cos{\theta} &amp; -\sin{\theta} \\
\sin{\theta} &amp; \cos{\theta}  \\
\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
R_{-\theta} =
\begin{pmatrix}
\cos{\theta} &amp; \sin{\theta} \\
-\sin{\theta} &amp; \cos{\theta}  \\
\end{pmatrix} =
R_{\theta}^\mathrm{T}
\]</span></p>
<p>根据定义，旋转<span
class="math inline">\(\theta\)</span>角度和旋转<span
class="math inline">\(-\theta\)</span>角度是互逆的，即：<span
class="math inline">\(R_{-\theta} = R_{\theta}^{-1}\)</span>。</p>
<p>所以，对于旋转变换，可以得出旋转矩阵的逆等于它的转置，即： <span
class="math display">\[
R_{\theta}^\mathrm{T} = R_{\theta}^{-1}
\]</span>
回到上面的旋转部分，直接求相机的坐标轴旋转到世界坐标轴的矩阵不是很方便，但是反过来，求世界坐标轴旋转到相机的坐标轴很容易：
<span class="math display">\[
R_{view}^{-1} =
\begin{bmatrix}
x_{\vec{g} \times \vec{t}} &amp; x_{\vec{t}} &amp; x_{-\vec{g}} &amp; 0
\\
y_{\vec{g} \times \vec{t}} &amp; y_{\vec{t}} &amp; y_{-\vec{g}} &amp; 0
\\
z_{\vec{g} \times \vec{t}} &amp; z_{\vec{t}} &amp; z_{-\vec{g}} &amp; 0
\\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span> 根据旋转矩阵的逆等于它的转置，得出： <span
class="math display">\[
R_{view} =
(R_{view}^{-1})^\mathrm{T} =
\begin{bmatrix}
x_{\vec{g} \times \vec{t}} &amp; y_{\vec{g} \times \vec{t}} &amp;
z_{\vec{g} \times \vec{t}} &amp; 0 \\
x_{\vec{t}} &amp; y_{\vec{t}} &amp; z_{\vec{t}} &amp; 0 \\
x_{-\vec{g}} &amp; y_{-\vec{g}} &amp; z_{-\vec{g}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span> 根据<span class="math inline">\(M_{view} =
R_{view}T_{view}\)</span>，可以得出： <span class="math display">\[
M_{view} =
R_{view}T_{view} =
\begin{bmatrix}
x_{\vec{g} \times \vec{t}} &amp; y_{\vec{g} \times \vec{t}} &amp;
z_{\vec{g} \times \vec{t}} &amp; 0 \\
x_{\vec{t}} &amp; y_{\vec{t}} &amp; z_{\vec{t}} &amp; 0 \\
x_{-\vec{g}} &amp; y_{-\vec{g}} &amp; z_{-\vec{g}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -x_{e} \\
0 &amp; 1 &amp; 0 &amp; -y_{e} \\
0 &amp; 0 &amp; 1 &amp; -z_{e} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<h1 id="相机空间-裁剪空间">相机空间-&gt;裁剪空间</h1>
<p>在一个顶点着色器运行的最后，期望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被裁剪掉(Clipped)。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段。这也就是裁剪空间(Clip
Space)名字的由来。</p>
<p>因为将所有可见的坐标都指定在-1.0到1.0的范围内不是很直观，所以我们会指定自己的坐标集(Coordinate
Set)并将它变换回标准化设备坐标系。</p>
<p>由投影矩阵创建的观察箱(Viewing
Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上。<strong>将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)，因为使用投影矩阵能将3D坐标投影(Project)到很容易映射到2D的标准化设备坐标系中。</strong></p>
<p><strong>这里要注意一下，OpenGL是右手坐标系的，但是在NDC中，是左手坐标系的，这里要特别注意！！！</strong></p>
<p>相机空间转换到裁剪空间，有需要用到投影变换。有两种投影变换：正交投影和透视投影。下面分别介绍一下。</p>
<h2 id="正交投影">正交投影</h2>
<p>我们先定义一个正交投影的视锥体<span class="math inline">\([l,r]
\times [b,t] \times
[f,n]\)</span>（注意，n和f都是负数，f是远平面，所以f&lt;n），它是一个长方体。我们需要做的，就是将正交投影的视锥体转换到标准立方体（即标准化设备坐标，<span
class="math inline">\([-1,1]^{3}\)</span>）。<strong>注意，这里<span
class="math inline">\([f,n]\)</span>映射到NDC中的[1,-1]。</strong></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20200408102657.png" /></p>
<p>这里，分成两个步骤：平移和缩放。正交投影的矩阵如下： <span
class="math display">\[
M_{ortho} =
\begin{bmatrix}
\frac{2}{r-l} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{2}{t-b} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac{2}{f-n} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\
0 &amp; 1 &amp; 0 &amp; -\frac{t+b}{2} \\
0 &amp; 0 &amp; 1 &amp; -\frac{n+f}{2} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}=
\begin{bmatrix}
\frac{2}{r-l} &amp; 0 &amp; 0 &amp; -\frac{r+l}{r-l} \\
0 &amp; \frac{2}{t-b} &amp; 0 &amp; -\frac{t+b}{t-b} \\
0 &amp; 0 &amp; \frac{2}{f-n} &amp; -\frac{f+n}{f-n} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<h2 id="透视投影">透视投影</h2>
<p>对于透视投影，分成两步操作：</p>
<ul>
<li>首先，“压扁”视锥体成一个长方体（n-&gt;n,f-&gt;f）（<span
class="math inline">\(M_{persp-&gt;ortho}\)</span>）；</li>
<li>然后，做正交投影操作（<span
class="math inline">\(M_{ortho}\)</span>，即上面的正交投影）。</li>
</ul>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20200408093419.png"
alt="透视投影和正交投影的视锥体示意图" />
<figcaption
aria-hidden="true">透视投影和正交投影的视锥体示意图</figcaption>
</figure>
<p>观察下图：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20200408093445.png"
alt="从X轴观察" />
<figcaption aria-hidden="true">从X轴观察</figcaption>
</figure>
<p>根据相似三角形的关系，可以得出： <span class="math display">\[
y^{&#39;} = \frac{n}{z}y
\]</span> 类似的，可以得出： <span class="math display">\[
x^{&#39;} = \frac{n}{z}x
\]</span> 由此，可以得出下面的关系： <span class="math display">\[
M_{persp-&gt;ortho}^{(4 \times 4)}
\begin{pmatrix}
x\\
y\\
z\\
1\\
\end{pmatrix}=
\begin{pmatrix}
\frac{n}{z}x \\
\frac{n}{z}y \\
unknown \\
1 \\
\end{pmatrix}
\]</span></p>
<p>下面，说一个齐次坐标的性质：在3D坐标系统中，<span
class="math inline">\(\left ( x,y,z,1 \right )\)</span>，<span
class="math inline">\(\left ( kx,ky,kz,k \neq 0 \right )\)</span>，<span
class="math inline">\(\left ( xz,yz,z^{2},z \neq 0 \right
)\)</span>都表示相同的坐标---<span class="math inline">\(\left ( x,y,z
\right )\)</span>。例如：<span class="math inline">\(\left ( 1,0,0,1
\right )\)</span>和<span class="math inline">\(\left ( 2,0,0,2 \right
)\)</span>都表示坐标<span class="math inline">\(\left ( 1,0,0 \right
)\)</span>。</p>
<p>所以，有如下关系： <span class="math display">\[
M_{persp-&gt;ortho}^{(4 \times 4)}
\begin{pmatrix}
x\\
y\\
z\\
1\\
\end{pmatrix}=
\begin{pmatrix}
\frac{n}{z}x \\
\frac{n}{z}y \\
unknown \\
1 \\
\end{pmatrix} =
\begin{pmatrix}
nx \\
ny \\
unknown \\
z \\
\end{pmatrix}
\]</span> 更进一步的，可以得到： <span class="math display">\[
M_{persp-&gt;ortho} =
\begin{pmatrix}
n &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; n &amp; 0 &amp; 0 \\
? &amp; ? &amp; ? &amp; ? \\
0 &amp; 0 &amp; 1 &amp; 0 \\
\end{pmatrix}
\]</span> 现在，还剩下第三列是未知的。</p>
<p>经过观察上面的透视投影视锥体，可以得出以下推论：</p>
<ol type="1">
<li><p>近平面上的点的坐标都不会改变；</p></li>
<li><p>远平面上的点，Z坐标不改变。</p></li>
</ol>
<p>根据推论1，近平面上的点<span class="math inline">\(\left (x,y,n,1
\right )\)</span>经过变换后，不会改变。即： <span
class="math display">\[
M_{persp-&gt;ortho}
\begin{pmatrix}
x \\
y \\
n \\
1 \\
\end{pmatrix} =
\begin{pmatrix}
x \\
y \\
n \\
1 \\
\end{pmatrix} =
\begin{pmatrix}
nx \\
ny \\
n^{2} \\
n \\
\end{pmatrix}
\]</span> 根据： <span class="math display">\[
M_{persp-&gt;ortho}
\begin{pmatrix}
x\\
y\\
z\\
1\\
\end{pmatrix}=
\begin{pmatrix}
nx \\
ny \\
unknown \\
z \\
\end{pmatrix}
\]</span> 因为<span
class="math inline">\(n^{2}\)</span>与x和y都没有关系，所以可以得出<span
class="math inline">\(M_{persp-&gt;ortho}\)</span>的第三列的形式是<span
class="math inline">\(\left (0,0,A,B \right )\)</span>。</p>
<p>根据： <span class="math display">\[
\left(0,0,A,B \right)
\begin{pmatrix}
x \\
y \\
n \\
1 \\
\end{pmatrix} = n^{2}
\]</span> 可以得出： <span class="math display">\[
An+B = n^{2}
\]</span> 根据推论2，远平面的中心点<span class="math inline">\(\left
(0,0,f,1 \right)\)</span>，经过变换后，还是本身。如下： <span
class="math display">\[
M_{persp-&gt;ortho}
\begin{pmatrix}
0 \\
0 \\
f \\
1 \\
\end{pmatrix} =
\begin{pmatrix}
0 \\
0 \\
f \\
1 \\
\end{pmatrix} =
\begin{pmatrix}
0 \\
0 \\
f^{2} \\
f \\
\end{pmatrix}
\]</span> 所以，可以得出： <span class="math display">\[
\left(0,0,A,B \right)
\begin{pmatrix}
0 \\
0 \\
f \\
1 \\
\end{pmatrix} = f^{2}
\]</span></p>
<p>即： <span class="math display">\[
Af + B = f^{2}
\]</span> 到这里，可以得出方程组： <span class="math display">\[
\begin{cases}
An + B = n^{2} \\
Af + B = f^{2} \\
\end{cases} \Rightarrow
\begin{matrix}
A = n + f \\
B = -nf \\
\end{matrix}
\]</span> 到这里，可以得出<span
class="math inline">\(M_{persp-&gt;ortho}\)</span>: <span
class="math display">\[
M_{persp-&gt;ortho} =
\begin{bmatrix}
n &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; n &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; n+f &amp; -nf \\
0 &amp; 0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\]</span> 最终，透视投影矩阵： <span class="math display">\[
M_{persp} =
M_{ortho}M_{persp-&gt;ortho} =
\begin{bmatrix}
\frac{2n}{r-l} &amp; 0 &amp; \frac{l+r}{l-r} &amp; 0 \\
0 &amp; \frac{2n}{t-b} &amp; \frac{b+t}{b-t} &amp; 0 \\
0 &amp; 0 &amp; \frac{f+n}{f-n} &amp; \frac{2nf}{n-f} \\
0 &amp; 0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\]</span></p>
<h1 id="裁剪空间-窗口空间">裁剪空间-&gt;窗口空间</h1>
<p>在裁剪空间的最后，所以的可见的点都在标准设备坐标系（NDC）中，即坐标坐落在范围<span
class="math inline">\([-1,1]^{3}\)</span>内。</p>
<p>先不考虑Z轴的变换。</p>
<p>从NDC到窗口空间，需要经过视口变换。定义一个屏幕空间：<span
class="math inline">\(\left (0,0,w,h
\right)\)</span>。平面左下角的坐标位<span class="math inline">\(\left
(0,0 \right)\)</span>，右上角的坐标为<span class="math inline">\(\left
(w,h \right)\)</span>。对于X和Y坐标的变换，即从<span
class="math inline">\(\left(-1,1\right) \times
\left(-1,1\right)\)</span>到<span class="math inline">\(\left(0,w\right)
\times \left(0,h\right)\)</span>。</p>
<p>这里，经过两步变换：</p>
<ol type="1">
<li><p>将NDC的中心平移到窗口的中心； <span class="math display">\[
T_{viewport} =
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; \frac{w}{2} \\
0 &amp; 1 &amp; 0 &amp; \frac{h}{2} \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\]</span></p></li>
<li><p>将NDC的大小缩放到屏幕的大小。</p></li>
</ol>
<p><span class="math display">\[
R_{viewport} =
\begin{pmatrix}
\frac{w}{2} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{h}{2} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\]</span></p>
<p>合并到一起： <span class="math display">\[
M_{viewport} = R_{viewport}T_{viewport} =
\begin{pmatrix}
\frac{w}{2} &amp; 0 &amp; 0 &amp; \frac{w}{2} \\
0 &amp; \frac{h}{2} &amp; 0 &amp; \frac{h}{2} \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\]</span> 对于Z坐标，从<span
class="math inline">\(\left(-1,1\right)\)</span>映射到了<span
class="math inline">\(\left(0,1\right)\)</span>。这里只是简单的线性映射。假设<span
class="math inline">\(z^{&#39;} = Az+B\)</span>，当<span
class="math inline">\(z\)</span>等于-1时，<span
class="math inline">\(z^{&#39;}\)</span>等于0；当<span
class="math inline">\(z\)</span>等于1时，<span
class="math inline">\(z^{&#39;}\)</span>等于1。可得如下方程组： <span
class="math display">\[
\begin{cases}
A(-1) + B = 0 \\
A(1) + B = 1 \\
\end{cases} \Rightarrow
\begin{cases}
A = \frac{1}{2} \\
B = \frac{1}{2} \\
\end{cases}
\]</span> 所以，<span class="math inline">\(z^{&#39;} = \frac{1}{2}z +
\frac{1}{2}\)</span>。代入上述<span
class="math inline">\(M_{viewport}\)</span>矩阵，可得： <span
class="math display">\[
M_{viewport} =
\begin{pmatrix}
\frac{w}{2} &amp; 0 &amp; 0 &amp; \frac{w}{2} \\
0 &amp; \frac{h}{2} &amp; 0 &amp; \frac{h}{2} \\
0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{2} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\]</span></p>
<h1 id="补充">补充</h1>
<p>偶然间发现一张图，很清晰地描述了上述的变换过程，这里也记录一下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-4/20210119214624.png" /></p>
<h1 id="参考">参考</h1>
<ul>
<li><p>[1] <a
href="https://www.bilibili.com/video/BV1X7411F744?p=4">GAMES101-现代计算机图形学入门-闫令琪</a></p></li>
<li><p>[2] <a
href="http://www.songho.ca/opengl/gl_projectionmatrix.html">OpenGL
Projection Matrix</a></p></li>
<li><p>[3] Steve Marschner and Peter Shirley，“Fundamentals of Computer
Graphics”</p></li>
</ul>
]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>Transformation</tag>
        <tag>Matrices</tag>
      </tags>
  </entry>
  <entry>
    <title>令人迷惑的Gamma</title>
    <url>/2020/04/19/2020-4-19-%E4%BB%A4%E4%BA%BA%E8%BF%B7%E6%83%91%E7%9A%84Gamma/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>首先我想说，接触到Gamma的概念也很长时间了，一直没有认真的去学习它。知其然而不知其所以然。最近恰巧学到了<a
href="https://learnopengl-cn.github.io/05%20Advanced%20Lighting/02%20Gamma%20Correction/">这一部分</a>，就想彻底地搞懂它。<span id="more"></span></p>
<h1 id="crt">CRT</h1>
<p>说起Gamma，肯定离不开CRT（阴极射线管）。</p>
<p>CRT（阴极射线管）是大多数计算机显示器、视频监视器、电视接收器和示波器中使用的显示设备，由德国科学家
Karl Ferdinand
Braun于1897年发明。它的特点是荧光屏被加热的阴极发射的电子束照射时发出可见光。电子被集中在一束光中，这束光在磁场的作用下发生偏转，扫描被磷光材料覆盖的观察端(阳极)。当电子撞击这种材料时，就会发出光来。
在电视阴极射线管(CRT)中，整个显像管区域以一种固定的模式被扫描，这种模式被称为光栅。通过视频信号调节电子束的强度，就可以产生一幅图像。在现代的电视机中，电子束是通过一个磁轭(一组由电子电路驱动的线圈)作用在电子管颈上的磁场来扫描的。彩色阴极射线管使用三种不同的材料，分别发出绿色、蓝色和红色的光，紧密地排列在条状(在孔径格栅设计中)或簇状(在荫罩阴极射线管中)。有三支电子枪，每种颜色一支，每支电子枪只能打到一种颜色的点。</p>
<p>在电视的早期，人们发现阴极射线管不会产生与输入电压成比例的光强。视频信号与阴极射线管产生的光(传递函数)之间的关系是非线性的，通常用幂定律来描述:
<span class="math display">\[
Light \quad intensity = Volt^{\gamma}
\]</span> Gamma(γ)的值为2.8 (PAL和SECAM制式)或2.2
(NTSC)。传递函数通常被称为曲线。<strong>它是由电子枪内部的静电效应引起的</strong>。这种关系的图形，如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-19/20200420090445.jpg" /></p>
<p>按照这种关系，最后屏幕上显示的亮度会比预期中的更暗。</p>
<p>比如如果是线性关系的话，50%亮度的入射光应该输出50%的亮度；但是按照这个指数关系，<span
class="math inline">\(50 \%^{2.2} = 21.8
\%\)</span>，实际上在CRT显示器上只会输出21.8%的亮度，还不到预期亮度的一半！</p>
<h1 id="gamma编码">Gamma编码</h1>
<p>人们发现了CRT的问题，必然要想办法解决。</p>
<p>可以想到的一种解决方法是，改变CRT显示器，使其可以线性输出。但当时已经存在很多的CRT显示器，重新改造的话，不是很现实。考虑到当时的情况，图像采集设备，例如相机，并不是很多，能不能对其进行改良，来解决CRT的Gamma问题呢？答案是肯定的。</p>
<p>图形采集设备，采集到的现实中的亮度，是线性的。在需要将采集到的数据存储之前，可以进行Gamma编码，它也符合幂定律：
<span class="math display">\[
V_{encode} = V_{Linear}^{\frac{1}{\gamma}}
\]</span> 用图像表示这种关系的话，如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-19/20200420092149.jpg" /></p>
<p>问题来了，这样为什么可以解决CRT的Gamma问题呢？</p>
<p>从数学上来看，存储图像时，要进行的操作是： <span
class="math display">\[
V_{encode} = V_{linear}^{\frac{1}{\gamma}}
\]</span></p>
<p>将图像显示到屏幕上，要进行的操作是： <span class="math display">\[
V_{linear} = V_{encode}^{\gamma}
\]</span> 所以，最后屏幕上输出的，是线性的。这个过程如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-19/20200420091041.jpg" /></p>
<p>这样，就可以解决CRT的Gamma问题了。</p>
<p>许多文章提到Gamma编码与人类视觉对亮度的非线性响应有关。这是不准确的。</p>
<p>这种混淆很可能源于Gamma编码(大约<span
class="math inline">\(x^{0.45}\)</span>)和人类视觉(大约<span
class="math inline">\(x^{0.42}\)</span>)之间非常相似的指数关系——但这只是巧合。</p>
<p>话虽如此，这种类似的关系确实有一个显著的好处。由于Gamma编码重新分配的色调水平更接近我们的眼睛如何感知它们，我们对暗部的表达更精细，而对亮部的表达会比较简单。</p>
<p><strong>这是因为人类的视觉对暗部的变化比亮部的变化更敏感</strong>。通过以与我们的视觉系统相匹配的方式对数据进行编码，色调值可以更有效地分布。换句话说，在亮部，我们很难看到细微的差别；然而，在暗部，我们却能探测到同样的绝对变化。因此，即使在更高的亮度级别上有更少的色调，我们也不会感知到任何差异。</p>
<p>所以，同等带宽/存储空间的前提下，尽量存储更多的暗部的信息可以给人带来更多的信息量。</p>
<p>Gamma编码的图形表示如下。可以看到，在输入x比较低的时候，y有更大的增长性；而在x比较大的时候，y的增长性就比较平缓了。所以我们可以使用更多的空间来处理暗部的信息。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-19/20200420092149.jpg" /></p>
<p><strong>重要的是要记住，这不是我们Gamma编码图像的原因，只是一个有趣的副作用。</strong></p>
<h1 id="srgb-standard-red-green-blue">sRGB (standard Red Green
Blue)</h1>
<p>sRGB是一个彩色空间，是当今消费电子设备，事实上的标准，包括显示器、数码相机、扫描仪、打印机和手持设备。它也是互联网上图像的标准颜色空间。</p>
<p>sRGB规范定义了使用什么Gamma来对sRGB图像进行编码和解码。sRGB的Gamma非常接近标准Gamma2.2。</p>
<p>因为显示器总是在sRGB空间中显示应用了Gamma的颜色，无论什么时候当你在计算机上绘制、编辑或者画出一个图片的时候，你所选的颜色都是根据你在显示器上看到的那种。这实际意味着所有你创建或编辑的图片并不是在线性空间，而是在sRGB空间中，假如在你的屏幕上对红色翻一倍，就是根据你所感知到的亮度进行的，并不等于将红色元素加倍。</p>
<p>这里考虑两种情况，一种情况是，图像是图像采集设备（如相机）产生的；另一种情况是，图像是美术工作者在计算机上画出来的。</p>
<p>对于前者，设备采集到图像后，会对线性的图像进行Gamma编码，即应用<span
class="math inline">\(V_{encode} =
V_{linear}^{\gamma}\)</span>的幂函数关系映射。这里，<span
class="math inline">\(\gamma\)</span>约等于0.45（<span
class="math inline">\(1/2.2\)</span>）。此时，图像就存储在sRGB空间中。</p>
<p>对于后者，当美术工作者在计算机上作图时，并不是在线性空间中，而是在sRGB空间中。</p>
<h1 id="gamma工作流">Gamma工作流</h1>
<p>尽管有这些好处，Gamma编码还是在记录和显示图像的过程中，增加了一层复杂性。一个Gamma编码的图像在屏幕上显示时，必须有Gamma解码，它被视为有效的转换为原始场景的效果。换句话说，Gamma编码的目的是记录图像，而不是显示图像。幸运的是，这第二步(“Gamma解码”)是由显示器和视频卡自动执行。下图说明了所有这些是如何组合在一起的：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-4-19/20200420091140.png" /></p>
<ol type="1">
<li>图像<span
class="math inline">\(\gamma\)</span>：当捕获的图像转换为标准的JPEG或TIFF文件时，相机或原始开发软件都会应用这种方法。它将相机的固有色调重新分配为更一致的色调，从而最有效地利用给定的位深度。</li>
<li>显示<span
class="math inline">\(\gamma\)</span>：这指的是你的显卡和显示设备的净影响，所以它实际上可能是由几个Gamma组成的。显示<span
class="math inline">\(\gamma\)</span>的主要目的是补偿文件的Gamma，从而确保图像在屏幕上显示时不会不真实地变亮。较高的显示<span
class="math inline">\(\gamma\)</span>导致更黑暗的图像与更大的对比度。</li>
<li>系统<span
class="math inline">\(\gamma\)</span>：这表示应用于图像的所有Gamma值的净效果，也称为“查看Gamma”。为了忠实地再现场景，这应该接近于一条直线(Gamma
=
1.0)。一条直线确保输入(原始场景)与输出(屏幕或打印中显示的灯光)相同。然而，为了提高对比度，系统Gamma有时设置略大于1.0。这有助于弥补由于显示设备的动态范围，或由于非理想的观看条件和图像耀斑所造成的限制。</li>
</ol>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://learnopengl.com/Advanced-Lighting/Gamma-Correction">Gamma
Correction</a></li>
<li>[2] <a
href="https://www.japanistry.com/understanding-gamma-in-photography/">Understanding
Gamma in Photography</a></li>
<li>[3] <a
href="http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/">What
every coder should know about gamma</a></li>
<li>[4] <a
href="https://www.cambridgeincolour.com/tutorials/gamma-correction.htm">UNDERSTANDING
GAMMA CORRECTION</a></li>
<li>[5] <a
href="https://en.wikipedia.org/wiki/Cathode-ray_tube">Cathode-ray
tube</a></li>
</ul>
]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>Gamma</tag>
        <tag>Linear</tag>
        <tag>sRGB</tag>
      </tags>
  </entry>
  <entry>
    <title>深度缓冲中的深度值计算及可视化</title>
    <url>/2020/04/08/2020-4-8-%E6%B7%B1%E5%BA%A6%E7%BC%93%E5%86%B2%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%80%BC%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>在<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/04/04/2020-4-4-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%AD%E7%9A%84%E9%A1%B6%E7%82%B9%E5%8F%98%E6%8D%A2/#more">渲染管线中的顶点变换</a>中，介绍了顶点在各个坐标空间的变换。<span id="more"></span>变换到最后，是屏幕坐标空间。在OpenGL中，屏幕空间坐标的Z值即是深度缓冲中的深度值。深度缓冲包含了一个介于0.0和1.0之间的深度值，它将会与观察者视角所看见的场景中所有物体的z值进行比较。本文将介绍深度值的计算，以及从深度值反向计算出相机空间中的顶点的Z值。</p>
<h1 id="深度值计算">深度值计算</h1>
<p>在<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/04/04/2020-4-4-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%AD%E7%9A%84%E9%A1%B6%E7%82%B9%E5%8F%98%E6%8D%A2/#more">渲染管线中的顶点变换</a>中，计算得到了透视投影矩阵：
<span class="math display">\[
M_{persp} =
\begin{bmatrix}
\frac{2n}{r-l} &amp; 0 &amp; \frac{l+r}{l-r} &amp; 0 \\
0 &amp; \frac{2n}{t-b} &amp; \frac{b+t}{b-t} &amp; 0 \\
0 &amp; 0 &amp; \frac{f+n}{f-n} &amp; \frac{2nf}{n-f} \\
0 &amp; 0 &amp; 1 &amp; 0 \\
\end{bmatrix}
\]</span> 同时，也得到了视口变换矩阵： <span class="math display">\[
M_{viewport} =
\begin{bmatrix}
\frac{w}{2} &amp; 0 &amp; 0 &amp; \frac{w}{2} \\
0 &amp; \frac{h}{2} &amp; 0 &amp; \frac{h}{2} \\
0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{2} \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\]</span>
首先，根据透视矩阵，计算NDC空间的Z值。这里，相机空间中的坐标经过透视矩阵变换后，还要进行齐次除法，才能得到NDC空间中的坐标。
<span class="math display">\[
\begin{pmatrix}
x_{clip} \\
y_{clip} \\
z_{clip} \\
w_{clip} \\
\end{pmatrix} =
M_{persp}
\begin{pmatrix}
x_{eye} \\
y_{eye} \\
z_{eye} \\
w_{eye} \\
\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
\begin{pmatrix}
x_{ndc} \\
y_{ndc} \\
z_{ndc} \\
\end{pmatrix} =
\begin{pmatrix}
\frac{x_{clip}}{w_{clip}} \\
\frac{y_{clip}}{w_{clip}} \\
\frac{z_{clip}}{w_{clip}} \\
\end{pmatrix}
\]</span></p>
<p>由此，可以得出： <span class="math display">\[
\begin{aligned}
z_{ndc} &amp;= \frac{\frac{f+n}{f-n}z_{eye}+\frac{-2nf}{f-n}}{z_{eye}}
\\
&amp;=\frac{f+n}{f-n}+\frac{-2nf}{z_{eye}(f-n)}
\end{aligned}
\tag{1}
\]</span> 根据上述公式，可以得出： <span class="math display">\[
z_{eye} = \frac{2nf}{(f+n)-z_{ndc}(f-n)} \tag{2}
\]</span> 根据视口变换矩阵，可以得出： <span class="math display">\[
z_{win} = \frac{1}{2}z_{ndc}+\frac{1}{2} \tag{3}
\]</span></p>
<p>将<span class="math inline">\(\left(1\right)\)</span>带入<span
class="math inline">\(\left(3\right)\)</span>，可以得到： <span
class="math display">\[
\begin{aligned}
z_{win} &amp;= \frac{1}{2}(z_{ndc}+1) \\
&amp;=\frac{1}{2}(\frac{f+n}{f-n}+\frac{-2nf}{z_{eye}(f-n)} + 1) \\
&amp;=\frac{f-\frac{nf}{z_{eye}}}{f-n} \\
&amp;= \frac{\frac{1}{n}-\frac{1}{z_{eye}}}{\frac{1}{n}-\frac{1}{f}}
\end{aligned}
\]</span></p>
<p>即： <span class="math display">\[
z_{win} = \frac{\frac{1}{n}-\frac{1}{z_{eye}}}{\frac{1}{n}-\frac{1}{f}}
\tag{4}
\]</span></p>
<p>到这一步，即可以求得屏幕空间中的深度。</p>
<p>在<a href="https://learnopengl-cn.github.io/">Learn OpenGL
CN</a>学习过的，可能对<a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a>这一节的内容有些印象。它得到的深度值的公式是：
<span class="math display">\[
F_{depth} = \frac{1/z - 1/near}{1/far - 1/near}
\]</span> 跟<span
class="math inline">\(\left(4\right)\)</span>式对比，发现有些不一样，这是怎么回事呢？</p>
<p>这里要注意，本文定义的<span class="math inline">\(n\)</span>、<span
class="math inline">\(f\)</span>和<span
class="math inline">\(z_{eye}\)</span>是实际的坐标值，是负的。而<a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a>文中，定义的<span
class="math inline">\(near\)</span>、<span
class="math inline">\(far\)</span>代表了近平面和远平面，而<span
class="math inline">\(z\)</span>代表了近、远平面之间的值，它们都是正的。将<span
class="math inline">\(n=-near\)</span>、<span
class="math inline">\(f=-far\)</span>、<span
class="math inline">\(z_{eye}=-z\)</span>代入<span
class="math inline">\(\left(4\right)\)</span>式，可得： <span
class="math display">\[
\begin{aligned}
F_{depth} &amp;= z_{win} \\
&amp;= \frac{\frac{1}{n}-\frac{1}{z_{eye}}}{\frac{1}{n}-\frac{1}{f}} \\
&amp;=
\frac{\frac{1}{-near}-\frac{1}{-z}}{\frac{1}{-near}-\frac{1}{-far}} \\
&amp;= \frac{\frac{1}{z}-\frac{1}{near}}{\frac{1}{far}-\frac{1}{near}}
\end{aligned}
\]</span></p>
<h1 id="深度值的线性可视化">深度值的线性可视化</h1>
<p>经过上面的推导，我们得出了深度值的计算公式。</p>
<p>现在，反过来，我们知道了屏幕空间中的深度值，怎么求出相机空间中的深度值呢？</p>
<p>首先，根据<span
class="math inline">\(\left(3\right)\)</span>，可以推导出： <span
class="math display">\[
z_{ndc} = 2z_{win}-1
\]</span> 对于公式2，得出的是实际坐标的<span
class="math inline">\(Z\)</span>值。为了和OpenGL中的定义统一，也将<span
class="math inline">\(near\)</span>、<span
class="math inline">\(far\)</span>和<span
class="math inline">\(z\)</span>代入公式<span
class="math inline">\(\left(2\right)\)</span>，可以得到： <span
class="math display">\[
\begin{aligned}
z_{eye} &amp;=
\frac{2(-near)(-far)}{((-far)+(-near))-z_{ndc}((-far)-(-near))} \\
&amp;= \frac{2nearfar}{-(far+near)-z_{ndc}(near-far)} \\
\end{aligned}
\tag{5}
\]</span> 在<a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a>这一节中，得出的公式是：
<span class="math display">\[
float \quad linearDepth = (2.0 * near * far) / (far + near - z * (far -
near));
\]</span> 对比发现，跟公式<span
class="math inline">\(\left(5\right)\)</span>有些不一样。这是因为，<span
class="math inline">\(linearDepth\)</span>求出的是顶点距离相机的距离，是正值。而<span
class="math inline">\(z_{eye}\)</span>是顶点的实际坐标，是负值，将<span
class="math inline">\(z_{eye}\)</span>取反，即可得到<span
class="math inline">\(linearDepth\)</span>。 <span
class="math display">\[
\begin{aligned}
linearDepth &amp;= -z_{eye} \\
&amp;= \frac{2nearfar}{(far+near)-z_{ndc}(far-near)}
\end{aligned}
\]</span> 至此，推导完成。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a></li>
<li>[2] <a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/04/04/2020-4-4-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%AD%E7%9A%84%E9%A1%B6%E7%82%B9%E5%8F%98%E6%8D%A2/#more">渲染管线中的顶点变换</a></li>
</ul>
]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>Transformation</tag>
        <tag>Matrices</tag>
      </tags>
  </entry>
  <entry>
    <title>法线贴图那些事儿</title>
    <url>/2020/05/17/2020-5-17-%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>在学习<a
href="https://learnopengl.com/Advanced-Lighting/Normal-Mapping">法线贴图</a>的过程中，有几个比较难以理解的概念，这里记录一下。<strong>特别说一下，本文的法线贴图是切线空间下的法线贴图。</strong><span id="more"></span></p>
<h1 id="空间变换">空间变换</h1>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-5-17/20200523103017.png"
alt="空间变换示意图" />
<figcaption aria-hidden="true">空间变换示意图</figcaption>
</figure>
<p>如上图所示，简单表达了在使用法线贴图的过程中，涉及到的几个空间变换：</p>
<ol type="1">
<li><p>切线空间：从法线贴图中采样得到的法线，在切线空间中；</p></li>
<li><p>对象空间：物体的本地坐标空间，顶点的相关信息，在对象空间；</p></li>
<li><p>世界空间：光源位置、观察者位置等，在世界空间中。</p></li>
</ol>
<p>在空间变换的过程中，主要涉及到了两个变换矩阵：</p>
<ol type="1">
<li><p><span
class="math inline">\(TBN\)</span>矩阵：从切线空间变换到对象空间；</p></li>
<li><p><span
class="math inline">\(Model\)</span>矩阵：从对象空间变换到世界空间。</p></li>
</ol>
<p>对于上述概念，大部分都是比较熟悉的，只有法线贴图、切线空间和<span
class="math inline">\(TBN\)</span>矩阵比较陌生。下面，将分别介绍一下。</p>
<h1 id="法线贴图">法线贴图</h1>
<p>在3D计算机图形学中，法线贴图是一种用于伪造凹凸光照的技术，是凹凸贴图的一种实现。它用于添加细节，而不使用更多的多边形。这种技术的一个常见用途是，通过从高精度多边形或高度图生成法线贴图，来极大地增强低精度多边形的外观和细节。下图来自Paolo
Cignoni，图中对比了两种方式：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-5-17/20200523101852.png"
alt="法线可以使低精度模型实现高精度模型的效果" />
<figcaption
aria-hidden="true">法线可以使低精度模型实现高精度模型的效果</figcaption>
</figure>
<p>法线贴图通常存储为常规RGB图像，其中RGB分量分别对应于表面法线的X，Y和Z坐标。</p>
<p>法线的每个分量的值的范围是<span
class="math inline">\([-1,1]\)</span>，而RGB分量的值的范围是<span
class="math inline">\([0,1]\)</span>。所以，在将法线存储为RGB图像时，需要对每个分量做一个映射：
<span class="math display">\[
vec3 \quad rgb\_normal = normal * 0.5 + 0.5
\]</span>
这里要注意，将法线存储到法线贴图的过程中，需要进行上述操作。当我们从法线贴图中读取到法线数据后，需要进行上述变换的逆变换，即从<span
class="math inline">\([0,1]\)</span>映射到<span
class="math inline">\([-1,1]\)</span>。</p>
<h1 id="切线空间">切线空间</h1>
<p>那么，法线向量应该相对于哪个坐标系呢？我们可以选择模型顶点的的坐标系，即对象空间；也可以选择模型纹理所在的坐标系，即切线空间，也称为纹理空间。</p>
<p>对象空间中，法线信息是相对于对象空间的朝向的，各个方向的法线向量都有，所有贴图看起来色彩比较丰富；而在切线空间中，法线是相对于顶点的，大致指向顶点信息中的法线方向，即法线向量接近于<span
class="math inline">\((0,0,1)\)</span>，映射到RGB是<span
class="math inline">\((0.5,0.5,1)\)</span>，这是一种偏蓝的颜色。下图分别是对象空间和切线空间下的法线纹理。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-5-17/20200523105701.jpg"
alt="对象空间和切线空间下的法线纹理" />
<figcaption
aria-hidden="true">对象空间和切线空间下的法线纹理</figcaption>
</figure>
<p>那么，怎么进行选择呢？考虑一下二者的优缺点：</p>
<ol type="1">
<li><p>重用性：对于对象空间的法线贴图，它是相对于特定对象的，假如应用到其他的对象上，可能效果就不正确了；而切线空间中的法线贴图，记录的是相对法线信息，所以可以把它应用到其他对象上，也能得到正确的结果。</p></li>
<li><p>可压缩：考虑到法线向量是单位向量，而且Z分量总是正的，可以只存储XY方向，而推导出Z方向。</p></li>
</ol>
<p>综上所述，我们一般选择切线空间下的法线贴图。</p>
<h1 id="tbn矩阵"><span class="math inline">\(TBN\)</span>矩阵</h1>
<p>在光照的计算过程中，需要用到光线方向、视线方向和法线方向等，为了得到正确的结果，这些变量必须在同一坐标系下计算。参考一下本文开头的“坐标变换示意图”。</p>
<p>在纹理坐标系中，x和y分量与2D图片的水平方向和垂直方向对齐，而z分量指向图片外部的上方。如下图所示：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-5-17/20200523140057.png"
alt="纹理坐标系" />
<figcaption aria-hidden="true">纹理坐标系</figcaption>
</figure>
<p>为了正确使用贴图中的纹理信息，我们必须找到一种方法——<strong>从切线坐标空间变换到对象空间</strong>。这可以通过指定切线坐标系的坐标轴在对象空间中的方向来达到。</p>
<p>对一个单独的三角形面片来说，我们可以认为纹理贴图覆盖在三角形的表面上，如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2020-5-17/20200523141704.png" /></p>
<p>根据上图，可以得出：三角面片和纹理贴图是<strong>共面</strong>的。那么，根据平行四边形法则，可以得出：
<span class="math display">\[
\begin{matrix}
E_{1} = \Delta U_{1}U + \Delta V_{1}V \\
E_{2} = \Delta U_{2}U + \Delta V_{2}V \\
\end{matrix}
\]</span> 其中，<span class="math inline">\(E_{1}\)</span>和<span
class="math inline">\(E_{2}\)</span>是两个顶点之间的向量差，可以根据顶点的坐标计算出来；<span
class="math inline">\(\Delta U_{1}\)</span>、<span
class="math inline">\(\Delta V_{1}\)</span>、<span
class="math inline">\(\Delta U_{2}\)</span>和<span
class="math inline">\(\Delta
V_{2}\)</span>分别是纹理坐标的水平和垂直方向的差，可以根据纹理坐标计算得到。<span
class="math inline">\(U\)</span>和<span
class="math inline">\(V\)</span>分别是纹理的水平和垂直坐标轴，是要计算的未知量。</p>
<p>写成坐标表示： <span class="math display">\[
\begin{matrix}
\left( E_{1x},E_{1y},E_{1z} \right) = \Delta
U_{1}\left(U_{x},U_{y},U_{z}\right) + \Delta V_{1}\left(
V_{x},V_{y},V_{z} \right) \\
\left( E_{2x},E_{2y},E_{2z} \right) = \Delta
U_{2}\left(U_{x},U_{y},U_{z}\right) + \Delta V_{2}\left(
V_{x},V_{y},V_{z} \right) \\
\end{matrix}
\]</span> 上面的方程，也可以写成矩阵乘法的形式： <span
class="math display">\[
\begin{bmatrix}
E_{1x} &amp; E_{1y} &amp; E_{1z} \\
E_{2x} &amp; E_{2y} &amp; E_{2z} \\
\end{bmatrix}=
\begin{bmatrix}
\Delta U_{1} &amp; \Delta V_{1} \\
\Delta U_{2} &amp; \Delta V_{2} \\
\end{bmatrix}
\begin{bmatrix}
U_{x} &amp; U_{y} &amp; U_{z} \\
V_{x} &amp; V_{y} &amp; V_{z} \\
\end{bmatrix}
\]</span></p>
<p>两边同时乘以<span class="math inline">\(\Delta U \Delta
V\)</span>的逆矩阵，可得： <span class="math display">\[
\begin{bmatrix}
U_{x} &amp; U_{y} &amp; U_{z} \\
V_{x} &amp; V_{y} &amp; V_{z} \\
\end{bmatrix}=
\begin{bmatrix}
\Delta U_{1} &amp; \Delta V_{1} \\
\Delta U_{2} &amp; \Delta V_{2} \\
\end{bmatrix}^{-1}
\begin{bmatrix}
E_{1x} &amp; E_{1y} &amp; E_{1z} \\
E_{2x} &amp; E_{2y} &amp; E_{2z} \\
\end{bmatrix}
\]</span></p>
<p>求逆矩阵不太方便，可以使用<strong>伴随矩阵法</strong>： <span
class="math display">\[
\begin{bmatrix}
U_x &amp; U_y &amp; U_z \\
V_x &amp; V_y &amp; V_z
\end{bmatrix}  =
\frac{1}{\Delta U_1 \Delta V_2 - \Delta U_2 \Delta V_1}
\begin{bmatrix}
\Delta V_2 &amp; -\Delta V_1 \\
-\Delta U_2 &amp; \Delta U_1
\end{bmatrix}
\begin{bmatrix}
E_{1x} &amp; E_{1y} &amp; E_{1z} \\
E_{2x} &amp; E_{2y} &amp; E_{2z}
\end{bmatrix}
\]</span></p>
<p>至此，我们求出了<span class="math inline">\(U\)</span>和<span
class="math inline">\(V\)</span>向量。但是我们需要的构成<span
class="math inline">\(TBN\)</span>空间的坐标轴是正交的，这里求出的<span
class="math inline">\(U\)</span>和<span
class="math inline">\(V\)</span>并不一定能满足正交的条件。这里，顶点的法线<span
class="math inline">\(N\)</span>是已知的，我们可以根据<span
class="math inline">\(U\)</span>、<span
class="math inline">\(V\)</span>和<span
class="math inline">\(N\)</span>，根据<strong>格拉姆-施密特正交化</strong>方法，求出与<span
class="math inline">\(N\)</span>正交的<span
class="math inline">\(T\)</span>和<span
class="math inline">\(B\)</span>（此处假设切线空间是右手坐标系）： <span
class="math display">\[
\begin{aligned}
T &amp;= normalize \left( U - dot \left( U,N \right) * N \right) \\
B &amp;= normalize \left( cross \left( N,T \right) \right) \\
TBN &amp;= mat3 \left( T,B,N \right)
\end{aligned}
\]</span></p>
<p>这样，我们获得了坐标轴相互正交的<span
class="math inline">\(TBN\)</span>矩阵。</p>
<h1 id="实际使用中的法线贴图">实际使用中的法线贴图</h1>
<p>看完上面计算切线空间的<span
class="math inline">\(TBN\)</span>矩阵的部分，估计也是头大。不禁想到，每次使用法线贴图的过程，真的如此麻烦吗？</p>
<p>幸运的是，答案是否定的。</p>
<p>一般情况下，模型存储的顶点信息中，都包含了顶点的法线和切线的数据，这样，我们就不用进行上面的复杂计算了，直接使用法线和切线的叉乘，求出副切线，从而构成<span
class="math inline">\(TBN\)</span>矩阵。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://learnopengl.com/Advanced-Lighting/Normal-Mapping">Normal
Mapping</a></li>
<li>[2] <a
href="https://docs.cryengine.com/display/SDKDOC4/Tangent+Space+Normal+Mapping">Tangent
Space Normal Mapping</a></li>
<li>[3] <a
href="https://zhuanlan.zhihu.com/p/139593847">切线空间（Tangent
Space）完全解析</a></li>
<li>[4] <a href="https://en.wikipedia.org/wiki/Normal_mapping">Normal
Mapping</a></li>
<li>[5] <a
href="http://windsmoon.com/2017/11/28/切线空间-Tangent-Space-的计算与应用/">切线空间(Tangent
Space) 的计算与应用</a></li>
<li>[6] <a href="http://foundationsofgameenginedev.com/">Foundations of
Game Engine Development Volume 2: Rendering</a></li>
</ul>
]]></content>
      <categories>
        <category>图形学</category>
      </categories>
      <tags>
        <tag>Normal Map</tag>
        <tag>Tangent Space</tag>
        <tag>TBN</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(六)：Back facing描边法</title>
    <url>/2021/01/17/2021-01-17-%EF%BC%88%E5%85%AD%EF%BC%89Back%20facing%E6%8F%8F%E8%BE%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>描边，在卡通渲染中是一个非常重要的主题。目前比较流行的描边方法有两种：一种是基于后处理的描边，这种方式相对不容易定制，适用于对复杂场景的描边；一种是过程式描边，通过两次绘制，一次绘制本体，一次绘制描边。<span id="more"></span>本文主要介绍第二种描边方式，在《GUILTY
GEAR Xrd》中称其为Back Facing法。</p>
<h1 id="一基本的实现描边">一、基本的实现描边</h1>
<p>基本思路是通过两次绘制，一次绘制本体，一次绘制描边。</p>
<p>这里就有个问题，两次绘制的顺序怎么处理呢？</p>
<p>经过试验可以发现，两种顺序可以得到相同的结果。</p>
<p>本文使用的顺序是先绘制本体，再绘制描边。参考下图，在片元着色器之前，有个Depth
Test操作，这样，在后绘制描边的时候可以通过深度检测过滤掉本体覆盖的像素，效率更高。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117104333.png" /></p>
<p>在URP中，如果没有设置LightMode，那么URP默认使用SRPDefaultUnlit。所以，可以将绘制本体Pass的LightMode设为SRPDefaultUnlit，而将绘制描边Pass的LightMode设为UniversalForward。这样，就可以实现先绘制本体，再绘制描边的功能了。主要的代码如下：</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">Varyings vert(Attributes <span class="meta">input</span>)</span><br><span class="line">&#123;</span><br><span class="line">    Varyings <span class="meta">output</span> = (Varyings)0;</span><br><span class="line">    </span><br><span class="line">    UNITY_SETUP_INSTANCE_ID(<span class="meta">input</span>);</span><br><span class="line">    UNITY_TRANSFER_INSTANCE_ID(<span class="meta">input</span>, <span class="meta">output</span>);</span><br><span class="line">    UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(<span class="meta">output</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="meta">output</span>.vertex = TransformObjectToHClip(<span class="meta">input</span>.positionOS.xyz);</span><br><span class="line">    </span><br><span class="line">    float3 normal = TransformObjectToWorl<span class="meta">dNormal(</span><span class="meta">input</span>.normalOS);</span><br><span class="line">    float2 offset = TransformWorldToHClipDir(normal).xy;</span><br><span class="line">    <span class="meta">output</span>.vertex.xy += offset <span class="comment">* _Outline;</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">return</span> <span class="meta">output</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时，可以得到如下的结果：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117111142.png" /></p>
<p>查看Frame Debugger，可以发现，确实是先绘制本体，再绘制描边。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117111538.png" /></p>
<h1
id="二到相机距离造成的描边粗细问题">二、到相机距离造成的描边粗细问题</h1>
<p>上面的步骤，得到了一个基本的描边效果。但是当物体远离相机时，可以发现，描边会变细。我们希望得到的，是描边宽度不随物体距离相机远近而变化的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117111857.png" /></p>
<p>这里就需要多提一个知识点。物体变换到投影空间后，x、y代表投影空间下的横纵坐标，z代表投影空间下的深度，w等于-z，w用于后面的齐次除法。我们希望得到的，是在屏幕上显示固定宽度的描边，那么顶点向外延伸的距离就应该是NDC空间下的固定距离，而不是投影空间下的固定距离。于是，在投影空间下计算向外延伸的距离的时候，乘上w的值，这样，在之后的齐次除法中会将坐标值除以w，得到的就是不会随距离相机远近不同的描边宽度了。代码如下：</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"><span class="meta">output</span>.vertex = TransformObjectToHClip(<span class="meta">input</span>.positionOS.xyz);</span><br><span class="line"></span><br><span class="line">float3 normal = TransformObjectToWorl<span class="meta">dNormal(</span><span class="meta">input</span>.normalOS);</span><br><span class="line">float2 offset = TransformWorldToHClipDir(normal).xy;</span><br><span class="line"><span class="meta">output</span>.vertex.xy += offset <span class="comment">* output.vertex.w * _Outline;</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117133827.png" /></p>
<h1
id="三屏幕分辨率造成的非等比缩放问题">三、屏幕分辨率造成的非等比缩放问题</h1>
<p>上面两个部分，得到的都是宽度一致的描边。但是，当试着对得到的offset进行归一化时，就会出现下面这种问题。代码如下：</p>
<figure class="highlight sas"><table><tr><td class="code"><pre><span class="line"><span class="meta">output</span>.vertex = TransformObjectToHClip(<span class="meta">input</span>.positionOS.xyz);</span><br><span class="line"></span><br><span class="line">float3 normal = TransformObjectToWorl<span class="meta">dNormal(</span><span class="meta">input</span>.normalOS);</span><br><span class="line">float2 offset = normalize(TransformWorldToHClipDir(normal).xy);</span><br><span class="line"><span class="meta">output</span>.vertex.xy += offset <span class="comment">* output.vertex.w * _Outline;</span></span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117135246.png" /></p>
<p>这是因为，观察空间变换到投影空间xy会非等比缩放，所以正常的法线在投影空间就是非归一化的。在投影空间下，output.vertex.xy未归一化，如果法线offset归一化了，最后计算得到的偏移值在xy方向上的拉伸程度就会不同。所以，这里不需要对offset归一化。</p>
<p>当然，也可以对offset归一化后，再根据屏幕的宽高比计算出一个系数，将offset.y乘以这个系数，得到一个新的法线，这样也可以解决上面的问题。</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">output.vertex = TransformObjectToHClip(<span class="keyword">input</span>.positionOS.xyz);</span><br><span class="line"></span><br><span class="line">float3 normal = TransformObjectToWorldNormal(<span class="keyword">input</span>.normalOS);</span><br><span class="line">float2 <span class="keyword">offset</span> = normalize(TransformWorldToHClipDir(normal).xy);</span><br><span class="line"></span><br><span class="line">//将近裁剪面右上角位置的顶点变换到观察空间</span><br><span class="line"><span class="type">float4</span> nearUpperRight = mul(unity_CameraInvProjection, <span class="type">float4</span>(<span class="number">1</span>, <span class="number">1</span>, UNITY_NEAR_CLIP_VALUE, _ProjectionParams.y));</span><br><span class="line">//求得屏幕宽高比</span><br><span class="line"><span class="type">float</span> aspect = abs(nearUpperRight.x / nearUpperRight.y);</span><br><span class="line"><span class="keyword">offset</span>.y *= aspect;</span><br><span class="line"></span><br><span class="line">output.vertex.xy += <span class="keyword">offset</span> * output.vertex.w * _Outline;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-01-17/20210117142510.png" /></p>
<p>当然，这种方式相对上一种方式有点麻烦，只是提供一种思路。</p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.5-Outline/Shader/1.5.5-Outline.shader">完整代码</a></p>
<h1 id="四其它的一些技巧">四、其它的一些技巧</h1>
<p>在《罪恶装备-Xrd》的分享中，也提到了在卡通渲染中，其他的一些提升描边质量的方法。比如，使用顶点色存储描边粗细、颜色等，可以更加精细地控制描边。最近在实际的工作中，也遇到一种提升描边效果的方式：根据顶点距离相机的距离，计算出一个参数，在代表描边宽度的渐变贴图中采样，这样，可以定制各种不同距离的描边宽度。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@10.2/manual/urp-shaders/urp-shaderlab-pass-tags.html">URP
ShaderLab Pass tags</a></li>
<li>[2] <a
href="http://www.songho.ca/opengl/gl_projectionmatrix.html">OpenGL
Projection Matrix</a></li>
<li>[3] <a
href="https://zhuanlan.zhihu.com/p/95986273">【02】卡通渲染基本光照模型的实现</a></li>
<li>[4] <a
href="https://zhuanlan.zhihu.com/p/109101851">【01】从零开始的卡通渲染-描边篇</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Outline</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(七)：几种简单的阴影实现</title>
    <url>/2021/01/20/2021-01-20-%EF%BC%88%E4%B8%83%EF%BC%89%E5%87%A0%E7%A7%8D%E7%AE%80%E5%8D%95%E7%9A%84%E9%98%B4%E5%BD%B1%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>再次说明一下，最近的几篇“练习项目”，都是在学习<a
href="https://github.com/KaimaChen/Unity-Shader-Demo">这个Github项目</a>，使用URP重新实现一遍。对于本篇的内容，我也纠结了很久，纠结要不要写本篇博客。因为本篇的内容没有什么知识点，只是介绍了一些比较受限的阴影实现。最后还是决定要写下来，让这个“练习项目”完整一点。
<span id="more"></span></p>
<h1 id="一用面片实现阴影">一、用面片实现阴影</h1>
<p>说起来也是缘分，几年前刚毕业进入一家游戏公司，那时候做的是横版2D游戏，游戏内角色的阴影就是用这种方式实现的。后来也有几款游戏延续了这种实现方式。</p>
<p>这种方式很简单，用一个圆形的面片代表阴影，放在要产生阴影的物体下方，跟随该物体。至于阴影面片的高度，当时的做法是：从产生阴影的物体往下面的地面发射射线，检测到地面，得到的高度就是阴影面片的高度。</p>
<p>这种方式比较受限，只适用于平整的地面。</p>
<p>也不需要写新的Shader，使用Sprite Renderer组件就能实现效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-23/20210123144036.png" /></p>
<h1 id="二平面阴影">二、平面阴影</h1>
<p>之前在听ILRuntime作者在Unity线上技术大会的<a
href="https://www.bilibili.com/video/BV1ca4y1W7wN">演讲</a>时，提到了平面阴影的概念（19:30开始）。</p>
<p>目前自己在做的游戏使用了Unity自带的Shadowmap实现的阴影。在Unity里面看起来效果还行，但是打包到手机上之后，效果很差，会有各种锯齿、抖动。后来按照上面的演讲，试着实现了一版平面阴影，发现阴影的质量真的非常高，在移动端也没有问题。但是发现平面阴影与场景烘焙出的阴影，在融合上有些问题，就暂时没有采用平面阴影。</p>
<p>下面简单介绍一下平面阴影的实现。主要参考了知乎上面的几篇博客，感谢博主的分享。</p>
<p>与上面的演讲的区别是，这里并没有使用Renderer
Feature来实现平面阴影，而是使用了多Pass来实现平面阴影。</p>
<p>第一个Pass用来渲染物体的本身，第二个Pass用来渲染阴影。</p>
<p>渲染阴影的思路：考虑在二维平面系中，已知地面的高度<span
class="math inline">\(h\)</span>，光线的方向<span
class="math inline">\((L_x,L_y)\)</span>，顶点的世界坐标为<span
class="math inline">\((V_x,V_y)\)</span>，那么要求的就是顶点在地面的投影点<span
class="math inline">\((P_x,P_y)\)</span>。由于投影点在地面上，所以<span
class="math inline">\(P_y = h\)</span>。从顶点到投影点的向量为<span
class="math inline">\((P_x-V_x,P_y-V_y)\)</span>，由于是光线经过顶点的投影，所以该向量和光线的方向平行，所以：
<span class="math display">\[
\frac{P_y-V_y}{P_x -V_x} = \frac{L_y}{L_x}
\]</span></p>
<p>所以可以得到： <span class="math display">\[
P_x = \frac{L_x*(P_y-V_y)}{L_y} + V_x
\]</span></p>
<p><span class="math display">\[
P_y = h
\]</span></p>
<p>效果如下图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-23/20210123154752.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.6-Shadow/Shader/1.6.2-PlanarShadow.shader">代码如下</a></p>
<p>当然，如果想改成Renderer
Feature实现平面阴影也很简单，只要把阴影Pass的LightMode改成自定义值，然后在ForwardRenderer里面添加新的Render
Objects即可，然后在Filters设置合适的Layer Mask和Light Mode
Tags即可。注意，本项目的URP版本是8.2.0，不用的版本可能有些名称不同。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-23/20210123155708.png" /></p>
<h1 id="三球体阴影">三、球体阴影</h1>
<p>不知道用“球体阴影”描述是否合适。这种实现方式主要适用于场景中只有球体产生阴影的情况。场景中其它的物体都“知道”球体的坐标和半径，从而可以判断是否在球体的阴影里面。</p>
<p>如下图所示，点L为光源位置，点A为场景中的物体的顶点，B为球形的圆心。点A到球形圆心的向量和点A到光源的向量之间的夹角为<span
class="math inline">\(\alpha\)</span>；C点是垂直于AB向量的圆周上的一点，AB和AC之间的夹角为<span
class="math inline">\(\beta\)</span>。那么，判断点A是否在球形的阴影里面，就是判断<span
class="math inline">\(\alpha\)</span>是否小于<span
class="math inline">\(\beta\)</span>。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-23/20210123163446.png" /></p>
<p>得到的效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-23/20210123163711.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.6-Shadow/Shader/1.6.3-SphereShadow.shader">代码如下</a></p>
<h1 id="四总结">四、总结</h1>
<p>上面介绍的几种阴影的实现方式，可能并不是很通用，但可能对于某种类型的游戏，或者某种情况下，上面的实现也会是一种比较优的方案。这里，只是简单介绍了一下实现的方式，有需要可以继续深入研究。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://zhuanlan.zhihu.com/p/31504088">使用顶点投射的方法制作实时阴影</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Shadow</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(八)：在URP中显示法线图</title>
    <url>/2021/01/23/2021-01-23-%EF%BC%88%E5%85%AB%EF%BC%89%E5%9C%A8URP%E4%B8%AD%E6%98%BE%E7%A4%BA%E6%B3%95%E7%BA%BF%E5%9B%BE/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>在Build
in渲染管线下，获取深度图、法线图很简单。但是在URP下，获取深度图很简单，但是并没有提供对获取法线图的支持。本文主要参考Build
in渲染管线下获取法线图的原理，在URP下获取法线图。 <span id="more"></span></p>
<h1 id="一build-in渲染管线中获取法线图">一、Build
in渲染管线中获取法线图</h1>
<p>在Build
in渲染管线中，获取法线图很简单，在脚本中添加如下代码，然后挂在相机上即可。这样，深度、法线信息就会存储在名为_CameraDepthNormalsTexture的图中，在Shader中可以采样该图获取深度、法线信息。</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">Camera.main.depthTextureMode</span> = DepthTextureMode.DepthNormals<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>使用Frame
Debugger调试，可以发现，渲染法线图的Pass使用的Shader是Hidden/Internal-DepthNormalsTexture。那么，可以想到的一种方式是，模仿该Shader，在URP中添加生成法线图的Pass。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203159.png" /></p>
<h1 id="二urp中获取法线图">二、URP中获取法线图</h1>
<p>从Unity官网下载一份Build
in的Shader文件，解压后，上述的Shader的位置为DefaultResourcesExtra/Internal-DepthNormalsTexture.shader。先关注渲染不透明物体的SubShader，如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">SubShader</span><br><span class="line">&#123;</span><br><span class="line">    Tags &#123; <span class="string">&quot;RenderType&quot;</span> = <span class="string">&quot;Opaque&quot;</span> &#125;</span><br><span class="line">    Pass</span><br><span class="line">    &#123;</span><br><span class="line">        CGPROGRAM</span><br><span class="line">        </span><br><span class="line">        #pragma vertex vert</span><br><span class="line">        #pragma fragment frag</span><br><span class="line">        #<span class="keyword">include</span> <span class="string">&quot;UnityCG.cginc&quot;</span></span><br><span class="line">        <span class="keyword">struct</span> v2f</span><br><span class="line">        &#123;</span><br><span class="line">            float4 pos: SV_POSITION;</span><br><span class="line">            float4 nz: TEXCOORD0;</span><br><span class="line">            UNITY_VERTEX_OUTPUT_STEREO</span><br><span class="line">        &#125;;</span><br><span class="line">        v2f vert(appdata_base v)</span><br><span class="line">        &#123;</span><br><span class="line">            v2f o;</span><br><span class="line">            <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">v</span>)</span>;</span><br><span class="line">            <span class="constructor">UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(<span class="params">o</span>)</span>;</span><br><span class="line">            o.pos = <span class="constructor">UnityObjectToClipPos(<span class="params">v</span>.<span class="params">vertex</span>)</span>;</span><br><span class="line">            o.nz.xyz = COMPUTE_VIEW_NORMAL;</span><br><span class="line">            o.nz.w = COMPUTE_DEPTH_01;</span><br><span class="line">            return o;</span><br><span class="line">        &#125;</span><br><span class="line">        fixed4 frag(v2f i): SV_Target</span><br><span class="line">        &#123;</span><br><span class="line">            return <span class="constructor">EncodeDepthNormal(<span class="params">i</span>.<span class="params">nz</span>.<span class="params">w</span>, <span class="params">i</span>.<span class="params">nz</span>.<span class="params">xyz</span>)</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ENDCG</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在顶点着色器中，通过COMPUTE_VIEW_NORMAL计算出观察空间下的法线，通过COMPUTE_DEPTH_01计算出观察空间中<span
class="math inline">\([0,1]\)</span>范围内的深度值。上述两个方法的具体实现，都可以在UnityCG.cginc文件中找到：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">#define COMPUTE_DEPTH_01 -(<span class="constructor">UnityObjectToViewPos( <span class="params">v</span>.<span class="params">vertex</span> )</span>.z<span class="operator"> * </span><span class="module-access"><span class="module"><span class="identifier">_ProjectionParams</span>.</span></span>w)</span><br><span class="line">#define COMPUTE_VIEW_NORMAL normalize(mul((float3x3)UNITY_MATRIX_IT_MV, v.normal))</span><br></pre></td></tr></table></figure>
<p>在片元着色器中，通过EncodeDepthNormal方法将深度和法线信息渲染到一张图中，而EncodeDepthNormal的具体实现也可以在UnityCG.cginc文件中找到：</p>
<figure class="highlight rsl"><table><tr><td class="code"><pre><span class="line">inline float4 EncodeDepthNormal( <span class="keyword">float</span> <span class="built_in">depth</span>, float3 <span class="keyword">normal</span> )</span><br><span class="line">&#123;</span><br><span class="line">    float4 enc;</span><br><span class="line">    enc.xy = EncodeViewNormalStereo (<span class="keyword">normal</span>);</span><br><span class="line">    enc.zw = EncodeFloatRG (<span class="built_in">depth</span>);</span><br><span class="line">    <span class="keyword">return</span> enc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而EncodeDepthNormal里面又调用了两个内置的方法，同样可以找到：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Encoding/decoding view space normals into 2D 0..1 vector</span></span><br><span class="line">inline float2 EncodeViewNormalStereo( float3 <span class="keyword">n</span> )</span><br><span class="line">&#123;</span><br><span class="line">    float kScale = 1.7777;</span><br><span class="line">    float2 <span class="keyword">enc</span>;</span><br><span class="line">    <span class="keyword">enc</span> = <span class="keyword">n</span>.xy / (<span class="keyword">n</span>.z+1);</span><br><span class="line">    <span class="keyword">enc</span> /= kScale;</span><br><span class="line">    <span class="keyword">enc</span> = <span class="keyword">enc</span>*0.5+0.5;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">enc</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Encoding/decoding [0..1) floats into 8 bit/channel RG. Note that 1.0 will not be encoded properly.</span></span><br><span class="line">inline <span class="built_in">float</span>2 EncodeFloatRG( <span class="built_in">float</span> v )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">float</span>2 kEncodeMul = <span class="built_in">float</span>2(<span class="number">1.0</span>, <span class="number">255.0</span>);</span><br><span class="line">    <span class="built_in">float</span> kEncodeBit = <span class="number">1.0</span>/<span class="number">255.0</span>;</span><br><span class="line">    <span class="built_in">float</span>2 enc = kEncodeMul * v;</span><br><span class="line">    enc = frac (enc);</span><br><span class="line">    enc.x -= enc.y * kEncodeBit;</span><br><span class="line">    <span class="keyword">return</span> enc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样，我们就可以实现把Internal-DepthNormalsTexture.shader改写成符合URP的形式，<a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.7-NormalTex/Shader/Internal-DepthNormalsTexture.shader">代码如下</a>。</p>
<p>Shader有了，怎么调用呢？这里就需要用到了Renderer Feature了。</p>
<p>模仿URP内置的一些Renderer
Feature，我们可以实现自己的获取法线图的Renderer
Feature。这里需要新建两个脚本，一个是DepthNormalsFeature.cs，另一个是DepthNormalsPass.cs。至于具体的原理，可以参考我之前的<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/#more">博客</a>。</p>
<p>然后，在ForwardRenderer资源中添加上述DepthNormalsFeature，这样，就可以调用DepthNormalsPass了。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203419.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203626.png" /></p>
<h1 id="三显示法线图">三、显示法线图</h1>
<p>上面只是生成了法线图，但是如果没有其他操作的话，我们并不能看到法线图。那么怎么才能看到法线图呢？</p>
<p>答案是使用后处理，具体的实现可以参考<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/">练习项目(四)：深度图基础及应用</a>中的“1、渲染深度图”部分。</p>
<p>这里也要新建两个脚本，一个是DisplayNormalTexturePassFeature.cs，另一个是DisplayNormalTexturePass.cs。</p>
<p>然后，在ForwardRenderer资源中添加上述DisplayNormalTexturePassFeature，这样，就可以调用DisplayNormalTexturePass了。</p>
<p>最后，还要实现一个显示法线图的Shader。</p>
<figure class="highlight verilog"><table><tr><td class="code"><pre><span class="line">Varyings vert(Attributes <span class="keyword">input</span>)</span><br><span class="line">&#123;</span><br><span class="line">    Varyings <span class="keyword">output</span> = (Varyings)<span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    UNITY_SETUP_INSTANCE_ID(<span class="keyword">input</span>);</span><br><span class="line">    UNITY_TRANSFER_INSTANCE_ID(<span class="keyword">input</span>, <span class="keyword">output</span>);</span><br><span class="line">    UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(<span class="keyword">output</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">output</span><span class="variable">.vertex</span> = TransformObjectToHClip(<span class="keyword">input</span><span class="variable">.positionOS</span><span class="variable">.xyz</span>);</span><br><span class="line">    <span class="keyword">output</span><span class="variable">.uv</span> = <span class="keyword">input</span><span class="variable">.uv</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//当有多个RenderTarget时，需要自己处理UV翻转问题</span></span><br><span class="line">    #<span class="keyword">if</span> UNITY_UV_STARTS_AT_TOP <span class="comment">//DirectX之类的</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">_</span>MainTex_TexelSize<span class="variable">.y</span> &lt; <span class="number">0</span>) <span class="comment">//开启了抗锯齿</span></span><br><span class="line">        <span class="keyword">output</span><span class="variable">.uv</span><span class="variable">.y</span> = <span class="number">1</span> - <span class="keyword">output</span><span class="variable">.uv</span><span class="variable">.y</span>; <span class="comment">//满足上面两个条件时uv会翻转，因此需要转回来</span></span><br><span class="line">    #endif</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">output</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 frag(Varyings input): SV_Target</span><br><span class="line">&#123;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(<span class="params">input</span>)</span>;</span><br><span class="line"></span><br><span class="line">    half4 normalDepth = <span class="constructor">SAMPLE_TEXTURE2D_X(<span class="params">_CameraDepthNormalsTexture</span>, <span class="params">sampler_CameraDepthNormalsTexture</span>, UnityStereoTransformScreenSpaceTex(<span class="params">input</span>.<span class="params">uv</span>)</span>);</span><br><span class="line">    half3 normal = <span class="constructor">DecodeViewNormalStereo(<span class="params">normalDepth</span>)</span>;</span><br><span class="line">    return half4(normal<span class="operator"> * </span><span class="number">0.5</span> + <span class="number">0.5</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在片元着色器中，DecodeViewNormalStereo方法并不是URP内置的方法，而是从Build
in渲染管线中移植过来的，可以在UnityCG.cginc文件中找到具体实现：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">inline <span class="built_in">float</span>3 DecodeViewNormalStereo( <span class="built_in">float</span>4 enc4 )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">float</span> kScale = <span class="number">1.7777</span>;</span><br><span class="line">    <span class="built_in">float</span>3 nn = enc4.xyz*<span class="built_in">float</span>3(<span class="number">2</span>*kScale,<span class="number">2</span>*kScale,<span class="number">0</span>) + <span class="built_in">float</span>3(-kScale,-kScale,<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">float</span> g = <span class="number">2.0</span> / dot(nn.xyz,nn.xyz);</span><br><span class="line">    <span class="built_in">float</span>3 n;</span><br><span class="line">    n.xy = g*nn.xy;</span><br><span class="line">    n.z = g<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203801.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203819.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.7-NormalTex/Shader/1.7.1-DisplayNormalTexture.shader">代码如下</a></p>
<h1 id="四总结">四、总结</h1>
<p>原本，在Build
in渲染管线中，是很简单的一件事，但是在URP中，却大费周折。而且在URP的文档中，直到最新版的<a
href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@10.2/manual/universalrp-builtin-feature-comparison.html">10.2.2</a>都没有提供支持，以后会不会提供支持还很难说。另外，在URP中获取法线图的相关资料，在中文互联网上基本没有查到，希望本文能对后来者有帮助。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-24/20210123203834.png" /></p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://alexanderameye.github.io/outlineshader">outlineshader</a></li>
<li>[2] <a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/">练习项目(四)：深度图基础及应用</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Normal texture</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(九)：反射、折射相关计算</title>
    <url>/2021/01/25/2021-01-25-%EF%BC%88%E4%B9%9D%EF%BC%89%E5%8F%8D%E5%B0%84%E3%80%81%E6%8A%98%E5%B0%84%E7%9B%B8%E5%85%B3%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>反射、折射，在实现水面、玻璃等效果的时候，都多多少少会用到一些。本文主要简单介绍一些实现反射和折射的知识。使用天空盒来代表环境的信息。
<span id="more"></span></p>
<h1 id="一简单的反射">一、简单的反射</h1>
<p>反射，表现为物体反射它周围的环境。根据观察者的视角，反射会影响到物体本身的颜色表现。镜子就是一个反射性物体，它会根据观察者的视角反射它周围的环境。</p>
<p>在中学的物理课中，应该就学习过入射角、反射角等概念。反射的原理并不难，只是根据视角方向、法线方向，计算出反射方向，用来采样立方体贴图（此处是天空盒）。下图简单描述了这个过程：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124101242.png" /></p>
<p>已知视角方向viewDir、法线方向normal，现在要求的是反射方向reflectDir。这里，有一个内置函数reflect可以得到反射方向。注意上图，视角方向viewDir是从相机指向物体的。但是很多时候，我们计算得到的视角方向都是从物体指向相机的，这时候，使用reflect函数的话，需要对视角方向取反。</p>
<p>获得了反射方向后，就可以使用反射方向对立方体贴图采样，得到反射的环境信息。这一步没什么特别要介绍的，只是使用内置的SAMPLE_TEXTURECUBE函数采样立方体贴图。最后会得到如下的效果：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124112611.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.8-Lighting/Shader/1.8.1-Reflect.shader">代码如下</a></p>
<h1 id="二光照计算与反射">二、光照计算与反射</h1>
<p>上面得到了简单的反射效果，最后物体表现的完全是环境的信息。现在，我们想让体现一部分物体本身的信息。</p>
<p>主要的思路大概是：先计算环境光照、物体的漫反射颜色，得到物体的本身的颜色；然后计算反射环境的颜色。在二者之间做一个插值，这样，既可以体现物体本身的颜色，又可以体现反射的环境颜色。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124112647.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.8-Lighting/Shader/1.8.2-LightingNReflect.shader">代码如下</a></p>
<h1 id="三简单的折射">三、简单的折射</h1>
<p>折射，与反射的原理比较相似。折射是光线由于传播介质的改变而产生的方向变化。在常见的类水表面上所产生的现象就是折射，光线不是直直地传播，而是弯曲了一点。比如将筷子插进水里面，看起来水下面的筷子好像弯了。</p>
<p>当给定入射方向时，我们可以根据斯涅耳定律（Snell's
Law）来计算折射角，当光从介质1沿着和表面法线夹角为<span
class="math inline">\(\theta_1\)</span>的方向斜射入介质2时，我们可以使用如下公式计算折射光线与法线的夹角<span
class="math inline">\(\theta_2\)</span>： <span class="math display">\[
\eta_1 sin\theta_1 = \eta_2 sin\theta_2
\]</span> 其中<span class="math inline">\(\eta_1\)</span>和<span
class="math inline">\(\eta_2\)</span>分别是两种介质的折射率。下图简单描述了这种关系：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124105843.png" /></p>
<p>方便的是，Unity内置的函数refract可以帮助我们计算得到折射的方向。</p>
<p>有了折射方向后，就可以像计算反射一样计算折射了。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124112716.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.8-Lighting/Shader/1.8.3-Refract.shader">代码如下</a></p>
<h1 id="四菲涅尔反射">四、菲涅尔反射</h1>
<p>在上面第二部分，只是简单地在物体本身颜色和环境的反射颜色之间进行插值。但其实为了得到更好的效果，我们一般会使用菲涅尔反射（Fresnel
reflection）来根据视角方向控制反射的程度。</p>
<p>我们一般使用菲涅尔等式来计算菲涅尔反射，菲涅尔等式一般是近似公式，其中一个著名的近似公式就是Schlick菲涅尔近似等式：
<span class="math display">\[
F_{schlick}(v,n)=F_0+(1-F_0)(1-v\cdot n)^5
\]</span> 其中，<span
class="math inline">\(F_0\)</span>是一个反射系数，用来控制菲涅尔反射的强度；<span
class="math inline">\(v\)</span>是视角方向；<span
class="math inline">\(n\)</span>是法线方向。</p>
<p>根据计算的数值，就可以在物体本身的颜色和反射的环境颜色之间进行插值了。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-25/20210124112735.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.8-Lighting/Shader/1.8.4-FresnelReflection.shader">代码如下</a></p>
<h1 id="五总结">五、总结</h1>
<p>本篇文章，没有什么比较复杂的知识，只是简单介绍了反射、折射、菲涅尔方程等内容，用一个简单的过程来对相应的效果产生一个比较直观的印象。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/06%20Cubemaps/#_1">立方体贴图</a></li>
<li>[2] 《Unity Shader入门精要》第10章</li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Reflect</tag>
        <tag>Refract</tag>
        <tag>Fresnel</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(十)：非真实感渲染的几个小知识点</title>
    <url>/2021/01/27/2021-01-27-%EF%BC%88%E5%8D%81%EF%BC%89%E9%9D%9E%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B8%B2%E6%9F%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本篇内容比较简单，主要介绍非真实感渲染中的几种轮廓线实现方法，再介绍一下卡通着色和素描风格的渲染技术。
<span id="more"></span></p>
<h1 id="一表面角度轮廓线">一、表面角度轮廓线</h1>
<p>实现思路：利用视线方向和顶点法线的点积，得到轮廓线的信息。点积越接近0，说明距离轮廓线越近。</p>
<p>这种方式的优点是，只需要一个Pass就可以得到结果，简单、快速。</p>
<p>但缺点也很明显，只适用于某些类型的模型，对于像Cube这样的模型就会有问题。由于这种方法渲染得到的轮廓线宽度不均，实际应用不多。</p>
<p>效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-27/20210127232419.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.9-NPR/Shader/1.9.1-SurfaceAngleSilhouette.shader">代码如下</a></p>
<h1 id="二程序几何轮廓线">二、程序几何轮廓线</h1>
<p>实现思路：使用两个Pass渲染，第一个Pass正常渲染，渲染前面；第二个Pass渲染轮廓线，渲染背面。使用某些技术让背面可见。</p>
<p>下面介绍几种渲染背面的方法。</p>
<p>1、Vertex Normal法</p>
<p>思路：在顶点着色器中把顶点法线变换到观察空间，统一设置变换后法线的Z值，然后，把观察空间的顶点沿着法线方向移动一段距离。最后，变换到裁剪空间中。如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-27/20210127232448.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.9-NPR/Shader/1.9.2-ProceduralGeometrySilhouette-VertexNormal.shader">代码如下</a></p>
<p>2、Z Bias法</p>
<p>思路：在顶点着色器中，把顶点变换到观察空间，然后控制顶点的Z值移动一段距离，最后，变换到裁剪空间中。如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-27/20210127232509.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.9-NPR/Shader/1.9.3-ProceduralGeometrySilhouette-ZBias.shader">代码如下</a></p>
<h1 id="三卡通着色">三、卡通着色</h1>
<p>思路：使用两个Pass渲染。第一个Pass正常渲染；第二个Pass可以直接使用上面的Vertex
Normal法中的轮廓线Pass，用来渲染轮廓线。</p>
<p>主要的内容在正常渲染的Pass。</p>
<p>这里，需要分别计算环境光照、漫反射和高光。</p>
<p>环境光照没什么需要多说的。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half3 ambient = <span class="module-access"><span class="module"><span class="identifier">UNITY_LIGHTMODEL_AMBIENT</span>.</span></span>xyz<span class="operator"> * </span>albedo.rgb;</span><br></pre></td></tr></table></figure>
<p>漫反射部分的话，有些不同。这里不是直接根据法线和光线的点积来计算漫反射颜色。而是使用法线和光线的点积来采样一张渐变纹理，这样，漫反射的明暗变化会更加可控。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span> diff = <span class="constructor">Convert01(<span class="params">dot</span>(<span class="params">normalWS</span>, <span class="params">lightDirWS</span>)</span>);</span><br><span class="line">half3 diffuse = mainLight.color<span class="operator"> * </span>albedo.rgb<span class="operator"> * </span><span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_Ramp</span>, <span class="params">sampler_Ramp</span>, <span class="params">float2</span>(<span class="params">diff</span>, <span class="params">diff</span>)</span>).rgb;</span><br></pre></td></tr></table></figure>
<p>高光部分，也有些不同。根据法线和半向量的点积，与高光阈值比较，控制高光的范围。</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">half <span class="keyword">spec</span> = dot(normalWS, halfDir);</span><br><span class="line">half w = fwidth(<span class="keyword">spec</span>) * <span class="number">2.0</span>;</span><br><span class="line">half3 specular = _SpecularColor.rgb * albedo.rgb * smoothstep(-w, w, <span class="keyword">spec</span> - _SpecularThreshold);</span><br></pre></td></tr></table></figure>
<p>最后，把三者相加得到最终的颜色。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-27/20210127232534.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.9-NPR/Shader/1.9.4-Toon.shader">代码如下</a></p>
<h1 id="四素描风格渲染">四、素描风格渲染</h1>
<p>思路：使用多张纹理，代表不同光照角度下的素描风格。在顶点着色器中，计算顶点法线和光照方向的点积，根据得到的结果，判断应该采样哪几张纹理。最后，在片元着色器中对各张纹理根据权重进行混合，得到最终的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-27/20210127232553.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.9-NPR/Shader/1.9.5-Hatching.shader">代码如下</a></p>
<h1 id="五总结">五、总结</h1>
<p>本篇文章谈的内容比较浅显、杂乱。先对相应的内容有个大概的印象，后面需要的话再详细地对相关知识点进行学习。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] 《Real-Time Rendering 4th Edition》15.2.2节</li>
<li>[2] 《Unity Shader入门精要》第14章</li>
<li>[3] <a
href="https://blog.csdn.net/candycat1992/article/details/45577749">【NPR】漫谈轮廓线的渲染</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>NPR</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(十一)：次表面散射的近似实现</title>
    <url>/2021/01/30/2021-01-30-%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E6%AC%A1%E8%A1%A8%E9%9D%A2%E6%95%A3%E5%B0%84%E7%9A%84%E8%BF%91%E4%BC%BC%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>实时图形中的很多着色模型只考虑光在物体表面的相互作用。但现实世界中，很多物体是半透明的，光射进表面，在材质里散射，然后从与入射点不同的地方退出表面。本文将介绍几种方法，近似实现次表面散射的效果。
<span id="more"></span></p>
<h1 id="一urp中的多光源计算">一、URP中的多光源计算</h1>
<p>在Build
in渲染管线中，要计算多个光源的贡献，一般的方式是使用两个Pass。可以参考《Unity
Shader入门精要》第九章。</p>
<p>但是在URP中，不需要多个Pass，可以在一个Pass中计算。参考URP内置的Lit.shader资源，可以发现计算多光源的方式。</p>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta">#ifdef _ADDITIONAL_LIGHTS</span></span><br><span class="line">    <span class="keyword">uint</span> pixelLightCount = GetAdditionalLightsCount();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">uint</span> lightIndex = <span class="number">0</span>u; lightIndex &lt; pixelLightCount; ++lightIndex)</span><br><span class="line">    &#123;</span><br><span class="line">        Light light = GetAdditionalLight(lightIndex, inputData.positionWS);</span><br><span class="line">        color += LightingPhysicallyBased(brdfData, light, inputData.normalWS, inputData.viewDirectionWS);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#endif</span></span><br></pre></td></tr></table></figure>
<p>主要的思路：使用GetAdditionalLightsCount()方法获得额外的光源数量，然后遍历这些光源；使用GetAdditionalLight()方法获得指定序号的光源信息。然后计算相应光源的贡献，叠加到主光源的贡献上。</p>
<h1 id="二环绕光照">二、环绕光照</h1>
<p>使用经典的兰伯特定律计算漫反射时，使用的公式如下： <span
class="math display">\[
c_{diffuse} = (c_{light}*m_{diffuse})max(0,n \cdot l)
\]</span>
观察上式可以发现，当表面法线和光线的方向垂直时，漫反射提供的照明度为0。</p>
<p>环绕光照对上述公式进行一定的修改，使得光照环绕在物体的周围。这样，那些原本暗色的地方也会有亮度。</p>
<p>下面的代码，显示了如何改变漫反射公式：</p>
<figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">half diffuse = max(<span class="number">0</span>, dot(<span class="name">N</span>, L))<span class="comment">;</span></span><br><span class="line">half wrap_diffuse = max(<span class="number">0</span>, (<span class="name">dot</span>(<span class="name">N</span>, L) + wrap) / (<span class="number">1</span> + wrap))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>其中，环绕值wrap是范围为<span
class="math inline">\([0,1]\)</span>的浮点数，控制光照环绕物体的距离。如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-30/20210130093512.png" /></p>
<p>当wrap为0时，就是标准的兰伯特反射。观察与y轴的交点，原本照明度为0的情况，随着wrap的变化，交点也在变化，表明照明度不为0了。</p>
<p>这里需要用到多光源的计算，参考第一部分的内容。</p>
<p>效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-30/20210130102035.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.10-Subsurface%20Scattering/Shader/1.10.1-WrapLighting.shader">代码如下</a></p>
<h1 id="三快速次表面散射">三、快速次表面散射</h1>
<p>快速次表面散射的实现，主要是根据<a
href="https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/">《Approximating
Translucency for a Fast, Cheap and Convincing Subsurface Scattering
Look》</a>实现的。</p>
<p>主要的思路是：对于不透明材质，光的贡献直接来自光源，相对于光的方向倾斜90度以上的顶点不接受光照（如下左图）；根据演示文稿中提出的模型，半透明材质具有额外的光源贡献，<span
class="math inline">\(-L\)</span>。从几何上来看，<span
class="math inline">\(-L\)</span>可以看作是某些光线实际穿过了材质并到达了另一侧（如下右图）。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-30/20210130095922.png" /></p>
<p>这样，最终的颜色包含两部分，第一部分是正常的照明，另一部分是来自虚拟光源的照明。</p>
<p>计算虚拟光源照明的公式如下： <span class="math display">\[
I_{back} = sarutate(V \cdot -&lt;L + N\delta&gt;)^p*s
\]</span> 其中：</p>
<ul>
<li>L是光源的方向；</li>
<li>V是视线的方向；</li>
<li>N是法线的方向；</li>
<li><span
class="math inline">\(\delta\)</span>是次表面变形参数，该参数迫使向量<span
class="math inline">\(-L\)</span>指向<span
class="math inline">\(N\)</span>；</li>
<li>p（功率）和s（比例）用来改变曲线的属性</li>
</ul>
<p>最终的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-30/20210130102809.png" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.10-Subsurface%20Scattering/Shader/1.10.2-FastSSS.shader">代码如下</a></p>
<h1 id="四总结">四、总结</h1>
<p>本文介绍了两种对次表面散射的近似方法，只是一种近似方法，可能不太适合真实物体渲染。如果需要更详细的介绍，可以参考下面的参考内容。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://developer.nvidia.com/gpugems/gpugems/part-iii-materials/chapter-16-real-time-approximations-subsurface-scattering">Chapter
16. Real-Time Approximations to Subsurface Scattering</a></li>
<li>[2] <a
href="https://gameinstitute.qq.com/community/detail/106613">Unity3D教程：次表面散射的简单实现</a></li>
<li>[3] <a
href="https://www.alanzucconi.com/2017/08/30/fast-subsurface-scattering-1/">Fast
Subsurface Scattering in Unity</a></li>
<li>[4] <a
href="https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/">GDC
2011 – Approximating Translucency for a Fast, Cheap and Convincing
Subsurface Scattering Look</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Subsurface Scattering</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(十二)：URP中自定义后处理实例</title>
    <url>/2021/01/31/2021-01-31-%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89URP%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8E%E5%A4%84%E7%90%86%E5%AE%9E%E4%BE%8B/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>URP项目中，是自带一些后处理效果的，可以通过添加Volume组件来启用相应的效果。那如果想添加自定义的后处理效果呢？<span id="more"></span>之前在<a
href="https://bzyzhang.github.io/bzyzhang.github.io/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/">《练习项目(四)：深度图基础及应用》</a>部分介绍了在URP中添加后处理的方法。这里，基本上还是按照上面介绍的流程，只是代码方面有了一些改变，下面会详细介绍。</p>
<h1 id="一通用的renderer-feature">一、通用的Renderer Feature</h1>
<p>对于一些简单的，只是对图像做一次处理的后处理类型，这里可以实现一个通用的Renderer
Feature，不同的效果可以通过不同的Shader实现。</p>
<p>首先是实现CommonRendererFeature，主要是可以配置后处理的材质，还有可以选择后处理的时机。主要的代码如下：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">CommonRendererFeature</span> : <span class="title">ScriptableRendererFeature</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> Material UsedMaterial;</span><br><span class="line">    <span class="keyword">public</span> RenderPassEvent PassEvent = RenderPassEvent.BeforeRenderingPostProcessing;</span><br><span class="line"></span><br><span class="line">    CommonPass m_ScriptablePass;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">Create</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        m_ScriptablePass = <span class="keyword">new</span> CommonPass(UsedMaterial)</span><br><span class="line">        &#123;</span><br><span class="line">            renderPassEvent = PassEvent</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">AddRenderPasses</span>(<span class="params">ScriptableRenderer renderer, <span class="keyword">ref</span> RenderingData renderingData</span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        <span class="keyword">var</span> dest = RenderTargetHandle.CameraTarget;</span><br><span class="line">        m_ScriptablePass.Setup(renderer.cameraColorTarget, dest);</span><br><span class="line">        renderer.EnqueuePass(m_ScriptablePass);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义了UsedMaterial和PassEvent两个公有变量，暴露出接口。然后初始化CommonPass，再对CommonPass传递一些变量，最后添加进渲染管线中。这里多说一点，在设置PassEvent的时候，一般选择BeforeRenderingPostProcessing，这样，自定义处理后的纹理，还可以继续被URP自带的后处理流程处理。具体的PassEvent需要具体分析。</p>
<p>然后实现CommonPass，这里是主要的操作处理，主要的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">void <span class="constructor">Render(CommandBuffer <span class="params">cmd</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) return;</span><br><span class="line"></span><br><span class="line">    cmd.<span class="constructor">GetTemporaryRT(<span class="params">m_TemporaryColorTexture</span>.<span class="params">id</span>, <span class="params">renderingData</span>.<span class="params">cameraData</span>.<span class="params">cameraTargetDescriptor</span>, FilterMode.Bilinear)</span>;</span><br><span class="line"></span><br><span class="line">    var source = currentTarget;</span><br><span class="line"></span><br><span class="line">    cmd.<span class="constructor">Blit(<span class="params">source</span>, <span class="params">m_TemporaryColorTexture</span>.Identifier()</span>, m_Material);</span><br><span class="line"></span><br><span class="line">    cmd.<span class="constructor">Blit(<span class="params">m_TemporaryColorTexture</span>.Identifier()</span>,source);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先获取一张临时的渲染贴图m_TemporaryColorTexture，与屏幕的宽高等相同；然后，将当前的帧缓冲source中的数据传递给m_TemporaryColorTexture，并进行相应的后处理，这一步是通过cmd.Blit()方式实现的，相应的处理根据m_Material来执行。</p>
<p>此时，m_TemporaryColorTexture中存储的就是经过后处理的图像。最后一步，将m_TemporaryColorTexture中的内容传递给source。这一步要注意，这里如果传递给destination的话，URP自带的最后的FinalPostProcessing就获取不到经过后处理的图像了，所以这里要传递给source，这样，经过自定义的后处理后，还可以经过URP中的后处理。</p>
<p>这样处理的话，需要两次cmd.Blit()操作，消耗比较大。后来又发现另一种实现方式，主要的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">///CommonRendererFeature.cs</span></span><br><span class="line">public <span class="keyword">class</span> CommonRendererFeature : ScriptableRendererFeature</span><br><span class="line">&#123;</span><br><span class="line">    public Material UsedMaterial;</span><br><span class="line">    public RenderPassEvent PassEvent = RenderPassEvent.BeforeRenderingPostProcessing;</span><br><span class="line"></span><br><span class="line">    CommonPass m_ScriptablePass;</span><br><span class="line"></span><br><span class="line">    RenderTargetHandle m_CameraColorAttachment;</span><br><span class="line"></span><br><span class="line">    public override void <span class="constructor">Create()</span></span><br><span class="line">    &#123;</span><br><span class="line">        m_ScriptablePass = <span class="keyword">new</span> <span class="constructor">CommonPass(UsedMaterial)</span></span><br><span class="line">        &#123;</span><br><span class="line">            renderPassEvent = PassEvent</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        m_CameraColorAttachment.<span class="constructor">Init(<span class="string">&quot;_CameraColorTexture&quot;</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public override void <span class="constructor">AddRenderPasses(ScriptableRenderer <span class="params">renderer</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">    &#123;</span><br><span class="line">        m_ScriptablePass.<span class="constructor">Setup(<span class="params">renderer</span>.<span class="params">cameraColorTarget</span>, <span class="params">m_CameraColorAttachment</span>)</span>;</span><br><span class="line">        renderer.<span class="constructor">EnqueuePass(<span class="params">m_ScriptablePass</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">///CommonPass.cs</span></span><br><span class="line">void <span class="constructor">Render(CommandBuffer <span class="params">cmd</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) return;</span><br><span class="line">	</span><br><span class="line">	cmd.<span class="constructor">Blit(<span class="params">currentTarget</span>, <span class="params">destination</span>.Identifier()</span>, m_Material);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要的区别，就是使用“_CameraColorTexture”初始化了m_CameraColorAttachment作为CommonPass的渲染目标。从ForwardRenderer.cs中，可以发现，也有一个m_CameraColorAttachment，应该是对应了颜色缓冲。这样，在CommonPass中，cmd.Blit()相当于currentTarget和destination都指向了颜色缓冲。这样做，也可以达到上面的效果，而且只有一次cmd.Blit()操作。<strong>但是，我并不确定这样做是否合适。有知道的大佬麻烦告知一下。谢谢！</strong></p>
<blockquote>
<p>这里有一点要注意，后处理Shader中必须添加Properties，其中必须有名称为“_MainTex”的属性。否则，cmd.Blit(source,
m_TemporaryColorTexture.Identifier(),
m_Material)这里就无法将source中的纹理传递给Shader。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202230133.png" /></p>
<h2 id="cross-hatching">1、Cross Hatching</h2>
<p>思路：采样纹理信息，计算出颜色的“长度”，然后给定一些阈值，对不同范围，满足一定条件的像素，返回黑色；不满足条件的话，返回白色。这样，就形成交叉条纹的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202124718.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.1-CrossHatching.shader">代码如下</a></p>
<h2 id="thermal-vision">2、Thermal Vision</h2>
<p>思路：采样纹理信息，计算出颜色值的亮度值，然后使用亮度值在三个颜色之间插值。这样，整个画面好像热视图一样的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202124741.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.2-ThermalVision.shader">代码如下</a></p>
<h2 id="dream-vision">3、Dream Vision</h2>
<p>思路：采样像素及其周围的9个点，然后把颜色相加除以9，这一步，主要是对纹理进行模糊；最后，把得到的颜色，对R、G、B三个通道相加取平均。得到一种黑白化的画面。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202124916.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.3-DreamVision.shader">代码如下</a></p>
<h2 id="edge-detection-by-sobel">4、Edge Detection By Sobel</h2>
<p>思路：使用Sobel算子根据颜色值进行边界检测。主要是对像素点周围的9个像素值采样，再根据Sobel算子计算，判断该像素点是不是边界。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202124936.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.4-EdgeDetectionBySobel.shader">代码如下</a></p>
<h2 id="lens-circle">5、Lens Circle</h2>
<p>思路：采样纹理，根据UV距离中心的距离，在内圆半径和外圆半径之间插值，根据插值结果与采样得到的纹理颜色相乘。这样，就可以得到内圆内正常显示，外圆外是黑色的，内圆和外圆之间是一个渐变色的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202124957.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.5-LensCircle.shader">代码如下</a></p>
<h2 id="pixelation">6、Pixelation</h2>
<p>思路：使用一个变量PixelSize对UV先进行缩小，然后使用floor()操作，向下取整，在使用PixelSize进行放大。最后用处理后的UV采样，这样，就可以得到像素化的效果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125018.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.6-Pixelation.shader">代码如下</a></p>
<h2 id="posterization">7、Posterization</h2>
<p>思路：采样纹理，对采样得到的颜色值先使用Num进行放大，然后使用floor()操作，向下取整；再使用Num进行缩小，得到最终的颜色。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125042.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.7-Posterization.shader">代码如下</a></p>
<h2
id="brightnesssaturationcontrast">8、Brightness、Saturation、Contrast</h2>
<p>思路：这里主要是使用亮度、饱和度和对比度对纹理采样的颜色进行处理。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125102.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.8-BSC.shader">代码如下</a></p>
<h1 id="二gaussian-blur">二、Gaussian Blur</h1>
<p>这里，具体的原理思路可以参考《Unity
Shader入门精要》12.4高斯模糊一节。Shader部分的代码基本相同。这里要说一下的是C#部分的代码改动比较多。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">void <span class="constructor">Render(CommandBuffer <span class="params">cmd</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) return;</span><br><span class="line"></span><br><span class="line">    var source = currentTarget;</span><br><span class="line"></span><br><span class="line">    RenderTextureDescriptor opaqueDesc = renderingData.cameraData.cameraTargetDescriptor;</span><br><span class="line"></span><br><span class="line">    opaqueDesc.width /= m_DownSample;</span><br><span class="line"></span><br><span class="line">    opaqueDesc.height /= m_DownSample;</span><br><span class="line"></span><br><span class="line">    opaqueDesc.depthBufferBits = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    cmd.<span class="constructor">GetTemporaryRT(<span class="params">bufferTex0</span>.<span class="params">id</span>, <span class="params">opaqueDesc</span>, FilterMode.Bilinear)</span>;</span><br><span class="line">    cmd.<span class="constructor">GetTemporaryRT(<span class="params">bufferTex1</span>.<span class="params">id</span>, <span class="params">opaqueDesc</span>, FilterMode.Bilinear)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">bufferTex0</span>.Identifier()</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; m_Iterations; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        gaussianBlurMat.<span class="constructor">SetFloat(<span class="string">&quot;_BlurSize&quot;</span>, 1.0f + <span class="params">i</span> <span class="operator">*</span> <span class="params">m_BlurSpread</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex0</span>.Identifier()</span>, bufferTex1.<span class="constructor">Identifier()</span>, gaussianBlurMat, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex1</span>.Identifier()</span>, bufferTex0.<span class="constructor">Identifier()</span>, gaussianBlurMat, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex0</span>.Identifier()</span>, source);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面，获取了两张临时的纹理，用来进行交换模糊。模糊结束后，还要将最终的模糊纹理传递给source，这样，URP中的自带的后处理可以对模糊后的图像继续处理。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125129.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.9-GaussianBlur.shader">代码如下</a></p>
<h1 id="三bloom">三、Bloom</h1>
<p>具体的原理思路可以参考《Unity
Shader入门精要》12.5Bloom效果一节，这里介绍一下不同的地方。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">void <span class="constructor">Render(CommandBuffer <span class="params">cmd</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">       &#123;</span><br><span class="line">           <span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) return;</span><br><span class="line"></span><br><span class="line">           var source = currentTarget;</span><br><span class="line"></span><br><span class="line">           RenderTextureDescriptor opaqueDesc = renderingData.cameraData.cameraTargetDescriptor;</span><br><span class="line"></span><br><span class="line">           opaqueDesc.width /= m_DownSample;</span><br><span class="line"></span><br><span class="line">           opaqueDesc.height /= m_DownSample;</span><br><span class="line"></span><br><span class="line">           opaqueDesc.depthBufferBits = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">           cmd.<span class="constructor">GetTemporaryRT(<span class="params">bufferTex0</span>.<span class="params">id</span>, <span class="params">opaqueDesc</span>, FilterMode.Bilinear)</span>;</span><br><span class="line">           cmd.<span class="constructor">GetTemporaryRT(<span class="params">bufferTex1</span>.<span class="params">id</span>, <span class="params">opaqueDesc</span>, FilterMode.Bilinear)</span>;</span><br><span class="line"></span><br><span class="line">           bloomMat.<span class="constructor">SetFloat(<span class="string">&quot;_LuminanceThreshold&quot;</span>, <span class="params">m_LuminanceThreshold</span>)</span>;</span><br><span class="line"></span><br><span class="line">           <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">bufferTex0</span>.Identifier()</span>, bloomMat, EXTRACT_PASS);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; m_Iterations; i++)</span><br><span class="line">           &#123;</span><br><span class="line">               bloomMat.<span class="constructor">SetFloat(<span class="string">&quot;_BlurSize&quot;</span>, 1.0f + <span class="params">i</span> <span class="operator">*</span> <span class="params">m_BlurSpread</span>)</span>;</span><br><span class="line"></span><br><span class="line">               <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex0</span>.Identifier()</span>, bufferTex1.<span class="constructor">Identifier()</span>, bloomMat, GAUSSIAN_HOR_PASS);</span><br><span class="line"></span><br><span class="line">               <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex1</span>.Identifier()</span>, bufferTex0.<span class="constructor">Identifier()</span>, bloomMat, GAUSSIAN_VERT_PASS);</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           cmd.<span class="constructor">SetGlobalTexture(<span class="string">&quot;_BloomTex&quot;</span>, <span class="params">bufferTex0</span>.Identifier()</span>);</span><br><span class="line">           <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">bufferTex1</span>.Identifier()</span>, bloomMat, BLOOM_PASS);</span><br><span class="line"></span><br><span class="line">           <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">bufferTex1</span>.Identifier()</span>, source);</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p>主要的思路是，先提取原始纹理中亮度超过一定阈值的区域，传递到临时纹理bufferTex0中；然后使用高斯模糊在bufferTex0和bufferTex1之间进行迭代操作；再然后，把原始纹理和模糊后的纹理进行叠加；最后，还要把叠加后的纹理传递回source。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125151.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.10-Bloom.shader">代码如下</a></p>
<h1 id="四motion-blur">四、Motion Blur</h1>
<p>具体的原理思路可以参考《Unity
Shader入门精要》12.6运动模糊一节，这里不再详细介绍。主要的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">void <span class="constructor">Render(CommandBuffer <span class="params">cmd</span>, <span class="params">ref</span> RenderingData <span class="params">renderingData</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (renderingData.cameraData.isSceneViewCamera) return;</span><br><span class="line"></span><br><span class="line">    var source = currentTarget;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m_LastRT<span class="operator"> == </span>null<span class="operator"> || </span>m_LastRT.width != renderingData.cameraData.cameraTargetDescriptor.width<span class="operator"> || </span>m_LastRT.height != renderingData.cameraData.cameraTargetDescriptor.height)</span><br><span class="line">    &#123;</span><br><span class="line">        Object.<span class="constructor">DestroyImmediate(<span class="params">m_LastRT</span>)</span>;</span><br><span class="line">        m_LastRT = <span class="keyword">new</span> <span class="constructor">RenderTexture(<span class="params">renderingData</span>.<span class="params">cameraData</span>.<span class="params">cameraTargetDescriptor</span>)</span>;</span><br><span class="line">        m_LastRT.hideFlags = HideFlags.HideAndDontSave;</span><br><span class="line">        <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">m_LastRT</span>)</span>;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    m_LastRT.<span class="constructor">MarkRestoreExpected()</span>;</span><br><span class="line"></span><br><span class="line">    m_Material.<span class="constructor">SetFloat(<span class="string">&quot;_BlurAmount&quot;</span>,<span class="params">m_BlurAmount</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">source</span>, <span class="params">m_LastRT</span>, <span class="params">m_Material</span>)</span>;</span><br><span class="line">    <span class="constructor">Blit(<span class="params">cmd</span>, <span class="params">m_LastRT</span>, <span class="params">source</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里有个问题，书上是在Build
in管线实现的，在OnDisable()的时候，会销毁m_LastRT。<strong>但是在Renderer
Feature中，目前没有发现类似的接口。那么这里可能要使用一些方式自己处理销毁了。这里如果有更好的方法，麻烦告知！</strong></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-1-31/20210202125247.gif" /></p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.11-MotionBlur.shader">代码如下</a></p>
<h1 id="五总结">五、总结</h1>
<p>本篇主要介绍了一些URP中的自定义后处理。与Build
in管线相比，Shader部分的变化并不大，只是这里是使用Renderer
Feature实现的后处理，差别还是有的，但类比之后，还是比较容易上手的。最后说一下，这些流程、效果都是本人自己学习的，目前没有用到实际的项目中，有需要的话，请自行辨别。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] 《Unity Shader入门精要》第12章</li>
<li>[2] <a
href="https://www.geeks3d.com/20091027/shader-library-posterization-post-processing-effect-glsl/">Posterization
Post Processing Effect (GLSL)</a></li>
<li>[3] <a
href="https://learnopengl-cn.github.io/05%20Advanced%20Lighting/07%20Bloom/">泛光</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Post Processing</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(十三)：简单地实现PBR</title>
    <url>/2021/02/28/2021-02-28-%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%E7%AE%80%E5%8D%95%E5%9C%B0%E5%AE%9E%E7%8E%B0PBR/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>本文主要参考《Unity Shader 入门精要》中<a
href="http://candycat1992.github.io/unity_shaders_book/unity_shaders_book_chapter_18.pdf">改版后的第18章</a>实现基于物理的渲染。<span id="more"></span>之前有很多次，在学习《Unity
Shader 入门精要》中的PBR章节和《Learn
OpenGL》中的PBR章节时，看到很长的推导篇幅，就望而却步，一直没有比较完整地实现一遍PBR。这次静下心来完整地看了一遍《Unity
Shader 入门精要》中<a
href="http://candycat1992.github.io/unity_shaders_book/unity_shaders_book_chapter_18.pdf">改版后的第18章</a>实现基于物理的渲染，发现没有自己想象中的那么复杂。其实基本上都是围绕渲染方程来展开的。这里，不会一步步地推导各种公式、方程，只会给出最终要用到的公式，具体的推导过程，还是推荐看看<a
href="http://candycat1992.github.io/unity_shaders_book/unity_shaders_book_chapter_18.pdf">改版后的第18章</a>。</p>
<h1 id="一公式">一、公式</h1>
<h2 id="渲染方程">1、渲染方程</h2>
<p>从整体上来看，都是围绕<strong><em>渲染方程</em></strong>的： <span
class="math display">\[
L_o(v)=L_e(v) + \int_{\Omega}
f(\omega_i,v)L_i{\omega_i}(n\cdot\omega_i)\, d\omega_i
\]</span> 简单地解释一下上面的公式：给的观察视角<span
class="math inline">\(v\)</span>，该方向上的出射辐射率<span
class="math inline">\(L_o(v)\)</span>等于该点向观察方向发出的自发光辐射率<span
class="math inline">\(L_e(v)\)</span>加上所有有效的入射光<span
class="math inline">\(L_i(\omega_i)\)</span>到达观察点的辐射率积分和。下图给出了渲染方程各个部分的通俗解释。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-2-28/20210301115247.png" /></p>
<p>渲染方程式图形学中的核心公式，当去掉其中的自发光项之后，剩余的部分就是著名的<strong><em>反射等式</em></strong>。我们可以这样理解反射等式：想象我们现在要计算表面上某点的出射辐射率，我们已知到该点的观察方向，该点的出射辐射率是由从许多不同方向的入射辐射率叠加后的结果。其中，<span
class="math inline">\(f(\omega_i,v)\)</span>表示了不同方向的入射光在该观察方向上的权重分布。我们把这些不同方向的光辐射率（<span
class="math inline">\((L_i(\omega_i))\)</span>部分）乘以观察方向上所占的权重（<span
class="math inline">\(f(\omega_i,v)\)</span>部分），再乘以它们在该表面的投影结果（<span
class="math inline">\((n\cdot\omega_i)\)</span>部分），最后再把这些值加起来（即积分操作）就是最后的出射辐射率。</p>
<p>在实时渲染中，自发光项通常就是直接加上某个自发光值。除此之外，积分累加部分在实时渲染中也基本无法实现，因此积分部分通常会被若干精确光源的叠加所替代。</p>
<h2 id="精确光源">2、精确光源</h2>
<p>对于一个精确光源来说，我们使用<span
class="math inline">\(l_c\)</span>来表示它的方向，使用<span
class="math inline">\(c_{light}\)</span>表示它的颜色。使用精确光源的最大好处是，我们可以大大简化上面的反射等式，不用计算积分了。我们可以使用下面的等式来计算它在某个观察方向<span
class="math inline">\(v\)</span>上的出射辐射率： <span
class="math display">\[
L_o(v)=\pi f(l_c,v)c_{light}(n\cdot l_c)
\]</span>
和之前使用积分形式的原始公式相比，上面的式子使用一个特定的方向的<span
class="math inline">\(f(l_c,v)\)</span>值来代替积分操作，这大大简化了计算。如果场景中包含了多个精确光源，我们可以把它们分别代入上面的式子进行计算，然后把它们的结果相加即可。也就是说，反射等式可以简化成下面的形式：
<span class="math display">\[
L_o(v)=\sum_{i=0}^{n}L_o^i(v)=\sum_{i=0}^{n}\pi f(l_c^i,v)c_{light}(n
\cdot l_c^i)
\]</span> 那么，剩下的问题就是，<span
class="math inline">\(f(l_c,v)\)</span>项怎么算呢？<span
class="math inline">\(f(l_c,v)\)</span>实际上描述了当前点事如何与入射光线进行交互的：当给定某个入射方向的入射光后，有多少百分比的光照被反射到了观察方向上。在图形学中，这一项有一个专门的名字，那就是双向反射分布函数，即<strong><em>BRDF</em></strong>。</p>
<h2 id="brdf">3、BRDF</h2>
<p>BRDF可以用于描述两种不同的物理现象：表面反射和次表面散射。针对每种现象，BRDF通常会包含一个单独的部分来描述它们。用于描述次表面散射的被称为<strong>漫反射项</strong>，以及用于描述表面反射的部分被称为<strong>高光反射项</strong>。</p>
<h3 id="漫反射项">（1）漫反射项</h3>
<p>有很多种实现方式，这里直接给出下面会用到的公式： <span
class="math display">\[
f_{diff}(l,v)=\frac{baseColor}{\pi}(1+(F_{D90}-1)(1-n\cdot
l)^5)(1+(F_{D90}-1)(1-n\cdot v)^5)
\]</span> 其中： <span class="math display">\[
F_{D90}=0.5+2*roughness*(h\cdot l)^2
\]</span> <span
class="math inline">\(baseColor\)</span>是表面颜色。通常由纹理采样得到，<span
class="math inline">\(roughness\)</span>是表面的粗糙度。</p>
<p>在Unity中的实现代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">inline half3 <span class="constructor">CustomDisneyDiffuseTerm(<span class="params">half</span> NdotV, <span class="params">half</span> NdotL, <span class="params">half</span> LdotH, <span class="params">half</span> <span class="params">roughness</span>, <span class="params">half3</span> <span class="params">baseColor</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    half fd90 = <span class="number">0.5</span> + <span class="number">2</span><span class="operator"> * </span>LdotH<span class="operator"> * </span>LdotH<span class="operator"> * </span>roughness;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Two schlick fresnel term</span></span><br><span class="line">    half lightScatter = <span class="number">1</span> + (fd90 - <span class="number">1</span>)<span class="operator"> * </span>pow(<span class="number">1</span> - NdotL, <span class="number">5</span>);</span><br><span class="line">    half viewScatter = <span class="number">1</span> + (fd90 - <span class="number">1</span>)<span class="operator"> * </span>pow(<span class="number">1</span> - NdotV, <span class="number">5</span>);</span><br><span class="line">    </span><br><span class="line">    return baseColor<span class="operator"> * </span>INV_PI<span class="operator"> * </span>lightScatter<span class="operator"> * </span>viewScatter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="高光反射项">（2）高光反射项</h3>
<p>基于微面元理论，BRDF的高光反射项科研用下面的通用形式来表示： <span
class="math display">\[
f_{spec}(l,v)=\frac{F(l,h)G(l,v,h)D(h)}{4*(n \cdot l)(n \cdot v)}
\]</span> 这就是著名的Torrane-Sparrow微面元模型。</p>
<p><span
class="math inline">\(D(h)\)</span>是微面元的法线分布函数，它用于计算有多少比例的微面元的法线满足<span
class="math inline">\(m=h\)</span>，只有这部分微面元才会把光线从<span
class="math inline">\(l\)</span>方向反射到<span
class="math inline">\(v\)</span>方向上。</p>
<p><span
class="math inline">\(G(l,v,h)\)</span>是阴影-遮掩函数，它用于计算那些满足<span
class="math inline">\(m=h\)</span>的微面元中有多少会由于遮挡而不会被人眼看到，因此它给出了活跃的微面元所占的浓度，只有活跃的微面元才会成功地把光线反射到观察方向上。</p>
<p><span
class="math inline">\(F(l,h)\)</span>则是这些活跃微面元的菲涅尔反射函数，它可以告诉我们每个活跃的微面元会把多少入射光线反射到观察方向上，即表示了反射光线占入射光线的比率。</p>
<p>最后，分母<span class="math inline">\(4*(n \cdot l)(n \cdot
v)\)</span>是用于校正从微面元的局部空间到整体宏观表面数量差异的校正因子。</p>
<h4 id="a菲涅尔反射函数">a、菲涅尔反射函数</h4>
<p>大多数PBS实现选择使用Schlick菲涅尔近似等式来得到近似的菲涅尔反射效果：
<span class="math display">\[
F_{Schlick}(l,h)=c_{spec} + (1-c_{spec})(1-(l \cdot h))^5
\]</span> 其中，<span
class="math inline">\(c_{spec}\)</span>是材质的高光反射颜色。在金属工作流和高光反射工作流中，<span
class="math inline">\(c_{spec}\)</span>的计算是不同的，这里要注意。</p>
<p>在Unity中的实现代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">inline half3 <span class="constructor">CustomFresnelTerm(<span class="params">half3</span> <span class="params">c</span>, <span class="params">half</span> <span class="params">cosA</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    half t = pow(<span class="number">1</span> - cosA, <span class="number">5</span>);</span><br><span class="line">    return c + (<span class="number">1</span> - c)<span class="operator"> * </span>t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="b法线分布函数">b、法线分布函数</h4>
<p>这里选择的法线分布函数是GGX分布，它的公式如下： <span
class="math display">\[
D_{GGX}(h)=\frac{\alpha ^ 2}{\pi ((\alpha ^2 -1)(n \cdot h)^2 + 1)^2}
\]</span> 其中： <span class="math display">\[
\alpha = roughness^2
\]</span> <span
class="math inline">\(roughness\)</span>是与表面粗糙度有关的参数。</p>
<p>在Unity中的实现代码如下：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">inline</span> half CustomGGXTerm(half NdotH, half roughness)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attribute">half</span> a2 = roughness * roughness;</span><br><span class="line">    <span class="attribute">half</span> d = (NdotH * a2 - NdotH) * NdotH + <span class="number">1</span>.0f;</span><br><span class="line">    <span class="attribute">return</span> INV_PI * a2 / (d * d + 1e-7f);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的<span
class="math inline">\(1e-7f\)</span>是为了避免分母为0。</p>
<h4 id="c阴影-遮挡函数">c、阴影-遮挡函数</h4>
<p>Unity为基于GGX的PBS模型改用了Smith-Joint阴影-遮挡函数，公式如下：
<span class="math display">\[
\frac{G_{smithJoint}(l,v,h)}{(n \cdot l)(n \cdot v)} \approx \frac{2}
{(n \cdot l)((n \cdot v)(1-\alpha_g)+\alpha_g) + (n \cdot v)((n \cdot
l)(1-\alpha_g)+\alpha_g)}
\]</span> 回顾上面高光反射项的公式： <span class="math display">\[
f_{spec}(l,v)=\frac{F(l,h)G(l,v,h)D(h)}{4*(n \cdot l)(n \cdot v)}
\]</span>
可以发现，上面实现的并不单单是G项，还包括了分母的部分。所以上面的就不是纯粹的阴影-遮挡函数了，一般叫做可见性项。</p>
<p>在Unity中的实现代码如下：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">inline</span> half CustomSmithJointGGXVisibilityTerm(half NdotL, half NdotV, half roughness)</span><br><span class="line">&#123;</span><br><span class="line">    half <span class="built_in">a2</span> = roughness * roughness<span class="comment">;</span></span><br><span class="line">    half lambdaV = NdotL * (NdotV * (<span class="number">1</span> - <span class="built_in">a2</span>) + <span class="built_in">a2</span>)<span class="comment">;</span></span><br><span class="line">    half lambdaL = NdotV * (NdotL * (<span class="number">1</span> - <span class="built_in">a2</span>) + <span class="built_in">a2</span>)<span class="comment">;</span></span><br><span class="line">    </span><br><span class="line">    return <span class="number">0</span>.<span class="number">5</span>f / (lambdaV + lambdaL + <span class="number">1</span>e-<span class="number">5</span>f)<span class="comment">;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里可以有些疑惑，代码的实现跟上面的公式不同啊？这是因为，把反射项的分母4也计算在内了。</p>
<h1 id="二ibl">二、IBL</h1>
<p>为了得到更加真实的效果，还需要计算基于图形的光照部分（IBL）。</p>
<p>在Unity中一般是通过反射探针实现的。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">//IBL</span></span><br><span class="line">half perceptualRoughness = roughness<span class="operator"> * </span>(<span class="number">1.7</span> - <span class="number">0.7</span><span class="operator"> * </span>roughness);</span><br><span class="line">half mip = perceptualRoughness<span class="operator"> * </span><span class="number">6</span>;</span><br><span class="line">half4 envMap = <span class="constructor">SAMPLE_TEXTURECUBE_LOD(<span class="params">unity_SpecCube0</span>, <span class="params">samplerunity_SpecCube0</span>, <span class="params">reflDirWS</span>, <span class="params">mip</span>)</span>;</span><br><span class="line">half grazingTerm = saturate((<span class="number">1</span> - roughness) + (<span class="number">1</span> - oneMinusReflectivity));</span><br><span class="line">half surfaceReduction = <span class="number">1.0</span><span class="operator"> / </span>(roughness<span class="operator"> * </span>roughness + <span class="number">1.0</span>);</span><br><span class="line">half3 indirectSpecular = surfaceReduction<span class="operator"> * </span>envMap.rgb<span class="operator"> * </span><span class="constructor">CustomFresnelLerp(<span class="params">specColor</span>, <span class="params">grazingTerm</span>, <span class="params">nv</span>)</span>;</span><br></pre></td></tr></table></figure>
<p>主要就是根据粗糙度对环境贴图进行LOD采样。</p>
<p>为了给IBL添加更加真实的菲涅尔反射，我们对高光反射颜色和掠射颜色grazingTerm进行菲涅尔插值。除此之外，还使用了由粗糙度计算得到的surfaceReduction参数进一步对IBL进行修正。CustomFresnelLerp函数的代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">inline half3 <span class="constructor">CustomFresnelLerp(<span class="params">half3</span> <span class="params">c0</span>, <span class="params">half3</span> <span class="params">c1</span>, <span class="params">half</span> <span class="params">cosA</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    half t = pow(<span class="number">1</span> - cosA, <span class="number">5</span>);</span><br><span class="line">    return lerp(c0, c1, t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它的实现和回去实现的CustomFresnelTerm函数很类似，不同的是这里使用参数<span
class="math inline">\(t\)</span>来混合两个颜色。</p>
<p>最后，只需要按照渲染方程把所有项加起来即可。</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">half3 col = emissionTerm + PI * (<span class="keyword">diffuseTerm </span>+ specularTerm) * mainLight.color * nl * mainLight.<span class="keyword">distanceAttenuation </span>* mainLight.<span class="keyword">shadowAttenuation</span></span><br><span class="line"><span class="keyword"> </span>               + indirectSpecular;</span><br></pre></td></tr></table></figure>
<h1 id="三两种工作流">三、两种工作流</h1>
<p>在Unity实现的PBR中，包含了两种工作流：高光反射工作流、金属工作流。它们之间的区别，只是参数的获取方式不同，最后使用的渲染方程都是上面介绍的。下面分布介绍一下二者。</p>
<h2 id="高光反射工作流">1、高光反射工作流</h2>
<p>先看下属性：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">_Color</span> (<span class="string">&quot;Color&quot;</span>, Color) = (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="attribute">_MainTex</span> (<span class="string">&quot;Albedo&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_Glossiness</span> (<span class="string">&quot;Smoothness&quot;</span>, Range(<span class="number">0</span>.<span class="number">0</span>, <span class="number">1</span>.<span class="number">0</span>)) = <span class="number">0</span>.<span class="number">5</span></span><br><span class="line"><span class="attribute">_SpecColor</span> (<span class="string">&quot;Specular&quot;</span>, Color) = (<span class="number">0</span>.<span class="number">2</span>, <span class="number">0</span>.<span class="number">2</span>, <span class="number">0</span>.<span class="number">2</span>)</span><br><span class="line"><span class="attribute">_SpecGlossMap</span> (<span class="string">&quot;Specular (RGB) Smoothness (A)&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_BumpScale</span> (<span class="string">&quot;Bump Scale&quot;</span>, Float) = <span class="number">1</span>.<span class="number">0</span></span><br><span class="line"><span class="attribute">_BumpMap</span> (<span class="string">&quot;Normal Map&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;bump&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_EmissionColor</span> (<span class="string">&quot;Color&quot;</span>, Color) = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="attribute">_EmissionMap</span> (<span class="string">&quot;Emission&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br></pre></td></tr></table></figure>
<p>比较特别的是，定义了高光反射的颜色和高光反射贴图。光滑值保存在_SpecGlossMap贴图的a通道中。高光颜色由_SpecColor和_SpecGlossMap的rgb通道相乘得到。</p>
<p>主要计算过程如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 specGloss = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_SpecGlossMap</span>, <span class="params">sampler_SpecGlossMap</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">specGloss.a *= _Glossiness;</span><br><span class="line">half3 specColor = <span class="module-access"><span class="module"><span class="identifier">_SpecColor</span>.</span></span>rgb<span class="operator"> * </span>specGloss.rgb;</span><br><span class="line">half roughness = <span class="number">1.0</span> - specGloss.a;</span><br><span class="line"></span><br><span class="line">half oneMinusReflectivity = <span class="number">1.0</span> - max(max(specColor.r, specColor.g), specColor.b);</span><br><span class="line"></span><br><span class="line">half3 albedo = <span class="module-access"><span class="module"><span class="identifier">_Color</span>.</span></span>rgb<span class="operator"> * </span><span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>.rgb;</span><br><span class="line">half3 diffColor = albedo<span class="operator"> * </span>oneMinusReflectivity;</span><br></pre></td></tr></table></figure>
<p>然后就是根据公式进行计算。这里不再赘述。</p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/2.1-PBR/Shader/2.1.1-CustomSpecularPBR.shader">代码如下</a></p>
<h2 id="金属工作流">2、金属工作流</h2>
<p>属性：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">_Color</span> (<span class="string">&quot;Color&quot;</span>, Color) = (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="attribute">_MainTex</span> (<span class="string">&quot;Albedo&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_Glossiness</span> (<span class="string">&quot;Smoothness&quot;</span>, Range(<span class="number">0</span>.<span class="number">0</span>, <span class="number">1</span>.<span class="number">0</span>)) = <span class="number">0</span>.<span class="number">5</span></span><br><span class="line"><span class="attribute">_MetallicGlossMap</span> (<span class="string">&quot;Metallic&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_BumpScale</span> (<span class="string">&quot;Bump Scale&quot;</span>, Float) = <span class="number">1</span>.<span class="number">0</span></span><br><span class="line"><span class="attribute">_BumpMap</span> (<span class="string">&quot;Normal Map&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;bump&quot;</span> &#123; &#125;</span><br><span class="line"><span class="attribute">_EmissionColor</span> (<span class="string">&quot;Color&quot;</span>, Color) = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="attribute">_EmissionMap</span> (<span class="string">&quot;Emission&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br></pre></td></tr></table></figure>
<p>与上面的高光反射工作流相比，大部分相同，只是使用_MetallicGlossMap代替了高光相关的两项。</p>
<p>_MetallicGlossMap的r通道保存的是金属值，a通道保存的是光滑值，而高光反射的颜色由kDieletricSpec和albedo通过金属值metallic插值得到。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 metallicMap = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MetallicGlossMap</span>, <span class="params">sampler_MetallicGlossMap</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">half metallic = metallicMap.r;</span><br><span class="line">half smoothness = metallicMap.a<span class="operator"> * </span>_Glossiness;</span><br><span class="line">half roughness = <span class="number">1.0</span> - smoothness;</span><br><span class="line"></span><br><span class="line">half3 albedo = <span class="module-access"><span class="module"><span class="identifier">_Color</span>.</span></span>rgb<span class="operator"> * </span><span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>.rgb;</span><br><span class="line"></span><br><span class="line">half oneMinusReflectivity = kDieletricSpec.a - metallic<span class="operator"> * </span>kDieletricSpec.a;</span><br><span class="line">half3 diffColor = albedo<span class="operator"> * </span>oneMinusReflectivity;</span><br><span class="line">half3 specColor = lerp(kDieletricSpec.rgb, albedo, metallic);</span><br></pre></td></tr></table></figure>
<p>kDieletricSpec是URP中的内置变量，可以在Lightin.hlsl中找到：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> kDieletricSpec half4(0.04, 0.04, 0.04, 1.0 - 0.04)</span></span><br></pre></td></tr></table></figure>
<p>其他部分的计算与高光反射工作流都是相同的。</p>
<p><a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/2.1-PBR/Shader/2.1.2-CustomMetallicPBR.shader">代码如下</a></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting//img/2021-2-28/20210301115352.png" /></p>
<h1 id="四总结">四、总结</h1>
<p>本文主要给出PBR的相关计算公式，然后给出计算代码。这里要注意，这些公式并不是唯一的。</p>
<p>还是说一下，本文相对来说还是很简单的介绍，建议阅读下面的参考部分。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="http://candycat1992.github.io/unity_shaders_book/unity_shaders_book_chapter_18.pdf">第18章
基于物理的渲染</a></li>
<li>[2] <a
href="https://learnopengl-cn.github.io/07%20PBR/01%20Theory/">PBR</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>PBR</tag>
      </tags>
  </entry>
  <entry>
    <title>【躬行】-围绕DrawMeshInstancedIndirect的一些实验</title>
    <url>/2021/03/17/2021-03-17-%E3%80%90%E8%BA%AC%E8%A1%8C%E3%80%91-%E5%9B%B4%E7%BB%95DrawMeshInstancedIndirect%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>项目中使用了Graphics.DrawMeshInstancedIndirect()方法来实现草地的渲染。最近，需要测试在真机上的兼容性。<span id="more"></span>在测试的过程中，遇到了一些问题，也打了包，在真机上进行了各种实验。这里记录一下。</p>
<h1 id="文档解释">文档解释</h1>
<p>在官方文档的<a
href="https://docs.unity3d.com/Manual/GPUInstancing.html">GPU
instancing</a>中提到：</p>
<blockquote>
<p>You can also use the calls Graphics.DrawMeshInstanced and
Graphics.DrawMeshInstancedIndirect to perform GPU Instancing from your
scripts.</p>
</blockquote>
<p>所以，Graphics.DrawMeshInstancedIndirect()对平台和图形API的要求，与GPU
instancing的要求是一致的。在上面的文档中，提到了GPU
instancing对平台和图形API的要求：</p>
<blockquote>
<p>GPU Instancing is available on the following platforms and APIs:</p>
<ul>
<li><p><strong>DirectX 11</strong> and <strong>DirectX 12</strong> on
Windows</p></li>
<li><p><strong>OpenGL Core 4.1+/ES3.0+</strong> on Windows, macOS,
Linux, and Android</p></li>
<li><p><strong>Metal</strong> on macOS and iOS</p></li>
<li><p><strong>Vulkan</strong> on Windows, Linux and Android</p></li>
<li><p><strong>PlayStation 4</strong> and <strong>Xbox
One</strong></p></li>
<li><p><strong>WebGL</strong> (requires WebGL 2.0 API)</p></li>
</ul>
</blockquote>
<p>先考虑Android平台的情况，从上面可以看出，需要支持OpenGL ES
3.0+或者是Vulkan。</p>
<p>但是，在另一份<a
href="https://unity3d.com/unity/beta/unity5.5.0b6">文档</a>中提到，由于驱动问题，对于仅具有OpenGL
ES 3.0的Adreno GPU的设备，禁用了GPU instancing：</p>
<blockquote>
<p>Graphics: GPU Instancing: Added support for Android with OpenGL ES
3.0 or newer. Note however that GPU instancing support is disabled for
Android devices that have the Adreno GPU with only OpenGL ES 3.0,
because of driver issues.</p>
</blockquote>
<p>暂且先认为，OpenGL ES 3.1之后开始完全支持GPU instancing。</p>
<p>那么，在哪里配置Unity对图像API的支持呢？答案是Player
Settings-&gt;Other Settings下面的Graphics API部分。</p>
<p>首先，看一下官方手册中的解释：</p>
<blockquote>
<p>Disable this option to manually pick and reorder the graphics APIs.
(OpenGL). By default this option is enabled, and Unity tries GLES3.2. If
the device doesn’t support GLES3.2, Unity falls back to GLES3.1, GLES3
or GLES2. If only GLES3 is in the list, additional checkboxes appear:
<strong>Require ES3.1</strong>, <strong>Require ES3.1+AEP</strong> and
<strong>Require ES3.2</strong>. These allow you to force the
corresponding graphics API. <strong>Important</strong>: Unity adds the
GLES3/GLES3.1/AEP/3.2 requirement to your Android manifest only if GLES2
is not in the list and the Minimum API Level is set to JellyBean (API
level 18) or higher. In this case only, your application does not appear
on unsupported devices in the Google Play Store.</p>
</blockquote>
<p>我的理解是，当选择了Auto Graphics
API时，Unity会按照GLES3.2-&gt;GLES3.1-&gt;GLES3-&gt;GLES2的顺序，设置设备支持的图像API；当没有选择Auto
Graphics
API时，可以手动控制顺序，Unity会按照列表，从上至下的顺序，设置设备支持的图像API。</p>
<p>下面，会进行几个实验，来测试Graphics
API的配置在真机上的表现，顺便测试了Graphics.DrawMeshInstancedIndirect()方法在真机上的兼容性。</p>
<h1 id="真机测试">真机测试</h1>
<p>测试手机：华为 Nova 3、魅蓝 E3</p>
<p>Unity版本：2019.4.22f1c1</p>
<p>代码：参考<a
href="https://docs.unity3d.com/ScriptReference/Graphics.DrawMeshInstancedIndirect.html">Graphics.DrawMeshInstancedIndirect</a></p>
<p>下面在真机上的图片，会按照华为 Nova 3在上，魅蓝
E3在下的顺序排序，不再赘述。</p>
<h2 id="实验一">1、实验一</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210319122642.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103207.jpg" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103227.jpg" /></p>
<h2 id="实验二">2、实验二</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210319123142.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103300.jpg" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103320.jpg" /></p>
<h2 id="实验三">3、实验三</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210319123242.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103344.jpg" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103406.jpg" /></p>
<h2 id="实验四">4、实验四</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210319123340.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103430.jpg" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-3-19/20210321103448.jpg" /></p>
<h1 id="实验结论">实验结论</h1>
<p>根据实验的结果，同时参考官方手册中的内容，可以得出如下结论：</p>
<ol type="1">
<li>根据实验一的结果，当启用了Auto Graphics
API的时候，Unity会尝试支持GLES3.2。但是对比两台手机的表现，可以发现，华为
Nova 3上面的显示是有问题的。目前没有找到出现问题的原因。</li>
<li>根据实验二、三和四的结果，当没有启用Auto Graphics
API的时候，可以手动选择、排序Graphics
APIs。同时，可以发现，硬件设备支持多个图形API。根据实验结果，可以得出：Unity会根据Graphics
APIs在列表中的排序，从上至下，检测硬件设备是否支持相应的图形API。Vulkan支持Graphics.DrawMeshInstancedIndirect()，GLES
2.0不支持Graphics.DrawMeshInstancedIndirect()。而GLES
3可能需要某个版本之后才完全支持Graphics.DrawMeshInstancedIndirect()。</li>
</ol>
<h1 id="项目中的做法">项目中的做法</h1>
<p>目前的做法是，选择手动排序Graphics
APIs，按照顺序添加了Vulkan、OpenGLES3。但根据官方的统计<a
href="https://developer.android.com/about/dashboards">数据</a>，支持Vulkan的的设备只有53%左右。后面可能需要进行更多的验证，有了新的结果也会更新本文。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://docs.unity3d.com/Manual/class-PlayerSettingsAndroid.html#Other">Android
Player settings</a></li>
<li>[2] <a href="https://docs.unity3d.com/Manual/GPUInstancing.html">GPU
instancing</a></li>
<li>[3] <a href="https://unity3d.com/unity/beta/unity5.5.0b6">5.5.0 Beta
6</a></li>
<li>[4] <a href="https://zhuanlan.zhihu.com/p/72717290">GPU
Instancing手机兼容性报告</a></li>
<li>[5] <a
href="https://docs.unity3d.com/ScriptReference/Graphics.DrawMeshInstancedIndirect.html">Graphics.DrawMeshInstancedIndirect</a></li>
<li>[6] <a
href="https://developer.android.com/about/dashboards">分发信息中心</a></li>
</ul>
]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title>【躬行】-Assembly definitions的相关实验</title>
    <url>/2021/07/10/2021-07-10-%E3%80%90%E8%BA%AC%E8%A1%8C%E3%80%91-Assembly%20definitions%E7%9A%84%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>大概从Unity 2017.3开始，添加了assembly
definition相关的功能。为了更深入的了解，进行了多次打包和对比。本文主要是对这一过程进行记录。<span id="more"></span></p>
<h1 id="文档解释">文档解释</h1>
<h2 id="编译脚本">1、编译脚本</h2>
<p>Untiy在默认情况下，根据脚本在项目中的文件夹，会分成四个阶段编译脚本。</p>
<p>当脚本引用在其它阶段(即位于不同程序集中)编译的类时，编译顺序非常重要。基本规则是，在当前编译阶段之后的任何编译阶段都不能被引用。在当前阶段或更早阶段编译的任何内容都是完全可用的。</p>
<p>编译的各个阶段如下：</p>
<table>
<colgroup>
<col style="width: 4%" />
<col style="width: 33%" />
<col style="width: 62%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">阶段</th>
<th style="text-align: left;">程序集名</th>
<th style="text-align: left;">脚本文件</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">Assembly-CSharp-firstpass</td>
<td style="text-align: left;">Standard Assets, Pro Standard
Assets和Plugins文件夹下面的运行时脚本</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">Assembly-CSharp-Editor-firstpass</td>
<td style="text-align: left;">Standard Assets, Pro Standard
Assets和Plugins文件夹下面的Editor文件夹下面的Editor脚本</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">Assembly-CSharp</td>
<td style="text-align: left;">其它不在Editor文件夹下面的脚本</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">Assembly-CSharp-Editor</td>
<td
style="text-align: left;">所有剩下的脚本（Editor文件夹下面的脚本）</td>
</tr>
</tbody>
</table>
<h2 id="assembly-definitions">2、Assembly definitions</h2>
<p>程序集是一个C#代码库，它包含由脚本定义的已编译类和结构，还定义了对其他程序集的引用。</p>
<p>默认情况下，Unity将几乎所有的游戏脚本编译到预定义的程序集中（Assembly-CSharp.dll）。</p>
<p>这种安排对于小型项目来说是可以接受的，但是当你向项目中添加更多代码时，会有一些缺点：</p>
<ul>
<li>每当你改变一个脚本时，Unity就必须重新编译所有其他脚本，这增加了迭代代码更改的整体编译时间。</li>
<li>任何脚本都可以直接访问任何其他脚本中定义的类型，这使得重构和改进代码变得更加困难。</li>
<li>所有脚本都是为所有平台编译的。</li>
</ul>
<p>通过定义程序集，你可以组织代码以促进模块化和可重用性。你为项目定义的程序集中的脚本将不再添加到默认程序集中，并且只能访问你指定的其他程序集中的脚本。</p>
<p><img
src="https://docs.unity3d.com/uploads/Main/ScriptCompilation.png" /></p>
<p>上面的图表说明了如何将项目中的代码拆分为多个程序集。因为Main引用Stuff而不是相反，你知道任何对Main中的代码的更改都不会影响Stuff中的代码。类似地，因为Library不依赖于任何其他程序集，所以可以更容易地在另一个项目中重用Library中的代码。</p>
<p>默认情况下，预定义程序集引用所有其他程序集，包括使用Assembly
Definition(1)创建的程序集和作为plugin添加到项目中的预编译程序集(2)。此外，使用Assembly
Definition创建的程序集自动引用所有预编译程序集(3)：</p>
<p><img
src="https://docs.unity3d.com/uploads/Main/AssemblyDependencies.png" /></p>
<p>要将项目代码组织成程序集，请为每个所需程序集创建一个文件夹，并将应该属于每个程序集的脚本移动到相关文件夹中。然后创建Assembly
Definition资产以指定程序集属性。</p>
<p>Unity在一个包含Assembly
Definition资产的文件夹中获取所有脚本，并使用该资产定义的名称和其他设置将它们编译为一个程序集。Unity还将任意子文件夹中的脚本包含到同一程序集中，除非子文件夹有自己的Assembly
Definition或Assembly Definition Reference资产。</p>
<p>要在现有程序集中包含来自非子文件夹的脚本，请在非子文件夹中创建Assembly
Definition Reference资产，并将其设置为引用定义目标程序集的Assembly
Definition资产。例如，你可以将项目中所有Editor文件夹中的脚本组合到它们自己的程序集中，而不管这些文件夹位于何处。</p>
<p>Assembly Definition
Reference在下面这种情况下可以解决问题：在Unity的Packages中，有一些访问级别为internal的类。如果我们在Assets下面创建脚本，是不能访问Packages中的internal类。有了Assembly
Definition
Reference就可以了。可以在创建的脚本的同级目录中创建一个Assembly
Definition Reference，设置引用包含internal类的Package即可。</p>
<h1 id="一些实验">一些实验</h1>
<p>Unity版本：2020.3.13f1</p>
<p>ILSpy版本：7.1.0.6543</p>
<p>创建一个空的URP工程，设置到Android平台，Player Setting中的Scripting
Backend设置为“Mono”。默认情况下，项目中包含的脚本如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710201916.png" /></p>
<p>每次打完包后，对apk进行解压即可。解压后，程序集的位置在“{解压的文件}”下面：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202102.png" /></p>
<h2 id="默认打包">1、默认打包</h2>
<p>我们需要关心的是“Assembly-CSharp.dll”程序集。使用ILSpy打开Assembly-CSharp.dll，可以看到：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202128.png" /></p>
<p>项目中的两个运行时脚本Readme和SimpleCameraController都被编译到程序集Assembly-CSharp.dll中。</p>
<h2 id="使用assembly-definition">2、使用Assembly Definition</h2>
<p>在SimpleCameraController的同级目标创建Assembly Definition，Assembly
Definition的设置保持默认即可。观察SimpleCameraController，可以发现SimpleCameraController的程序集信息是新创建的Assembly
Definition：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202148.png" /></p>
<p>打包，解压，可以看到，刚才新创建的Assembly
Definition产生的程序集：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202206.png" /></p>
<p>使用ILSpy分别打开Assembly-CSharp.dll和NewAssembly.dll，结果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202226.png" /></p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202241.png" /></p>
<p>可以发现，SimpleCameraController被编译进新的程序集NewAssembly.dll中，而原本的程序集Assembly-CSharp.dll中没有SimpleCameraController了。</p>
<h3 id="使用assembly-definition-reference">3、使用Assembly Definition
Reference</h3>
<p>删除上面创建的Assembly
Definition，在SimpleCameraController的同级目标创建Assembly Definition
Reference。假设，我们想访问的Unity的Package是Unity UI，设置Assembly
Definition Reference上的Assembly
Definition为UnityEngine.UI即可，如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710211122.png" /></p>
<p>打包，解压，可以看到，上面新创建的程序集NewAssembly.dll没了，而使用ILSpy打开Assembly-CSharp.dll，也并没有看到SimpleCameraController。那么，SimpleCameraController去哪儿了呢？使用ILSpy打开UnityEngine.UI.dll程序集：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-7-10/20210710202300.png" /></p>
<p>可以发现，SimpleCameraController被包含到了UnityEngine.UI.dll程序集中，也就是说，SimpleCameraController可以访问程序集中的internal级别的类了。</p>
<h1 id="一些使用场景">一些使用场景</h1>
<ol type="1">
<li>对于Assembly
Definition的用处，网上很多的介绍是可以加快代码编译速度。这个也很容易理解，使用Assembly
Definition对项目中的脚本进行细分后，每次修改只需要编译脚本所在的程序集，因此减少了编译的时间。</li>
<li>如果想访问Untiy的Package中的internal类的话，由于可以获得Package的源码，当然可以直接在Package中添加修改。当现在如果不修改Package的话，就可以使用Assembly
Definition
Reference，将自己的代码包含到Package中，这样，就会编译到同一个程序集中，也就可以访问internal类了。</li>
</ol>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://unity3d.com/unity/whats-new/unity-2017.3.0">Unity
2017.3</a></li>
<li>[2] <a
href="https://docs.unity3d.com/Manual/ScriptCompileOrderFolders.html">Special
folders and script compilation order</a></li>
<li>[3] <a
href="https://docs.unity3d.com/Manual/ScriptCompilationAssemblyDefinitionFiles.html">Assembly
definitions</a></li>
<li>[4] <a
href="https://www.xuanyusong.com/archives/4474">Unity3D研究院新方法加快代码编译速度（九十六）</a></li>
<li>[5] <a
href="https://answer.uwa4d.com/question/58d2829a9ad5c0094f461e30">提升Unity编辑器中代码的编译速度</a></li>
</ul>
]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>Untiy</tag>
      </tags>
  </entry>
  <entry>
    <title>练习项目(十四)：速度线效果的实现</title>
    <url>/2021/10/29/2021-10-29-%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%E9%80%9F%E5%BA%A6%E7%BA%BF%E6%95%88%E6%9E%9C%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>最近接到一个需求，需要实现速度线的效果。这里，会一步步地展示实现的过程。希望对大家能有所启发。<span id="more"></span>下面是项目的Github地址，欢迎Star。</p>
<p><a href="https://github.com/bzyzhang/RoadOfShader">Road Of
Shader</a></p>
<h1 id="实现">实现</h1>
<p>首先，合理地使用搜索引擎，找一下速度线效果的参考图：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031184754.jpeg" /></p>
<p>对于上图，下面进行一些分析。</p>
<p>对于黑色线条的形状，猛一看没什么思路。但如果换一种角度，考虑与黑色线条互补的白色部分，是类似中间一个光团，往周围发射的形状。这种形状，就比较好实现了。下面，先实现这种形状。</p>
<p>下面是后面要用到的基础代码，主要关注片元着色器部分：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Shader <span class="string">&quot;RoadOfShader/2.2-SpeedLine/Speed Line&quot;</span></span><br><span class="line">&#123;</span><br><span class="line">    Properties</span><br><span class="line">    &#123;</span><br><span class="line">        [NoScaleOffset]_NoiseTex (<span class="string">&quot;NoiseTex&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line">        _Center (<span class="string">&quot;Center&quot;</span>, Vector) = (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    SubShader</span><br><span class="line">    &#123;</span><br><span class="line">        Tags &#123; <span class="string">&quot;Queue&quot;</span> = <span class="string">&quot;Transparent&quot;</span> <span class="string">&quot;RenderType&quot;</span> = <span class="string">&quot;Transparent&quot;</span> <span class="string">&quot;RenderPipeline&quot;</span> = <span class="string">&quot;UniversalPipeline&quot;</span> <span class="string">&quot;IgnoreProjector&quot;</span> = <span class="string">&quot;True&quot;</span> &#125;</span><br><span class="line">        </span><br><span class="line">        Pass</span><br><span class="line">        &#123;</span><br><span class="line">            Tags &#123; <span class="string">&quot;LightMode&quot;</span> = <span class="string">&quot;UniversalForward&quot;</span> &#125;</span><br><span class="line"></span><br><span class="line">            Blend SrcAlpha OneMinusSrcAlpha</span><br><span class="line">            ZWrite Off</span><br><span class="line">            </span><br><span class="line">            HLSLPROGRAM</span><br><span class="line"></span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> prefer_hlslcc gles</span></span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> exclude_renderers d3d11_9x</span></span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> target 2.0</span></span><br><span class="line">            </span><br><span class="line">            <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot;</span></span></span><br><span class="line">            </span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> vertex vert</span></span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> fragment frag</span></span><br><span class="line">            </span><br><span class="line">            struct Attributes</span><br><span class="line">            &#123;</span><br><span class="line">                float4 positionOS: POSITION;</span><br><span class="line">                float2 uv: TEXCOORD0;</span><br><span class="line">            &#125;;</span><br><span class="line">            </span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">Varyings</span></span></span><br><span class="line"><span class="class">            &#123;</span></span><br><span class="line">                float2 uv: TEXCOORD0;</span><br><span class="line">                float4 vertex: SV_POSITION;</span><br><span class="line">            &#125;;</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">CBUFFER_START</span>(UnityPerMaterial)</span><br><span class="line">            half4 _Center;</span><br><span class="line">            CBUFFER_END</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">TEXTURE2D</span>(_NoiseTex);   <span class="built_in">SAMPLER</span>(sampler_NoiseTex);</span><br><span class="line">            </span><br><span class="line">            <span class="function">Varyings <span class="title">vert</span><span class="params">(Attributes input)</span></span></span><br><span class="line"><span class="function">            </span>&#123;</span><br><span class="line">                Varyings output = (Varyings)<span class="number">0</span>;</span><br><span class="line">                </span><br><span class="line">                output.vertex = <span class="built_in">TransformObjectToHClip</span>(input.positionOS.xyz);</span><br><span class="line">                output.uv = input.uv;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">return</span> output;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="function">half4 <span class="title">frag</span><span class="params">(Varyings input)</span>: SV_Target</span></span><br><span class="line"><span class="function">            &#123;</span></span><br><span class="line">                half2 uv = input.uv - _Center.xy;</span><br><span class="line">                half2 normalizedUV = <span class="built_in">normalize</span>(uv);</span><br><span class="line">                </span><br><span class="line">                half textureMask = <span class="built_in">SAMPLE_TEXTURE2D</span>(_NoiseTex, sampler_NoiseTex, normalizedUV).r;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">half4</span>(textureMask, textureMask, textureMask, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            ENDHLSL</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101509.png" /></p>
<p>主要的功能都在片元着色器中。首先，根据中心点偏移UV，目前的Center设置成<span
class="math inline">\((0.5,0.5)\)</span>，目的是把UV的中心移动到图像的中心位置。然后，对偏移后的UV归一化，这一步达到的效果是，对于方向相同的UV，取值都相同，也就是说，对于同一方向的UV，对纹理采样的结果都是相同的。这样，就会形成从中心点往周围发散的效果。对于上图的效果图，使用的NoiseTex纹理比较特殊，是亮暗方格间隔的，选择这张图，主要是为了更好地展示上述采样的逻辑。（仔细看一下上图，黑色部分是不是就像上面的速度线了。）</p>
<p>速度线不是静止的，是有快速变化的，接下来，在上面的基础上做一些旋转的效果。</p>
<p>主要的改变都在片元着色器中：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half2 uv = input.uv - <span class="module-access"><span class="module"><span class="identifier">_Center</span>.</span></span>xy;</span><br><span class="line"></span><br><span class="line">half angle = radians(_RotateSpeed<span class="operator"> * </span><span class="module-access"><span class="module"><span class="identifier">_Time</span>.</span></span>y);</span><br><span class="line"></span><br><span class="line">half sinAngle, cosAngle;</span><br><span class="line">sincos(angle, sinAngle, cosAngle);</span><br><span class="line"></span><br><span class="line">half2x2 rotateMatrix = half2x2(cosAngle, -sinAngle, sinAngle, cosAngle);</span><br><span class="line"></span><br><span class="line">half2 normalizedUV = normalize(mul(rotateMatrix, uv));</span><br><span class="line"></span><br><span class="line">half textureMask = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">normalizedUV</span>)</span>.r;</span><br><span class="line">return half4(textureMask, textureMask, textureMask, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>添加了一个速度参数_RotateSpeed，根据时间变化，计算出旋转的角度angle。注意，这里的计算得到的angle是弧度，再使用sincos函数计算得到angle的正弦和余弦值。然后，构造2维的旋转矩阵rotateMatrix，对UV进行旋转后再计算得到归一化的normalizedUV。</p>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101558.gif" /></p>
<p>观察发现，上面的效果很明显地往一个方向旋转，而速度线并不是往一个方向旋转的。此时，可以加一个反方向的旋转，这样，就可以抵消这种单方向的旋转。</p>
<p>主要的改变都在片元着色器中：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half2</span> uv = input.uv - _Center.xy;</span><br><span class="line"></span><br><span class="line"><span class="attribute">half</span> angle = radians(_RotateSpeed * _Time.y);</span><br><span class="line"></span><br><span class="line"><span class="attribute">half</span> sinAngle, cosAngle;</span><br><span class="line"><span class="attribute">sincos</span>(angle, sinAngle, cosAngle);</span><br><span class="line"></span><br><span class="line"><span class="attribute">half2x2</span> rotateMatrix<span class="number">0</span> = half<span class="number">2</span>x<span class="number">2</span>(cosAngle, -sinAngle, sinAngle, cosAngle);</span><br><span class="line"><span class="attribute">half2</span> normalizedUV<span class="number">0</span> = normalize(mul(rotateMatrix<span class="number">0</span>, uv));</span><br><span class="line"></span><br><span class="line"><span class="attribute">half2x2</span> rotateMatrix<span class="number">1</span> = half<span class="number">2</span>x<span class="number">2</span>(cosAngle, sinAngle, -sinAngle, cosAngle);</span><br><span class="line"><span class="attribute">half2</span> normalizedUV<span class="number">1</span> = normalize(mul(rotateMatrix<span class="number">1</span>, uv));</span><br><span class="line"></span><br><span class="line"><span class="attribute">half</span> textureMask = SAMPLE_TEXTURE<span class="number">2</span>D(_NoiseTex, sampler_NoiseTex, normalizedUV<span class="number">0</span>).r * SAMPLE_TEXTURE<span class="number">2</span>D(_NoiseTex, sampler_NoiseTex, normalizedUV<span class="number">1</span>).r;</span><br><span class="line"><span class="attribute">return</span> half<span class="number">4</span>(textureMask, textureMask, textureMask, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>主要的区别是，添加了rotateMatrix1的计算，这里的有一点需要注意一些，对于反方向的旋转：
<span class="math display">\[
\begin{aligned}
cos(-angle) = cos(angle)\\
sin(-angle) = -sin(angle)
\end{aligned}
\]</span>
然后，计算得到normalizedUV1。使用normalizedUV0和normalizedUV1分别对纹理采样，将采样的结果相乘，就可以解决上面的往一个方向旋转的问题了。</p>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101633.gif" /></p>
<p>再观察一下最前面的效果图，发现黑色线条分布在边缘。很容易可以想到，可以根据UV距离中心点的距离对上面的结果做一个叠加，也就是根据UV距离做一个遮罩。</p>
<p>主要的改变都在片元着色器中：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half textureMask = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">normalizedUV0</span>)</span>.r<span class="operator"> * </span><span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_NoiseTex</span>, <span class="params">sampler_NoiseTex</span>, <span class="params">normalizedUV1</span>)</span>.r;</span><br><span class="line"></span><br><span class="line">half uvMask = pow(_RayMultiply<span class="operator"> * </span>length(uv), _RayPower);</span><br><span class="line"></span><br><span class="line">half mask = textureMask<span class="operator"> * </span>uvMask;</span><br><span class="line"></span><br><span class="line">return half4(mask, mask, mask, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>textureMask是之前计算得到的纹理遮罩，而uvMask是新计算的UV遮罩。这里计算uvMask，使用的是幂函数，使用幂函数，相对于直接使用uv的长度，幂函数曲线比直线更加平缓。然后对textureMask和uvMask进行叠加，得到最终的mask。</p>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101703.gif" /></p>
<p>目前，使用的NoiseTex是亮暗间隔的格子图。真正使用的，是噪声图。下面替换成噪声图。</p>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101726.png" /></p>
<p>可以发现，边缘的条纹太密集了。这里，可以添加一个阈值，对上面计算得到的mask进行分层。</p>
<p>主要改变的片元着色器代码如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half</span> mask = smoothstep(_Threshold - <span class="number">0</span>.<span class="number">1</span>, _Threshold + <span class="number">0</span>.<span class="number">1</span>, textureMask * uvMask);</span><br></pre></td></tr></table></figure>
<p>主要就是使用_Threshold对纹理遮罩和UV遮罩做一个分层，这里，使用smoothstep函数，使分层的边缘不会那么的“硬”。</p>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101759.gif" /></p>
<p>到这里，与开头的速度线效果相比较，已经神似了。下面，给速度线条加上颜色控制。</p>
<p>主要改变的片元着色器代码如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">half</span> mask = smoothstep(_Threshold - <span class="number">0</span>.<span class="number">1</span>, _Threshold + <span class="number">0</span>.<span class="number">1</span>, textureMask * uvMask);</span><br><span class="line">                </span><br><span class="line"><span class="attribute">return</span> half<span class="number">4</span>(_TintColor.rgb, mask * _TintColor.a);</span><br></pre></td></tr></table></figure>
<p>主要的区别在返回值部分。返回了_TintColor.rgb作为颜色，使用遮罩mask和_TintColor.a相乘的结果作为透明度。</p>
<p>这里需要注意一下，目前使用的混合模式如下：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Blend SrcAlpha OneMinusSrcAlpha</span></span><br></pre></td></tr></table></figure>
<p>速度线目前使用面片实现的，是按照半透明物体渲染的。上面的混合模式，可以得到速度线与后面的场景混合的效果。当然，也可以使用如下的混合模式：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Blend One OneMinusSrcAlpha</span></span><br></pre></td></tr></table></figure>
<p>此时，最终返回的颜色，要自己做颜色与透明度的叠加了：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">return half4(<span class="module-access"><span class="module"><span class="identifier">_TintColor</span>.</span></span>rgb<span class="operator"> * </span>mask<span class="operator"> * </span><span class="module-access"><span class="module"><span class="identifier">_TintColor</span>.</span></span>a, mask<span class="operator"> * </span><span class="module-access"><span class="module"><span class="identifier">_TintColor</span>.</span></span>a);</span><br></pre></td></tr></table></figure>
<p>实现的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1//img/2021-10-29/20211031101833.gif" /></p>
<p>最终的代码<a
href="https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/2.2-SpeedLine/Shader/2.2.1-SpeedLine.shader">如下</a>。</p>
<h1 id="扩展">扩展</h1>
<p>上面实现了基本的速度线效果。但速度线一般是全屏的。可以使用粒子、全屏的面片或者后处理实现全屏的效果，这里不再赘述。另外，还可以进行扩展。目前使用的是单层的速度线，也可以经过改变获得双层甚至多层的速度线。主要的算法都是上面的。考虑到对NoiseTex采样次数多了会对性能造成影响，这里，可以充分利用NoiseTex的其它通道，一次采样，可以获得四个通道的数据，根据不同通道的数据，可以实现多层速度线的效果。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a href="https://www.wesbrannen.com/steven-universe">Steven
Universe</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Effect</tag>
      </tags>
  </entry>
  <entry>
    <title>【躬行】-深度缓冲和模板缓冲是怎么存储的？</title>
    <url>/2023/11/02/2023-11-02-%E3%80%90%E8%BA%AC%E8%A1%8C%E3%80%91-%E6%B7%B1%E5%BA%A6%E7%BC%93%E5%86%B2%E5%92%8C%E6%A8%A1%E6%9D%BF%E7%BC%93%E5%86%B2%E6%98%AF%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84%EF%BC%9F/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>最近在工作中需要实现一个功能，用到了模板测试。但奇怪的是，模板测试竟然不起作用！<span id="more"></span>在解决问题的过程中，发现了一些有趣的知识点。通过本文，可以了解在unity中，深度缓冲和模板缓冲到底是怎么存储的。</p>
<h1 id="测试环境的搭建">测试环境的搭建</h1>
<p>Unity版本：2021.3.16f1</p>
<p>URP版本：12.1.8</p>
<p>RenderDoc：1.29</p>
<p>需要注意的是，URP的版本迭代，代码改动较大，最好与上面的版本一致。否则，可能会因为版本不同，产生无谓的麻烦。</p>
<p>后面的实验需要使用到RenderDoc。关于怎么在Unity中使用RenderDoc，可以查看最后的参考文献部分。</p>
<ol type="1">
<li><p>由于后续需要修改URP的源码进行测试，所以需要移动URP源码的路径。新建URP项目，源码的路径是类似这种：xxx（xxx是URP项目的文件夹名）。需要将以下两个URP源码文件夹移动到xxx：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032159891.png" /></p>
<p>移动后，Packages文件夹类似这样：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032204075.png" /></p></li>
<li><p>实现一个基础的Shader,包含了深度测试和模板测试。代码很简单，就不赘述了。如下所示：</p>
<figure class="highlight puppet"><table><tr><td class="code"><pre><span class="line">Shader <span class="string">&quot;Test/Hello World&quot;</span></span><br><span class="line">&#123;</span><br><span class="line">    Properties</span><br><span class="line">    &#123;</span><br><span class="line">        _Color (<span class="string">&quot;Main Color&quot;</span>, Color) = (1,1,1,1)</span><br><span class="line">        </span><br><span class="line">        [Header(Stencil)]</span><br><span class="line">        [Enum(UnityEngine.Rendering.CompareFunction)]_StencilComp (<span class="string">&quot;Stencil Comparison&quot;</span>, Float) = 8</span><br><span class="line">        [IntRange]_Stencil (<span class="string">&quot;Stencil ID&quot;</span>, Range(0,255)) = 0</span><br><span class="line">        [Enum(UnityEngine.Rendering.StencilOp)]_StencilPass (<span class="string">&quot;Stencil Pass&quot;</span>, Float) = 0</span><br><span class="line">    &#125;</span><br><span class="line">    SubShader</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">Tags</span> &#123; <span class="string">&quot;Queue&quot;</span> = <span class="string">&quot;Geometry&quot;</span> <span class="string">&quot;RenderType&quot;</span> = <span class="string">&quot;Opaque&quot;</span> <span class="string">&quot;RenderPipeline&quot;</span> = <span class="string">&quot;UniversalPipeline&quot;</span> &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">Pass</span></span><br><span class="line">        &#123;</span><br><span class="line">            Tags &#123; <span class="string">&quot;LightMode&quot;</span> = <span class="string">&quot;UniversalForward&quot;</span> &#125;</span><br><span class="line">            <span class="keyword">Cull</span> <span class="keyword">Off</span></span><br><span class="line">            <span class="keyword">ZTest</span> <span class="keyword">LEqual</span></span><br><span class="line">            <span class="keyword">ZWrite</span> <span class="keyword">On</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">Stencil</span></span><br><span class="line">            &#123;</span><br><span class="line">                Ref [_Stencil]</span><br><span class="line">                Comp [_StencilComp]</span><br><span class="line">                Pass [_StencilPass]</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">HLSLPROGRAM</span></span><br><span class="line">            </span><br><span class="line">            #include <span class="string">&quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot;</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#pragma vertex vert</span></span><br><span class="line">            <span class="comment">#pragma fragment frag</span></span><br><span class="line">            </span><br><span class="line">            struct Attributes</span><br><span class="line">            &#123;</span><br><span class="line">                float4 positionOS: POSITION;</span><br><span class="line">            &#125;;</span><br><span class="line">            </span><br><span class="line">            struct Varyings</span><br><span class="line">            &#123;</span><br><span class="line">                float4 vertex: SV_POSITION;</span><br><span class="line">            &#125;;</span><br><span class="line">            </span><br><span class="line">            half4 _Color;</span><br><span class="line">            </span><br><span class="line">            Varyings vert(Attributes input)</span><br><span class="line">            &#123;</span><br><span class="line">                Varyings output = (Varyings)0;</span><br><span class="line">                </span><br><span class="line">                output.vertex = TransformObjectToHClip(input.positionOS.xyz);</span><br><span class="line">                </span><br><span class="line">                return output;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            half4 frag(Varyings input): SV_Target</span><br><span class="line">            &#123;</span><br><span class="line">                return _Color;</span><br><span class="line">            &#125;</span><br><span class="line">            ENDHLSL</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>需要设置一下测试的场景环境。使用上面的Shader新建两个材质球：Far和Near，如下设置：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032205272.png"
alt="far材质球" />
<figcaption aria-hidden="true">far材质球</figcaption>
</figure>
<p>Far材质球，设置为总是通过模板测试，替换模板值3，Render
Queue设为2000。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032206026.png"
alt="near材质球" />
<figcaption aria-hidden="true">near材质球</figcaption>
</figure>
<p>Near材质球，设置模板缓冲值为3时才通过，保留模板缓冲值，Render
Queue设为2010。</p>
<p>通过上面的设置，会先渲染Far材质球，写入模板缓冲3。然后再渲染Near材质球，只有模板缓冲中值为3的区域才会渲染。</p>
<p>使用Frame
Debugger查看渲染流程，可以发现，确实是先渲染Far，再渲染Near。整体的渲染流程如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032215112.png" /></p>
<p>注意上图中红框中的部分，是颜色缓冲纹理的名称。在代码中使用全局搜索，可以找到如下部分：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032234520.png" /></p>
<p>通过观察分析，可以发现，深度缓冲和模板缓冲，主要是受到下面代码的影响：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032237561.png" /></p>
<p><strong>colorDescriptor.depthBufferBits</strong>的代码注释如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032238004.png" /></p>
<p>这个值代表渲染纹理的深度缓冲精度比特值，支持0,16,24,32这四个值。</p>
<p>下面，分别把<strong>colorDescriptor.depthBufferBits</strong>设为上面的四个值，查看效果。</p>
<h1 id="实验">实验</h1>
<h2 id="实验一-设为0">实验一 设为0</h2>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">colorDescriptor.depthBufferBits</span> = (useDepthRenderBuffer) ? <span class="number">0</span> : <span class="number">0</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>场景效果</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032250867.png" /></p></li>
<li><p>Frame Debugger</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032251621.png" /></p></li>
<li><p>RenderDoc</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032251409.png" /></p>
<p>分析：从场景效果看，只渲染了天空盒，没有显示出Far或Near。但从Frame
Debugger上看，流程并没有改变，还是先渲染Far，再渲染Near，接着再渲染天空盒。只是天空盒将Far和Near都覆盖了。从RenderDoc看，只有颜色纹理RT0。从这些内容分析以下，应该是因为没有了深度缓冲和模板缓冲，导致深度测试和模板测试不起作用了。</p></li>
</ol></li>
</ol>
<h2 id="实验二-设为16">实验二 设为16</h2>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">colorDescriptor.depthBufferBits</span> = (useDepthRenderBuffer) ? <span class="number">16</span> : <span class="number">0</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>场景效果</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032303774.png" /></p></li>
<li><p>Frame Debugger 与上面相同，略</p></li>
<li><p>RenderDoc</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032305491.png" /></p>
<p>分析：从场景效果看，显示出Far和Near，但是模板测试并没有起作用，因为完整的渲染出了Near。从Frame
Debugger上看，流程并没有改变。从RenderDoc看，除了颜色纹理RT0，还多渲染了一张纹理DS（从名字看，应该是Depth
Stencil）。在RT0中右键选中Far范围内的一点，再切换到DS，可以在RenderDoc的底部看到选中点的深度、模板信息。从上图可以看出，DS纹理的格式是R16，后面的值是选中点的深度缓冲值。这样，可以推测，有了深度缓冲，深度测试应该是起作用了，但是模板缓冲还是没有起作用，因为没有模板缓冲。</p></li>
</ol>
<h2 id="实验三-设为24">实验三 设为24</h2>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">colorDescriptor.depthBufferBits</span> = (useDepthRenderBuffer) ? <span class="number">24</span> : <span class="number">0</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>场景效果</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032315257.png" /></p></li>
<li><p>Frame Debugger 与上面相同，略</p></li>
<li><p>RenderDoc</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032315464.png" /></p>
<p>分析：从场景效果和Frame
Debugger上看，效果和流程与开始实验前完全一样。从RenderDoc看，与设为16时一样，都有RT0和DS两张纹理。但DS纹理的格式和内容是不同的，在上图底部可以发现，DS的格式是D32S8，后面还有深度缓冲值和模板缓冲值。与设为16时相比，DS纹理的格式不同，纹理的信息中，还多了模板缓冲值。这样，可以推测，深度缓冲和模板缓冲都有了，深度测试和模板测试也都起作用了。</p></li>
</ol>
<h2 id="实验四-设为32">实验四 设为32</h2>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">colorDescriptor.depthBufferBits</span> = (useDepthRenderBuffer) ? <span class="number">32</span> : <span class="number">0</span><span class="comment">;</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>场景效果与上面相同，略</p></li>
<li><p>Frame Debugger 与上面相同，略</p></li>
<li><p>RenderDoc与上面相同，略</p></li>
</ol>
<p>可以发现，设为32时，与设为24时的效果完全相同。这是为什么呢？</p>
<p><strong>colorDescriptor.depthBufferBits</strong>的源码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">public <span class="built_in">int</span> depthBufferBits</span><br><span class="line">&#123;</span><br><span class="line"> <span class="function"> <span class="params">get</span> =&gt;</span> GraphicsFormatUtility.<span class="constructor">GetDepthBits(<span class="params">this</span>.<span class="params">depthStencilFormat</span>)</span>;</span><br><span class="line"> <span class="function"> <span class="params">set</span> =&gt;</span> this.depthStencilFormat = RenderTexture.<span class="constructor">GetDepthStencilFormatLegacy(<span class="params">value</span>, <span class="params">this</span>.<span class="params">graphicsFormat</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设为24时，单步调试的结果如下：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032328655.png"
alt="9、bit为24时的单步调试结果" />
<figcaption aria-hidden="true">9、bit为24时的单步调试结果</figcaption>
</figure>
<p>设为32时，单步调试的结果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-2/202311032328037.png" /></p>
<p>从上面可以发现，设置depthBufferBits的int值，并不会向一般的属性那样直接存储int值。而是经过计算之后，存储到GraphicsFormat类型的变量中。而当设置的值是24和32时，保存的GraphicsFormat类型的变量都是D32_SFloat_S8_UInt。这也就解释了为什么设为24和32时，RenderDoc中完全一致的问题。</p>
<h1 id="实验结论">实验结论</h1>
<p>上面的实验结果，可以用下面的图表简洁表达：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">DS纹理</th>
<th style="text-align: center;">深度测试</th>
<th style="text-align: center;">模板测试</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">✖</td>
<td style="text-align: center;">✖</td>
<td style="text-align: center;">✖</td>
</tr>
<tr class="even">
<td style="text-align: center;">16</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✖</td>
</tr>
<tr class="odd">
<td style="text-align: center;">24</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
</tr>
<tr class="even">
<td style="text-align: center;">32</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
</tr>
</tbody>
</table>
<p>回到最初遇到的问题：模板测试不起作用。根据上面的表格，在项目中查了一下，是因为depthBufferBits设为了0，导致深度测试和模板测试都不起作用了。思路延伸一下：从性能优化的角度考虑，如果某种情况下不需要深度测试或模板测试，可以赋予depthBufferBits一个比较低的值，这样，DS纹理占用的内存会比较小，甚至不需要申请DS纹理的内存。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://docs.unity3d.com/2021.3/Documentation/Manual/RenderDocIntegration.html">RenderDoc
Integration</a></li>
</ul>
]]></content>
      <categories>
        <category>躬行</category>
      </categories>
      <tags>
        <tag>图形学</tag>
      </tags>
  </entry>
  <entry>
    <title>（十五）面片阴影的一些改进思考</title>
    <url>/2023/11/13/2023-11-13-%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%E9%9D%A2%E7%89%87%E9%98%B4%E5%BD%B1%E7%9A%84%E4%B8%80%E4%BA%9B%E6%94%B9%E8%BF%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>在之前的项目<a
href="https://bzyzhang.github.io/2021/01/20/2021-01-20-%EF%BC%88%E4%B8%83%EF%BC%89%E5%87%A0%E7%A7%8D%E7%AE%80%E5%8D%95%E7%9A%84%E9%98%B4%E5%BD%B1%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/">几种简单的阴影实现方法</a>中，提到了用面片实现阴影的方式。<span id="more"></span>当时提到，这种方式比较受限，只适用于平整的地面。最近在回顾这篇文章的时候，当看到第三部分的球体阴影时，忽然想到，是不是可以使用球体阴影的思想，来解决面片阴影的限制呢？</p>
<h1 id="思路">思路</h1>
<p>基本的思路是：在C#代码中，实时将角色的世界坐标传递给Shader，作为圆形面片阴影的圆心。然后，在Shader的片元着色器中，计算该片元距离圆心的距离，如果在半径范围内，就是处于阴影区域；否则，就不处于阴影区域。</p>
<h1 id="实验">实验</h1>
<p>首先搭建好方便实验的场景。新建一个球体模拟角色，新建两个立方体模拟地面和台阶。如下图所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311202227754.png" /></p>
<p>新建C#脚本，将圆形面片的圆心位置和半径传递给Shader：</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> UnityEngine;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">PlaneShadow</span> : <span class="title">MonoBehaviour</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">float</span> Radius;</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">float</span> ShadowFalloff;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Update</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">        Shader.SetGlobalVector(<span class="string">&quot;_CenterPos&quot;</span>, transform.position);</span><br><span class="line">        Shader.SetGlobalFloat(<span class="string">&quot;_CenterRadius&quot;</span>, Radius * Radius);</span><br><span class="line">        Shader.SetGlobalFloat(<span class="string">&quot;_ShadowFalloff&quot;</span>, ShadowFalloff);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上述代码中，ShadowFalloff变量是用来控制阴影从圆心向四周衰减的。圆心处阴影最强，往四周逐渐减弱。</p>
<p>为地面和台阶部分新建Shader。接受C#中传递过来的数据。Shader文件如下所示：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">Shader <span class="string">&quot;RoadOfShader/2.3-PlaneShadow/Plane Shadow&quot;</span></span><br><span class="line">&#123;</span><br><span class="line">    Properties</span><br><span class="line">    &#123;</span><br><span class="line">        _MainTex (<span class="string">&quot;Main Tex&quot;</span>, <span class="number">2</span>D) = <span class="string">&quot;white&quot;</span> &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    SubShader</span><br><span class="line">    &#123;</span><br><span class="line">        Tags</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;Queue&quot;</span> = <span class="string">&quot;Geometry&quot;</span> <span class="string">&quot;RenderType&quot;</span> = <span class="string">&quot;Opaque&quot;</span> <span class="string">&quot;RenderPipeline&quot;</span> = <span class="string">&quot;UniversalPipeline&quot;</span> <span class="string">&quot;IgnoreProjector&quot;</span> = <span class="string">&quot;True&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Pass</span><br><span class="line">        &#123;</span><br><span class="line">            Tags</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;LightMode&quot;</span> = <span class="string">&quot;UniversalForward&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">            Cull Off</span><br><span class="line"></span><br><span class="line">            HLSLPROGRAM</span><br><span class="line">            <span class="comment">// Required to compile gles 2.0 with standard SRP library</span></span><br><span class="line">            <span class="comment">// All shaders must be compiled with HLSLcc and currently only gles is not using HLSLcc by default</span></span><br><span class="line">            #pragma prefer_hlslcc gles</span><br><span class="line">            #pragma exclude_renderers d3d11_9x</span><br><span class="line">            #pragma target <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">            #<span class="keyword">include</span> <span class="string">&quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot;</span></span><br><span class="line">            #<span class="keyword">include</span> <span class="string">&quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl&quot;</span></span><br><span class="line"></span><br><span class="line">            #pragma vertex vert</span><br><span class="line">            #pragma fragment frag</span><br><span class="line"></span><br><span class="line">            <span class="keyword">struct</span> Attributes</span><br><span class="line">            &#123;</span><br><span class="line">                float4 positionOS: POSITION;</span><br><span class="line">                float2 uv: TEXCOORD0;</span><br><span class="line">                UNITY_VERTEX_INPUT_INSTANCE_ID</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">struct</span> Varyings</span><br><span class="line">            &#123;</span><br><span class="line">                float2 uv: TEXCOORD0;</span><br><span class="line">                float3 positionWS: TEXCOORD1;</span><br><span class="line">                float4 positionCS: SV_POSITION;</span><br><span class="line">                UNITY_VERTEX_INPUT_INSTANCE_ID</span><br><span class="line">                UNITY_VERTEX_OUTPUT_STEREO</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">            float4 _CenterPos;</span><br><span class="line">            <span class="built_in">float</span> _CenterRadius;</span><br><span class="line">            half _ShadowFalloff;</span><br><span class="line"></span><br><span class="line">            <span class="constructor">CBUFFER_START(UnityPerMaterial)</span></span><br><span class="line">            float4 _MainTex_ST;</span><br><span class="line">            CBUFFER_END</span><br><span class="line"></span><br><span class="line">            <span class="constructor">TEXTURE2D(<span class="params">_MainTex</span>)</span>;</span><br><span class="line">            <span class="constructor">SAMPLER(<span class="params">sampler_MainTex</span>)</span>;</span><br><span class="line"></span><br><span class="line">            Varyings vert(Attributes input)</span><br><span class="line">            &#123;</span><br><span class="line">                Varyings output = (Varyings)<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">                <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">                <span class="constructor">UNITY_TRANSFER_INSTANCE_ID(<span class="params">input</span>, <span class="params">output</span>)</span>;</span><br><span class="line">                <span class="constructor">UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(<span class="params">output</span>)</span>;</span><br><span class="line"></span><br><span class="line">                VertexPositionInputs vertexInput = <span class="constructor">GetVertexPositionInputs(<span class="params">input</span>.<span class="params">positionOS</span>.<span class="params">xyz</span>)</span>;</span><br><span class="line">                output.positionWS = vertexInput.positionWS;</span><br><span class="line">                output.positionCS = vertexInput.positionCS;</span><br><span class="line"></span><br><span class="line">                output.uv = <span class="constructor">TRANSFORM_TEX(<span class="params">input</span>.<span class="params">uv</span>, <span class="params">_MainTex</span>)</span>;</span><br><span class="line"></span><br><span class="line">                return output;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            half4 frag(Varyings input): SV_Target</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">                <span class="constructor">UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(<span class="params">input</span>)</span>;</span><br><span class="line"></span><br><span class="line">                float3 toCenter = <span class="module-access"><span class="module"><span class="identifier">_CenterPos</span>.</span></span>xyz - input.positionWS;</span><br><span class="line">                <span class="built_in">float</span> sqrDistanceXZ = dot(toCenter.xz, toCenter.xz);</span><br><span class="line"></span><br><span class="line">                half atten = (sqrDistanceXZ<span class="operator"> / </span>_CenterRadius)<span class="operator"> / </span>_ShadowFalloff;</span><br><span class="line"></span><br><span class="line">                return atten;</span><br><span class="line">            &#125;</span><br><span class="line">            ENDHLSL</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在片元着色器中，计算顶点和圆心的方向向量，点乘toCenter的xz向量，得到xz平面上方向向量长度的平方。根据方向向量的平方与半径的平方相比较，计算得到一个比率，代表阴影的强度，在和_ShadowFalloff计算之后，得到最终的阴影衰减atten。直接输出atten，效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311192240931.png" /></p>
<p>黑色部分是阴影的区域，其余白色的部分是正常的区域。下面，改一下Shader代码，使用阴影衰减与采样得到的颜色相乘，得到带阴影的效果。注意改动片元着色器，代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 frag(Varyings input): SV_Target</span><br><span class="line">&#123;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(<span class="params">input</span>)</span>;</span><br><span class="line"></span><br><span class="line">    float3 toSphere = <span class="module-access"><span class="module"><span class="identifier">_CenterPos</span>.</span></span>xyz - input.positionWS;</span><br><span class="line">    <span class="built_in">float</span> sqrDistanceXZ = dot(toSphere.xz, toSphere.xz);</span><br><span class="line"></span><br><span class="line">    half atten = (sqrDistanceXZ<span class="operator"> / </span>_CenterRadius)<span class="operator"> / </span>_ShadowFalloff;</span><br><span class="line"></span><br><span class="line">    half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">    col *= atten;</span><br><span class="line">    return col;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311192243684.png" /></p>
<p>可以发现，颜色过渡曝光。这是为什么呢？</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">half atten = (sqrDistanceXZ <span class="regexp">/ _CenterRadius) /</span> _ShadowFalloff;</span><br></pre></td></tr></table></figure>
<p>观察Shader代码发现，在计算atten的时候，没有做限制。随着顶点距离圆心的位置逐渐变远，sqrDistanceXZ趋于无穷大，导致atten会趋于无穷大。这显然不符合我们的预期。可以想到的是，对最终的结果做以下限制，当顶点距离圆心的距离超过半径时，就不会受到阴影的影响了。可以使用saturate()函数来达到这一目的：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">half atten = saturate((sqrDistanceXZ <span class="regexp">/ _CenterRadius) /</span> _ShadowFalloff);</span><br></pre></td></tr></table></figure>
<p>此时的效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311192249081.png" /></p>
<p>效果看起来还不错，与原本的圆形面片阴影的效果大致相同。</p>
<p>将模拟角色的球体往左移动到台阶正上方的效果如下：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311202228773.png" /></p>
<p>可以发现，台阶部分有一条垂直的阴影，一直延伸到了地面之下。这是因为，我们在上面计算距离的时候，只使用了xz分量，没有使用y分量，导致在台阶的垂直面上，得到的距离都相同。结合实际的项目经验来说，台阶的高度应该是很小的，所以在地面之上的台阶部分（上图中A区）的阴影是可以接受的。不可接收到，是地面之下的台阶（上图中的B区）的阴影。我们要想办法去除地面之下的台阶阴影。</p>
<p>可以想到的办法是，计算顶点与圆心在竖直方向上的距离差，只有满足一定的条件才会受到阴影的影响。</p>
<p>在C#中，将竖直方向上的阴影距离范围传递给Shader：</p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">Shader</span><span class="selector-class">.SetGlobalFloat</span>(<span class="string">&quot;_HeightRange&quot;</span>, HeightRange);</span><br></pre></td></tr></table></figure>
<p>在片元着色器中，在竖直方向上计算一个遮罩值，用来控制哪些区域会受到阴影的影响：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 frag(Varyings input): SV_Target</span><br><span class="line">&#123;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(<span class="params">input</span>)</span>;</span><br><span class="line"></span><br><span class="line">    float3 toSphere = <span class="module-access"><span class="module"><span class="identifier">_CenterPos</span>.</span></span>xyz - input.positionWS;</span><br><span class="line">    <span class="built_in">float</span> sqrDistanceXZ = dot(toSphere.xz, toSphere.xz);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float</span> yMask = saturate(step(toSphere.y, <span class="number">0</span>) + step(_HeightRange, toSphere.y));</span><br><span class="line">    return yMask;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311212230539.png" /></p>
<p>在上图中，黑色区域是竖直方向上可能受到阴影影响的区域，与我们上面的设想相符。</p>
<p>结合之前的效果，修改Shader代码如下：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">half4 frag(Varyings input): SV_Target</span><br><span class="line">&#123;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_INSTANCE_ID(<span class="params">input</span>)</span>;</span><br><span class="line">    <span class="constructor">UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(<span class="params">input</span>)</span>;</span><br><span class="line"></span><br><span class="line">    float3 toSphere = <span class="module-access"><span class="module"><span class="identifier">_CenterPos</span>.</span></span>xyz - input.positionWS;</span><br><span class="line">    <span class="built_in">float</span> sqrDistanceXZ = dot(toSphere.xz, toSphere.xz);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float</span> yMask = step(toSphere.y, <span class="number">0</span>) + step(_HeightRange, toSphere.y);</span><br><span class="line"></span><br><span class="line">    half atten = (sqrDistanceXZ<span class="operator"> / </span>_CenterRadius)<span class="operator"> / </span>_ShadowFalloff;</span><br><span class="line"></span><br><span class="line">    half4 col = <span class="constructor">SAMPLE_TEXTURE2D(<span class="params">_MainTex</span>, <span class="params">sampler_MainTex</span>, <span class="params">input</span>.<span class="params">uv</span>)</span>;</span><br><span class="line">    col *= saturate(atten + yMask);</span><br><span class="line">    return col;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终的效果如下所示：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/bzyzhang/ImgHosting1/img/2023-11-13/202311212241850.gif" /></p>
<p>最终的代码<a
href="https://github.com/bzyzhang/RoadOfShader/tree/main/Assets/2.3-PlaneShadow">如下</a></p>
<h1 id="总结">总结</h1>
<p>回顾一开始说的用面片实现阴影的问题，经过我们的改进，现在也适用于非平整的地面了。</p>
<h1 id="参考">参考</h1>
<ul>
<li>[1] <a
href="https://bzyzhang.github.io/2021/01/20/2021-01-20-%EF%BC%88%E4%B8%83%EF%BC%89%E5%87%A0%E7%A7%8D%E7%AE%80%E5%8D%95%E7%9A%84%E9%98%B4%E5%BD%B1%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/">练习项目(七)：几种简单的阴影实现</a></li>
</ul>
]]></content>
      <categories>
        <category>练习项目</category>
      </categories>
      <tags>
        <tag>Shadow</tag>
      </tags>
  </entry>
</search>
