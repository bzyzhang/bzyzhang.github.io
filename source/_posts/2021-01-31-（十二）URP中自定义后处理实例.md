---
title: 练习项目(十二)：URP中自定义后处理实例
date: 2021-01-31 16:30:19
categories: 练习项目
tags: [Post Processing]
mathjax: true
---

# 概述

URP项目中，是自带一些后处理效果的，可以通过添加Volume组件来启用相应的效果。那如果想添加自定义的后处理效果呢？<!--more-->之前在[《练习项目(四)：深度图基础及应用》](https://bzyzhang.github.io/bzyzhang.github.io/2020/12/01/2020-12-01-%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/)部分介绍了在URP中添加后处理的方法。这里，基本上还是按照上面介绍的流程，只是代码方面有了一些改变，下面会详细介绍。

# 一、通用的Renderer Feature

对于一些简单的，只是对图像做一次处理的后处理类型，这里可以实现一个通用的Renderer Feature，不同的效果可以通过不同的Shader实现。

首先是实现CommonRendererFeature，主要是可以配置后处理的材质，还有可以选择后处理的时机。主要的代码如下：

```
public class CommonRendererFeature : ScriptableRendererFeature
{
    public Material UsedMaterial;
    public RenderPassEvent PassEvent = RenderPassEvent.BeforeRenderingPostProcessing;

    CommonPass m_ScriptablePass;

    public override void Create()
    {
        m_ScriptablePass = new CommonPass(UsedMaterial)
        {
            renderPassEvent = PassEvent
        };
    }

    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)
    {
        var dest = RenderTargetHandle.CameraTarget;
        m_ScriptablePass.Setup(renderer.cameraColorTarget, dest);
        renderer.EnqueuePass(m_ScriptablePass);
    }
}
```

定义了UsedMaterial和PassEvent两个公有变量，暴露出接口。然后初始化CommonPass，再对CommonPass传递一些变量，最后添加进渲染管线中。

然后实现CommonPass，这里是主要的操作处理，主要的代码如下：

```
        void Render(CommandBuffer cmd, ref RenderingData renderingData)
        {
            if (renderingData.cameraData.isSceneViewCamera) return;

            cmd.GetTemporaryRT(m_TemporaryColorTexture.id, renderingData.cameraData.cameraTargetDescriptor, FilterMode.Bilinear);

            var source = currentTarget;

            cmd.Blit(source, m_TemporaryColorTexture.Identifier(), m_Material);

            cmd.Blit(m_TemporaryColorTexture.Identifier(),source);
        }
```

首先获取一张临时的渲染贴图m_TemporaryColorTexture，与屏幕的宽高等相同；然后，将当前的帧缓冲source中的数据传递给m_TemporaryColorTexture，并进行相应的后处理，这一步是通过cmd.Blit()方式实现的，相应的处理根据m_Material来执行。

此时，m_TemporaryColorTexture中存储的就是经过后处理的图像。最后一步，将m_TemporaryColorTexture中的内容传递给source。这一步要注意，这里如果传递给destination的话，URP自带的最后的FinalPostProcessing就获取不到经过后处理的图像了，所以这里要传递给source，这样，经过自定义的后处理后，还可以经过URP中的后处理。

> 这里有一点要注意，后处理Shader中必须添加Properties，其中必须有名称为“_MainTex”的属性。否则，cmd.Blit(source, m_TemporaryColorTexture.Identifier(), m_Material)这里就无法将source中的纹理传递给Shader。

此处有图。

## 1、Cross Hatching

思路：采样纹理信息，计算出颜色的“长度”，然后给定一些阈值，对不同范围，满足一定条件的像素，返回黑色；不满足条件的话，返回白色。这样，就形成交叉条纹的效果。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.1-CrossHatching.shader)

## 2、Thermal Vision

思路：采样纹理信息，计算出颜色值的亮度值，然后使用亮度值在三个颜色之间插值。这样，整个画面好像热视图一样的效果。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.2-ThermalVision.shader)

## 3、Dream Vision

思路：采样像素及其周围的9个点，然后把颜色相加除以9，这一步，主要是对纹理进行模糊；最后，把得到的颜色，对R、G、B三个通道相加取平均。得到一种黑白化的画面。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.3-DreamVision.shader)

## 4、Edge Detection By Sobel

思路：使用Sobel算子根据颜色值进行边界检测。主要是对像素点周围的9个像素值采样，再根据Sobel算子计算，判断该像素点是不是边界。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.4-EdgeDetectionBySobel.shader)

## 5、Lens Circle

思路：采样纹理，根据UV距离中心的距离，在内圆半径和外圆半径之间插值，根据插值结果与采样得到的纹理颜色相乘。这样，就可以得到内圆内正常显示，外圆外是黑色的，内圆和外圆之间是一个渐变色的效果。

此处有图：

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.5-LensCircle.shader)

## 6、Pixelation

思路：使用一个变量PixelSize对UV先进行缩小，然后使用floor()操作，向下取整，在使用PixelSize进行放大。最后用处理后的UV采样，这样，就可以得到像素化的效果。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.6-Pixelation.shader)

## 7、Posterization

思路：采样纹理，对采样得到的颜色值先使用Num进行放大，然后使用floor()操作，向下取整；再使用Num进行缩小，得到最终的颜色。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.7-Posterization.shader)

## 8、Brightness、Saturation、Contrast

思路：这里主要是使用亮度、饱和度和对比度对纹理采样的颜色进行处理。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.8-BSC.shader)

# 二、Gaussian Blur

这里，具体的原理思路可以参考《Unity Shader入门精要》12.4高斯模糊一节。Shader部分的代码基本相同。这里要说一下的是C#部分的代码改动比较多。

```
        void Render(CommandBuffer cmd, ref RenderingData renderingData)
        {
            if (renderingData.cameraData.isSceneViewCamera) return;

            var source = currentTarget;

            RenderTextureDescriptor opaqueDesc = renderingData.cameraData.cameraTargetDescriptor;

            opaqueDesc.width /= m_DownSample;

            opaqueDesc.height /= m_DownSample;

            opaqueDesc.depthBufferBits = 0;

            cmd.GetTemporaryRT(bufferTex0.id, opaqueDesc, FilterMode.Bilinear);
            cmd.GetTemporaryRT(bufferTex1.id, opaqueDesc, FilterMode.Bilinear);

            Blit(cmd, source, bufferTex0.Identifier());

            for (int i = 0; i < m_Iterations; i++)
            {
                Blit(cmd, bufferTex0.Identifier(), bufferTex1.Identifier(), gaussianBlurMat, 0);

                Blit(cmd, bufferTex1.Identifier(), bufferTex0.Identifier(), gaussianBlurMat, 1);
            }

            Blit(cmd, bufferTex0.Identifier(), source);
        }
```

上面，获取了两张临时的纹理，用来进行交换模糊。模糊结束后，还有将最终的模糊纹理传递给source，这样，URP中的自带的后处理可以对模糊后的图像继续处理。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.9-GaussianBlur.shader)

# 三、Bloom

具体的原理思路可以参考《Unity Shader入门精要》12.5Bloom效果一节，这里介绍一下不同的地方。

```
void Render(CommandBuffer cmd, ref RenderingData renderingData)
        {
            if (renderingData.cameraData.isSceneViewCamera) return;

            var source = currentTarget;

            RenderTextureDescriptor opaqueDesc = renderingData.cameraData.cameraTargetDescriptor;

            opaqueDesc.width /= m_DownSample;

            opaqueDesc.height /= m_DownSample;

            opaqueDesc.depthBufferBits = 0;

            cmd.GetTemporaryRT(bufferTex0.id, opaqueDesc, FilterMode.Bilinear);
            cmd.GetTemporaryRT(bufferTex1.id, opaqueDesc, FilterMode.Bilinear);

            bloomMat.SetFloat("_LuminanceThreshold", m_LuminanceThreshold);
            bloomMat.SetInt("_BlurSize", m_BlurSize);

            Blit(cmd, source, bufferTex0.Identifier(), bloomMat, EXTRACT_PASS);

            for (int i = 0; i < m_Iterations; i++)
            {
                Blit(cmd, bufferTex0.Identifier(), bufferTex1.Identifier(), bloomMat, GAUSSIAN_HOR_PASS);

                Blit(cmd, bufferTex1.Identifier(), bufferTex0.Identifier(), bloomMat, GAUSSIAN_VERT_PASS);
            }

            cmd.SetGlobalTexture("_BloomTex", bufferTex0.Identifier());
            Blit(cmd, source, bufferTex1.Identifier(), bloomMat, BLOOM_PASS);

            Blit(cmd, bufferTex1.Identifier(), source);
        }
```

最要的思路是，先提取原始纹理中亮度超过一定阈值的区域，才出到临时纹理bufferTex0中；然后使用高斯模糊在bufferTex0和bufferTex1之间进行迭代操作；再然后，把原始纹理和模糊后的纹理进行叠加；最后，还要吧叠加后的纹理传递会source。

此处有图

[代码如下](https://github.com/bzyzhang/RoadOfShader/blob/main/Assets/1.11-PostProcessing/Shader/1.11.10-Bloom.shader)

# 参考

- [1] 《Unity Shader入门精要》第12章
- [2] [Posterization Post Processing Effect (GLSL)](https://www.geeks3d.com/20091027/shader-library-posterization-post-processing-effect-glsl/)
- [3] [泛光](https://learnopengl-cn.github.io/05%20Advanced%20Lighting/07%20Bloom/)